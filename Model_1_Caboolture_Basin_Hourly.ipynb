{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood Prediction Model 1 - Hourly Discharge at Caboolture River\n",
    "\n",
    "The Objective of this notebook is to create a flood prediction model for the Caboolture River at Upper Caboolture. We will use hourly rainfall data and an hourly discharge as the target time series and a single hourly rainfall time series as input variable. This model will be used for comparision with [RORB](https://www.monash.edu/engineering/departments/civil/research/themes/water/rorb)â€™s predictions.\n",
    "\n",
    "## Benchmark Model\n",
    "\n",
    "[RORB](https://www.monash.edu/engineering/departments/civil/research/themes/water/rorb) model is generally employed for calculating design flood discharges. It uses many assumptions and is manually calibrated to one flooding event. This will be used as benchmark model for comparison purpose.\n",
    "\n",
    "## Data Set\n",
    "The hydrological data available at [Queensland Water Monitoring Information Portal](https://water-monitoring.information.qld.gov.au/) will be used. Hourly as well as daily water flow data is available at various stations. Rainfall data is available in some of the stations. For the Caboolture River, only single discharge and rainfal station is available. \n",
    "\n",
    "\n",
    "\n",
    "### Work Workflow\n",
    "\n",
    "* Preprocessing and exploring the data\n",
    "* Creating training and test sets of time series\n",
    "* Formatting data as JSON files and uploading to S3\n",
    "* Instantiating and training a DeepAR estimator\n",
    "* Deploying a model and creating a predictor\n",
    "* Comparing the Predictor with RORB's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and exploring the data\n",
    "\n",
    "The raw data for Caboolture River is available at raw_data/Caboolture folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "from utility import unzip_ts_data, read_ts_data, series_to_json, clean_ts_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./raw_data/Caboolture/142001A_20191103_rain\n",
      "unzipped 142001A_20191103_rain.zip!\n",
      "./raw_data/Caboolture/142001A_20191103_flow\n",
      "unzipped 142001A_20191103_flow.zip!\n"
     ]
    }
   ],
   "source": [
    "# Read target (flow) and feature (rain) data\n",
    "\n",
    "target_name = '142001A_20191103_flow' # folder name containing target time series\n",
    "\n",
    "# Unzip the data and get list of csv paths\n",
    "cabooltre_csv_paths = unzip_ts_data('./raw_data/Caboolture')\n",
    "# maroochy_csv_paths = unzip_ts_data('./raw_data/Maroochy')\n",
    "# brisbane_csv_paths = unzip_ts_data('./raw_data/Brisbane')\n",
    "\n",
    "# Select the target csv\n",
    "target_csv_paths = []\n",
    "other_csv_paths = []\n",
    "for csv_path in cabooltre_csv_paths:\n",
    "    if target_name in csv_path:\n",
    "        target_csv_paths.append(csv_path)\n",
    "    else:\n",
    "        other_csv_paths.append(csv_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./raw_data/Caboolture/142001A_20191103_rain/142001A.csv',\n",
       " './raw_data/Caboolture/142001A_20191103_flow/142001A.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cabooltre_csv_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Read the extracted csv data\n",
    "\n",
    "target_ts_data = read_ts_data(target_csv_paths[0], value_cols = [\"Mean\"], prefix = \"CabFlow\")\n",
    "\n",
    "rain_ts_data = read_ts_data(other_csv_paths[0], value_cols = [\"Total\"], prefix = \"CabRain\")\n",
    "\n",
    "# rain_maroochy_ts_data = read_ts_data(maroochy_csv_paths[0], value_cols = [\"Total\"], prefix = \"MarRain\")\n",
    "# rain_brisbane_ts_data = read_ts_data(brisbane_csv_paths[0], value_cols = [\"Total\"], prefix = \"BrisRain\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344171"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_ts_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_ts_data = target_ts_data.join(rain_ts_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdfcc2cb7f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_ts_data[210000:255000].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "First we remove the missing values from the both ends of time. After doing so, we find that there are no missing values for the flow data while there are some missing data for the rainfall data. We replace the missing rainfall data with the rainfall from the nearest station in Maroochy basin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_length = 24\n",
    "ts_s = clean_ts_data(main_ts_data, datetime.timedelta(hours=1), 10*prediction_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting to Training and Test Series\n",
    "Now we split the data into training and test series. Data up to 2007 will be used for training and then the rest for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "ts_train = []\n",
    "ts_val = []\n",
    "ts_test = []\n",
    "\n",
    "val_percent = 0.5 # Select 20% of training data for validation (for hyper parameter tuning)\n",
    "\n",
    "for ts in ts_s:\n",
    "    if ts.index[0] <= pd.Timestamp('2005-01-01 00:00:00'):\n",
    "        ts_train.append(ts)\n",
    "        if random.random() <val_percent:\n",
    "            ts_val.append(ts)\n",
    "    else:\n",
    "        ts_test.append(ts)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ts_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ts_s[0]\n",
    "target_col = \"CabFlowMean\"\n",
    "\n",
    "json_obj = series_to_json(ts, target_col)\n",
    "\n",
    "# print(json_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json for formatting data\n",
    "import json\n",
    "import os # and os for saving\n",
    "\n",
    "def write_json_dataset(time_series, target_col, filename): \n",
    "    with open(filename, 'wb') as f:\n",
    "        # for each of our times series, there is one JSON line\n",
    "        for ts in time_series:\n",
    "            json_line = json.dumps(series_to_json(ts, target_col)) + '\\n'\n",
    "            json_line = json_line.encode('utf-8')\n",
    "            f.write(json_line)\n",
    "    print(filename + ' saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this data to a local directory\n",
    "data_dir = 'json_model4_data'\n",
    "\n",
    "# make data dir, if it does not exist\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_model4_data/train.json saved.\n",
      "json_model4_data/test.json saved.\n",
      "json_model4_data/val.json saved.\n"
     ]
    }
   ],
   "source": [
    "# directories to save train/test data\n",
    "train_path = os.path.join(data_dir, 'train.json')\n",
    "test_path = os.path.join(data_dir, 'test.json')\n",
    "val_path = os.path.join(data_dir, 'val.json')\n",
    "\n",
    "# write train/test JSON files\n",
    "write_json_dataset(ts_train, target_col, train_path)        \n",
    "write_json_dataset(ts_test, target_col, test_path)\n",
    "write_json_dataset(ts_val, target_col, val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading data to S3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session, role, bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "prefix='flood-prediction-model-4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload training data to a location in S3, and save that location to train_path\n",
    "Upload test data to a location in S3, and save that location to test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# *unique* train/test prefixes\n",
    "train_prefix   = '{}/{}'.format(prefix, 'train')\n",
    "test_prefix    = '{}/{}'.format(prefix, 'test')\n",
    "val_prefix    = '{}/{}'.format(prefix, 'val')\n",
    "\n",
    "# uploading data to S3, and saving locations\n",
    "train_s3_path  = sagemaker_session.upload_data(train_path, bucket=bucket, key_prefix=train_prefix)\n",
    "test_s3_path   = sagemaker_session.upload_data(test_path,  bucket=bucket, key_prefix=test_prefix)\n",
    "val_s3_path   = sagemaker_session.upload_data(val_path,  bucket=bucket, key_prefix=val_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is stored in: s3://sagemaker-ap-southeast-2-990878777707/flood-prediction-model-4/train/train.json\n",
      "Test data is stored in: s3://sagemaker-ap-southeast-2-990878777707/flood-prediction-model-4/test/test.json\n",
      "Val data is stored in: s3://sagemaker-ap-southeast-2-990878777707/flood-prediction-model-4/val/val.json\n"
     ]
    }
   ],
   "source": [
    "# check locations\n",
    "print('Training data is stored in: '+ train_s3_path)\n",
    "print('Test data is stored in: '+ test_s3_path)\n",
    "print('Val data is stored in: '+ val_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training a DeepAR Estimator\n",
    "\n",
    "Some estimators have specific, SageMaker constructors, but not all. Instead you can create a base `Estimator` and pass in the specific image (or container) that holds a specific model.\n",
    "\n",
    "Next, we configure the container image to be used for the region that we are running in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "image_name = get_image_uri(boto3.Session().region_name, # get the region\n",
    "                           'forecasting-deepar') # specify image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate an Estimator \n",
    "\n",
    "You can now define the estimator that will launch the training job. A generic Estimator will be defined by the usual constructor arguments and an `image_name`. \n",
    "> You can take a look at the [estimator source code](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/estimator.py#L595) to view specifics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# dir to save model artifacts\n",
    "s3_output_path = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "\n",
    "# instantiate a DeepAR estimator\n",
    "estimator = Estimator(sagemaker_session=sagemaker_session,\n",
    "                      image_name=image_name,\n",
    "                      role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='ml.m4.xlarge',\n",
    "                      output_path=s3_output_path\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Hyperparameters\n",
    "\n",
    "Next, we need to define some DeepAR hyperparameters that define the model size and training behavior. Values for the epochs, frequency, prediction length, and context length are required.\n",
    "\n",
    "* **epochs**: The maximum number of times to pass over the data when training.\n",
    "* **time_freq**: The granularity of the time series in the dataset ('D' for daily).\n",
    "* **prediction_length**: A string; the number of time steps (based off the unit of frequency) that the model is trained to predict. \n",
    "* **context_length**: The number of time points that the model gets to see *before* making a prediction. \n",
    "\n",
    "### Context Length\n",
    "\n",
    "Typically, it is recommended that you start with a `context_length`=`prediction_length`. This is because a DeepAR model also receives \"lagged\" inputs from the target time series, which allow the model to capture long-term dependencies. For example, a daily time series can have yearly seasonality and DeepAR automatically includes a lag of one year. So, the context length can be shorter than a year, and the model will still be able to capture this seasonality. \n",
    "\n",
    "The lag values that the model picks depend on the frequency of the time series. For example, lag values for daily frequency are the previous week, 2 weeks, 3 weeks, 4 weeks, and year. You can read more about this in the [DeepAR \"how it works\" documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar_how-it-works.html).\n",
    "\n",
    "### Optional Hyperparameters\n",
    "\n",
    "You can also configure optional hyperparameters to further tune your model. These include parameters like the number of layers in our RNN model, the number of cells per layer, the likelihood function, and the training options, such as batch size and learning rate. \n",
    "\n",
    "For an exhaustive list of all the different DeepAR hyperparameters you can refer to the DeepAR [hyperparameter documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar_hyperparameters.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "freq='H' # Hourly\n",
    "context_length = 24\n",
    "prediction_length = 24\n",
    "\n",
    "# hyperparameters = {\n",
    "#     \"epochs\": \"1000\",\n",
    "#     \"time_freq\": freq,\n",
    "#     \"prediction_length\": str(prediction_length),\n",
    "#     \"context_length\": str(context_length),\n",
    "#     \"num_cells\": \"50\",\n",
    "#     \"num_layers\": \"3\",\n",
    "#     \"mini_batch_size\": \"128\",\n",
    "#     \"learning_rate\": \"0.001\",\n",
    "#     \"early_stopping_patience\": \"10\"\n",
    "# }\n",
    "\n",
    "hyperparameters = {\n",
    "#     \"epochs\": \"50\",\n",
    "    \"time_freq\": freq,\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"context_length\": str(context_length),\n",
    "#     \"num_cells\": \"50\",\n",
    "#     \"num_layers\": \"3\",\n",
    "    \"mini_batch_size\": \"75\",\n",
    "    \"learning_rate\": \"0.0057\",\n",
    "    \"dropout_rate\" : \"0.1\",\n",
    "    \"num_cells\":95\n",
    "#     \"early_stopping_patience\": \"10\"\n",
    "}\n",
    "\n",
    "hyperparameter_ranges = {'num_layers': IntegerParameter(5, 8),\n",
    "                        'epochs' : IntegerParameter(50,1000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hyperparams\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'train:final_loss'\n",
    "\n",
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=50,\n",
    "                            max_parallel_jobs=2,\n",
    "                            objective_type = \"Minimize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Job\n",
    "\n",
    "Now, we are ready to launch the training job! SageMaker will start an EC2 instance, download the data from S3, start training the model and save the trained model.\n",
    "\n",
    "If you provide the `test` data channel, as we do in this example, DeepAR will also calculate accuracy metrics for the trained model on this test data set. This is done by predicting the last `prediction_length` points of each time series in the test set and comparing this to the *actual* value of the time series. The computed error metrics will be included as part of the log output.\n",
    "\n",
    "The next cell may take a few minutes to complete, depending on data size, model complexity, and training options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 ms, sys: 0 ns, total: 13.7 ms\n",
      "Wall time: 250 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Hyper parameter tuning using validation data.\n",
    "data_channels = {\n",
    "    \"train\": val_s3_path\n",
    "}\n",
    "\n",
    "# fit the estimator\n",
    "tuner.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq='H'\n",
    "context_length=24 # same as prediction_length\n",
    "\n",
    "hyperparameters = {\n",
    "    \"epochs\": \"995\",\n",
    "    \"time_freq\": freq,\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"context_length\": str(context_length),\n",
    "    \"num_cells\": \"95\",\n",
    "    \"num_layers\": \"7\",\n",
    "    \"mini_batch_size\": \"74\",\n",
    "    \"learning_rate\": \"0.0057\",\n",
    "    \"dropout_rate\" : \"0.1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hyperparams\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-31 10:53:33 Starting - Starting the training job...\n",
      "2020-01-31 10:53:34 Starting - Launching requested ML instances......\n",
      "2020-01-31 10:54:36 Starting - Preparing the instances for training...\n",
      "2020-01-31 10:55:31 Downloading - Downloading input data...\n",
      "2020-01-31 10:55:58 Training - Downloading the training image...\n",
      "2020-01-31 10:56:17 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'dropout_rate': u'0.1', u'learning_rate': u'0.0057', u'num_cells': u'95', u'prediction_length': u'24', u'epochs': u'995', u'time_freq': u'H', u'context_length': u'24', u'num_layers': u'7', u'mini_batch_size': u'74'}\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] Final configuration: {u'dropout_rate': u'0.1', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'0.0057', u'num_layers': u'7', u'epochs': u'995', u'embedding_dimension': u'10', u'num_cells': u'95', u'_num_kv_servers': u'auto', u'mini_batch_size': u'74', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'24', u'time_freq': u'H', u'context_length': u'24', u'_kvstore': u'auto', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=1 from dataset.\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] Training set statistics:\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] Real time series\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] number of time series: 47\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] number of observations: 22195\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] mean target length: 472\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] min/mean/max target: 0.0/1.01540836731/150.463592529\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] mean abs(target): 1.01540836731\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] contains missing values: no\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] Small number of time series. Doing 10 number of passes over dataset per epoch.\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] Test set statistics:\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] Real time series\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] number of time series: 8\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] number of observations: 3497\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] mean target length: 437\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] min/mean/max target: 0.00150000001304/0.194971293049/14.1605997086\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] mean abs(target): 0.194971293049\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:19 INFO 140345909798720] contains missing values: no\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:20 INFO 140345909798720] nvidia-smi took: 0.0251879692078 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:20 INFO 140345909798720] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:20 INFO 140345909798720] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 259.6259117126465, \"sum\": 259.6259117126465, \"min\": 259.6259117126465}}, \"EndTime\": 1580468180.263209, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468180.002632}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:20 INFO 140345909798720] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 688.2960796356201, \"sum\": 688.2960796356201, \"min\": 688.2960796356201}}, \"EndTime\": 1580468180.691055, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468180.263302}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:22 INFO 140345909798720] Epoch[0] Batch[0] avg_epoch_loss=1.417717\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:22 INFO 140345909798720] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=1.41771656758\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:25 INFO 140345909798720] Epoch[0] Batch[5] avg_epoch_loss=0.531605\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:25 INFO 140345909798720] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=0.531604998821\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:25 INFO 140345909798720] Epoch[0] Batch [5]#011Speed: 109.70 samples/sec#011loss=0.531605\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:28 INFO 140345909798720] Epoch[0] Batch[10] avg_epoch_loss=0.758698\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:28 INFO 140345909798720] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=1.03120888633\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:28 INFO 140345909798720] Epoch[0] Batch [10]#011Speed: 121.74 samples/sec#011loss=1.031209\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:28 INFO 140345909798720] processed a total of 749 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 995, \"sum\": 995.0, \"min\": 995}, \"update.time\": {\"count\": 1, \"max\": 7981.048107147217, \"sum\": 7981.048107147217, \"min\": 7981.048107147217}}, \"EndTime\": 1580468188.672371, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468180.691143}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:28 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=93.8457362917 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:28 INFO 140345909798720] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:28 INFO 140345909798720] #quality_metric: host=algo-1, epoch=0, train loss <loss>=0.75869767496\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:29 INFO 140345909798720] Epoch[1] Batch[0] avg_epoch_loss=0.340335\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=0.340334660298\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:32 INFO 140345909798720] Epoch[1] Batch[5] avg_epoch_loss=0.063108\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=0.0631084592493\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:32 INFO 140345909798720] Epoch[1] Batch [5]#011Speed: 124.18 samples/sec#011loss=0.063108\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:34 INFO 140345909798720] processed a total of 705 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6131.75892829895, \"sum\": 6131.75892829895, \"min\": 6131.75892829895}}, \"EndTime\": 1580468194.805001, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468188.672466}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:34 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.96873316 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:34 INFO 140345909798720] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:34 INFO 140345909798720] #quality_metric: host=algo-1, epoch=1, train loss <loss>=-0.154601005606\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:35 INFO 140345909798720] Epoch[2] Batch[0] avg_epoch_loss=-0.359522\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:35 INFO 140345909798720] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=-0.359521556545\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:38 INFO 140345909798720] Epoch[2] Batch[5] avg_epoch_loss=-0.655055\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:38 INFO 140345909798720] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=-0.655055127702\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:38 INFO 140345909798720] Epoch[2] Batch [5]#011Speed: 123.14 samples/sec#011loss=-0.655055\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:41 INFO 140345909798720] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6219.675779342651, \"sum\": 6219.675779342651, \"min\": 6219.675779342651}}, \"EndTime\": 1580468201.025792, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468194.805303}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:41 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=107.720625308 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:41 INFO 140345909798720] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:41 INFO 140345909798720] #quality_metric: host=algo-1, epoch=2, train loss <loss>=-0.715617481438\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:41 INFO 140345909798720] Epoch[3] Batch[0] avg_epoch_loss=-0.185808\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:41 INFO 140345909798720] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=-0.185808181763\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:44 INFO 140345909798720] Epoch[3] Batch[5] avg_epoch_loss=-0.601497\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:44 INFO 140345909798720] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=-0.601496649218\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:44 INFO 140345909798720] Epoch[3] Batch [5]#011Speed: 125.99 samples/sec#011loss=-0.601497\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:47 INFO 140345909798720] processed a total of 733 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6168.910980224609, \"sum\": 6168.910980224609, \"min\": 6168.910980224609}}, \"EndTime\": 1580468207.195276, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468201.025864}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:47 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.819209708 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:47 INFO 140345909798720] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:47 INFO 140345909798720] #quality_metric: host=algo-1, epoch=3, train loss <loss>=-0.609889989286\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:48 INFO 140345909798720] Epoch[4] Batch[0] avg_epoch_loss=-1.174437\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=-1.17443682696\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:50 INFO 140345909798720] Epoch[4] Batch[5] avg_epoch_loss=-1.141665\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:50 INFO 140345909798720] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=-1.14166475416\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:50 INFO 140345909798720] Epoch[4] Batch [5]#011Speed: 125.71 samples/sec#011loss=-1.141665\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:53 INFO 140345909798720] processed a total of 698 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6147.861957550049, \"sum\": 6147.861957550049, \"min\": 6147.861957550049}}, \"EndTime\": 1580468213.343615, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468207.195361}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:53 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.532798942 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:53 INFO 140345909798720] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:53 INFO 140345909798720] #quality_metric: host=algo-1, epoch=4, train loss <loss>=-1.04122746957\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:54 INFO 140345909798720] Epoch[5] Batch[0] avg_epoch_loss=-1.219318\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:54 INFO 140345909798720] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=-1.21931787439\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:57 INFO 140345909798720] Epoch[5] Batch[5] avg_epoch_loss=-1.546997\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:57 INFO 140345909798720] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=-1.54699727651\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:56:57 INFO 140345909798720] Epoch[5] Batch [5]#011Speed: 125.13 samples/sec#011loss=-1.546997\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:00 INFO 140345909798720] Epoch[5] Batch[10] avg_epoch_loss=-1.547200\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:00 INFO 140345909798720] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=-1.54744320431\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:00 INFO 140345909798720] Epoch[5] Batch [10]#011Speed: 126.86 samples/sec#011loss=-1.547443\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:00 INFO 140345909798720] processed a total of 783 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6695.343971252441, \"sum\": 6695.343971252441, \"min\": 6695.343971252441}}, \"EndTime\": 1580468220.03952, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468213.343719}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:00 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.944792732 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:00 INFO 140345909798720] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:00 INFO 140345909798720] #quality_metric: host=algo-1, epoch=5, train loss <loss>=-1.54719997097\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:00 INFO 140345909798720] Epoch[6] Batch[0] avg_epoch_loss=-1.666310\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:00 INFO 140345909798720] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=-1.66631038769\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:03 INFO 140345909798720] Epoch[6] Batch[5] avg_epoch_loss=-1.641674\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:03 INFO 140345909798720] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=-1.64167428231\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:03 INFO 140345909798720] Epoch[6] Batch [5]#011Speed: 123.80 samples/sec#011loss=-1.641674\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:06 INFO 140345909798720] processed a total of 715 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6220.8240032196045, \"sum\": 6220.8240032196045, \"min\": 6220.8240032196045}}, \"EndTime\": 1580468226.26084, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468220.039607}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:06 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.934229507 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:06 INFO 140345909798720] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:06 INFO 140345909798720] #quality_metric: host=algo-1, epoch=6, train loss <loss>=-1.64453677616\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:07 INFO 140345909798720] Epoch[7] Batch[0] avg_epoch_loss=-2.071294\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:07 INFO 140345909798720] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=-2.0712935989\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:10 INFO 140345909798720] Epoch[7] Batch[5] avg_epoch_loss=-1.610662\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:10 INFO 140345909798720] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=-1.61066239159\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:10 INFO 140345909798720] Epoch[7] Batch [5]#011Speed: 126.20 samples/sec#011loss=-1.610662\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:12 INFO 140345909798720] processed a total of 739 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6131.024122238159, \"sum\": 6131.024122238159, \"min\": 6131.024122238159}}, \"EndTime\": 1580468232.392355, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468226.260928}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:12 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.532037077 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:12 INFO 140345909798720] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:12 INFO 140345909798720] #quality_metric: host=algo-1, epoch=7, train loss <loss>=-1.72050922497\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:13 INFO 140345909798720] Epoch[8] Batch[0] avg_epoch_loss=-1.953293\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:13 INFO 140345909798720] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=-1.95329284668\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:16 INFO 140345909798720] Epoch[8] Batch[5] avg_epoch_loss=-1.862286\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:16 INFO 140345909798720] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=-1.86228638726\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:16 INFO 140345909798720] Epoch[8] Batch [5]#011Speed: 125.32 samples/sec#011loss=-1.862286\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:18 INFO 140345909798720] processed a total of 727 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6177.523851394653, \"sum\": 6177.523851394653, \"min\": 6177.523851394653}}, \"EndTime\": 1580468238.57052, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468232.392441}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:18 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.682426925 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:18 INFO 140345909798720] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:18 INFO 140345909798720] #quality_metric: host=algo-1, epoch=8, train loss <loss>=-1.95308017215\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:19 INFO 140345909798720] Epoch[9] Batch[0] avg_epoch_loss=-1.881383\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:19 INFO 140345909798720] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=-1.88138271022\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:22 INFO 140345909798720] Epoch[9] Batch[5] avg_epoch_loss=-1.969178\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:22 INFO 140345909798720] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=-1.96917815681\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:22 INFO 140345909798720] Epoch[9] Batch [5]#011Speed: 124.58 samples/sec#011loss=-1.969178\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:25 INFO 140345909798720] Epoch[9] Batch[10] avg_epoch_loss=-1.940500\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:25 INFO 140345909798720] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=-1.90608619999\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:25 INFO 140345909798720] Epoch[9] Batch [10]#011Speed: 126.58 samples/sec#011loss=-1.906086\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:25 INFO 140345909798720] processed a total of 765 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6712.451934814453, \"sum\": 6712.451934814453, \"min\": 6712.451934814453}}, \"EndTime\": 1580468245.283502, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468238.570595}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:25 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.965053974 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:25 INFO 140345909798720] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:25 INFO 140345909798720] #quality_metric: host=algo-1, epoch=9, train loss <loss>=-1.94049999462\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:26 INFO 140345909798720] Epoch[10] Batch[0] avg_epoch_loss=-2.316510\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:26 INFO 140345909798720] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=-2.31650955613\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:29 INFO 140345909798720] Epoch[10] Batch[5] avg_epoch_loss=-2.065209\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=-2.06520932859\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:29 INFO 140345909798720] Epoch[10] Batch [5]#011Speed: 126.05 samples/sec#011loss=-2.065209\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:31 INFO 140345909798720] processed a total of 724 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6099.050998687744, \"sum\": 6099.050998687744, \"min\": 6099.050998687744}}, \"EndTime\": 1580468251.383097, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468245.283591}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:31 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.704523676 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:31 INFO 140345909798720] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:31 INFO 140345909798720] #quality_metric: host=algo-1, epoch=10, train loss <loss>=-2.19159989228\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:32 INFO 140345909798720] Epoch[11] Batch[0] avg_epoch_loss=-1.923650\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=-1.92364996833\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:35 INFO 140345909798720] Epoch[11] Batch[5] avg_epoch_loss=-2.076789\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:35 INFO 140345909798720] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=-2.07678865312\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:35 INFO 140345909798720] Epoch[11] Batch [5]#011Speed: 126.55 samples/sec#011loss=-2.076789\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:38 INFO 140345909798720] Epoch[11] Batch[10] avg_epoch_loss=-2.147564\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:38 INFO 140345909798720] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=-2.23249375627\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:38 INFO 140345909798720] Epoch[11] Batch [10]#011Speed: 125.68 samples/sec#011loss=-2.232494\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:38 INFO 140345909798720] processed a total of 772 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6725.730180740356, \"sum\": 6725.730180740356, \"min\": 6725.730180740356}}, \"EndTime\": 1580468258.109456, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468251.383183}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:38 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.781115041 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:38 INFO 140345909798720] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:38 INFO 140345909798720] #quality_metric: host=algo-1, epoch=11, train loss <loss>=-2.14756370001\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:38 INFO 140345909798720] Epoch[12] Batch[0] avg_epoch_loss=-2.308714\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:38 INFO 140345909798720] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=-2.30871355211\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:41 INFO 140345909798720] Epoch[12] Batch[5] avg_epoch_loss=-2.148905\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:41 INFO 140345909798720] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=-2.14890498943\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:41 INFO 140345909798720] Epoch[12] Batch [5]#011Speed: 125.75 samples/sec#011loss=-2.148905\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:44 INFO 140345909798720] Epoch[12] Batch[10] avg_epoch_loss=-1.862777\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:44 INFO 140345909798720] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=-1.51942375802\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:44 INFO 140345909798720] Epoch[12] Batch [10]#011Speed: 127.39 samples/sec#011loss=-1.519424\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:44 INFO 140345909798720] processed a total of 770 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6662.851095199585, \"sum\": 6662.851095199585, \"min\": 6662.851095199585}}, \"EndTime\": 1580468264.772821, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468258.109533}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:44 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.563768998 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:44 INFO 140345909798720] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:44 INFO 140345909798720] #quality_metric: host=algo-1, epoch=12, train loss <loss>=-1.86277715697\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:45 INFO 140345909798720] Epoch[13] Batch[0] avg_epoch_loss=-2.353302\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=-2.35330158955\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:48 INFO 140345909798720] Epoch[13] Batch[5] avg_epoch_loss=-2.232365\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=-2.23236462017\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:48 INFO 140345909798720] Epoch[13] Batch [5]#011Speed: 124.09 samples/sec#011loss=-2.232365\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:50 INFO 140345909798720] processed a total of 702 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6110.839128494263, \"sum\": 6110.839128494263, \"min\": 6110.839128494263}}, \"EndTime\": 1580468270.884207, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468264.772916}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:50 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.875661825 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:50 INFO 140345909798720] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:50 INFO 140345909798720] #quality_metric: host=algo-1, epoch=13, train loss <loss>=-2.33871958965\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:51 INFO 140345909798720] Epoch[14] Batch[0] avg_epoch_loss=-2.507481\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:51 INFO 140345909798720] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=-2.50748051824\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:54 INFO 140345909798720] Epoch[14] Batch[5] avg_epoch_loss=-1.574552\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:54 INFO 140345909798720] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=-1.57455198185\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:54 INFO 140345909798720] Epoch[14] Batch [5]#011Speed: 126.88 samples/sec#011loss=-1.574552\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:56 INFO 140345909798720] processed a total of 723 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6107.012033462524, \"sum\": 6107.012033462524, \"min\": 6107.012033462524}}, \"EndTime\": 1580468276.991763, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468270.884277}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:56 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.385806454 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:56 INFO 140345909798720] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:56 INFO 140345909798720] #quality_metric: host=algo-1, epoch=14, train loss <loss>=-1.66655651556\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:57 INFO 140345909798720] Epoch[15] Batch[0] avg_epoch_loss=-2.084943\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:57:57 INFO 140345909798720] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=-2.08494341051\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:00 INFO 140345909798720] Epoch[15] Batch[5] avg_epoch_loss=-1.977615\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:00 INFO 140345909798720] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=-1.97761527053\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:00 INFO 140345909798720] Epoch[15] Batch [5]#011Speed: 127.50 samples/sec#011loss=-1.977615\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:03 INFO 140345909798720] processed a total of 731 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6159.065961837769, \"sum\": 6159.065961837769, \"min\": 6159.065961837769}}, \"EndTime\": 1580468283.151569, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468276.991859}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:03 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.683992931 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:03 INFO 140345909798720] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:03 INFO 140345909798720] #quality_metric: host=algo-1, epoch=15, train loss <loss>=-2.10285193985\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:03 INFO 140345909798720] Epoch[16] Batch[0] avg_epoch_loss=-2.089954\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:03 INFO 140345909798720] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=-2.08995386072\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:06 INFO 140345909798720] Epoch[16] Batch[5] avg_epoch_loss=-2.215471\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:06 INFO 140345909798720] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=-2.21547070065\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:06 INFO 140345909798720] Epoch[16] Batch [5]#011Speed: 126.01 samples/sec#011loss=-2.215471\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:09 INFO 140345909798720] Epoch[16] Batch[10] avg_epoch_loss=-2.303753\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:09 INFO 140345909798720] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=-2.40969213537\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:09 INFO 140345909798720] Epoch[16] Batch [10]#011Speed: 125.15 samples/sec#011loss=-2.409692\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:09 INFO 140345909798720] processed a total of 750 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6700.603008270264, \"sum\": 6700.603008270264, \"min\": 6700.603008270264}}, \"EndTime\": 1580468289.85281, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468283.151644}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:09 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=111.92778333 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:09 INFO 140345909798720] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:09 INFO 140345909798720] #quality_metric: host=algo-1, epoch=16, train loss <loss>=-2.30375317098\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:10 INFO 140345909798720] Epoch[17] Batch[0] avg_epoch_loss=-2.073356\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:10 INFO 140345909798720] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=-2.07335600982\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:13 INFO 140345909798720] Epoch[17] Batch[5] avg_epoch_loss=-2.032809\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:13 INFO 140345909798720] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=-2.03280893962\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:13 INFO 140345909798720] Epoch[17] Batch [5]#011Speed: 125.57 samples/sec#011loss=-2.032809\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:16 INFO 140345909798720] Epoch[17] Batch[10] avg_epoch_loss=-2.209240\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:16 INFO 140345909798720] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=-2.42095749314\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:16 INFO 140345909798720] Epoch[17] Batch [10]#011Speed: 127.48 samples/sec#011loss=-2.420957\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:16 INFO 140345909798720] processed a total of 756 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6674.269914627075, \"sum\": 6674.269914627075, \"min\": 6674.269914627075}}, \"EndTime\": 1580468296.527546, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468289.852897}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:16 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.26870802 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:16 INFO 140345909798720] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:16 INFO 140345909798720] #quality_metric: host=algo-1, epoch=17, train loss <loss>=-2.20924010031\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:17 INFO 140345909798720] Epoch[18] Batch[0] avg_epoch_loss=-1.769252\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=-1.7692524678\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:20 INFO 140345909798720] Epoch[18] Batch[5] avg_epoch_loss=-2.260857\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:20 INFO 140345909798720] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=-2.26085745322\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:20 INFO 140345909798720] Epoch[18] Batch [5]#011Speed: 126.59 samples/sec#011loss=-2.260857\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:22 INFO 140345909798720] processed a total of 697 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6129.410028457642, \"sum\": 6129.410028457642, \"min\": 6129.410028457642}}, \"EndTime\": 1580468302.657459, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468296.52763}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:22 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.70996127 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:22 INFO 140345909798720] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:22 INFO 140345909798720] #quality_metric: host=algo-1, epoch=18, train loss <loss>=-2.36601214022\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:23 INFO 140345909798720] Epoch[19] Batch[0] avg_epoch_loss=-2.125581\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=-2.12558127738\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:26 INFO 140345909798720] Epoch[19] Batch[5] avg_epoch_loss=-2.475721\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:26 INFO 140345909798720] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=-2.4757214108\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:26 INFO 140345909798720] Epoch[19] Batch [5]#011Speed: 127.62 samples/sec#011loss=-2.475721\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:29 INFO 140345909798720] Epoch[19] Batch[10] avg_epoch_loss=-2.626043\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=-2.80642832163\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:29 INFO 140345909798720] Epoch[19] Batch [10]#011Speed: 126.98 samples/sec#011loss=-2.806428\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:29 INFO 140345909798720] processed a total of 753 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6632.848024368286, \"sum\": 6632.848024368286, \"min\": 6632.848024368286}}, \"EndTime\": 1580468309.290912, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468302.657637}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:29 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.523702444 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:29 INFO 140345909798720] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=19, train loss <loss>=-2.62604273391\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:30 INFO 140345909798720] Epoch[20] Batch[0] avg_epoch_loss=-1.754070\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:30 INFO 140345909798720] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=-1.75407038508\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:33 INFO 140345909798720] Epoch[20] Batch[5] avg_epoch_loss=-2.434594\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:33 INFO 140345909798720] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=-2.43459392238\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:33 INFO 140345909798720] Epoch[20] Batch [5]#011Speed: 125.66 samples/sec#011loss=-2.434594\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:35 INFO 140345909798720] Epoch[20] Batch[10] avg_epoch_loss=-2.440826\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:35 INFO 140345909798720] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=-2.44830466606\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:35 INFO 140345909798720] Epoch[20] Batch [10]#011Speed: 127.14 samples/sec#011loss=-2.448305\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:35 INFO 140345909798720] processed a total of 747 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6657.896041870117, \"sum\": 6657.896041870117, \"min\": 6657.896041870117}}, \"EndTime\": 1580468315.949372, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468309.291}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:35 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.195553416 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:35 INFO 140345909798720] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:35 INFO 140345909798720] #quality_metric: host=algo-1, epoch=20, train loss <loss>=-2.4408260786\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:36 INFO 140345909798720] Epoch[21] Batch[0] avg_epoch_loss=-2.124524\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:36 INFO 140345909798720] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=-2.12452388454\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:39 INFO 140345909798720] Epoch[21] Batch[5] avg_epoch_loss=-2.083990\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:39 INFO 140345909798720] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=-2.08398966746\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:39 INFO 140345909798720] Epoch[21] Batch [5]#011Speed: 127.35 samples/sec#011loss=-2.083990\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:42 INFO 140345909798720] Epoch[21] Batch[10] avg_epoch_loss=-2.044270\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:42 INFO 140345909798720] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=-1.99660537307\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:42 INFO 140345909798720] Epoch[21] Batch [10]#011Speed: 126.66 samples/sec#011loss=-1.996605\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:42 INFO 140345909798720] processed a total of 751 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6669.106960296631, \"sum\": 6669.106960296631, \"min\": 6669.106960296631}}, \"EndTime\": 1580468322.619009, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468315.949454}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:42 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.606702988 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:42 INFO 140345909798720] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:42 INFO 140345909798720] #quality_metric: host=algo-1, epoch=21, train loss <loss>=-2.04426953365\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:43 INFO 140345909798720] Epoch[22] Batch[0] avg_epoch_loss=-1.954181\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:43 INFO 140345909798720] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=-1.95418094944\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:46 INFO 140345909798720] Epoch[22] Batch[5] avg_epoch_loss=-2.064866\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:46 INFO 140345909798720] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=-2.06486641824\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:46 INFO 140345909798720] Epoch[22] Batch [5]#011Speed: 126.53 samples/sec#011loss=-2.064866\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:49 INFO 140345909798720] Epoch[22] Batch[10] avg_epoch_loss=-2.221004\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=-2.40836866224\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:49 INFO 140345909798720] Epoch[22] Batch [10]#011Speed: 126.61 samples/sec#011loss=-2.408369\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:49 INFO 140345909798720] processed a total of 773 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6670.716047286987, \"sum\": 6670.716047286987, \"min\": 6670.716047286987}}, \"EndTime\": 1580468329.29024, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468322.619091}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:49 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.877493408 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:49 INFO 140345909798720] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=22, train loss <loss>=-2.22100380188\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:50 INFO 140345909798720] Epoch[23] Batch[0] avg_epoch_loss=-1.935173\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:50 INFO 140345909798720] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=-1.93517262227\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:53 INFO 140345909798720] Epoch[23] Batch[5] avg_epoch_loss=-2.356137\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:53 INFO 140345909798720] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=-2.35613690625\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:53 INFO 140345909798720] Epoch[23] Batch [5]#011Speed: 125.68 samples/sec#011loss=-2.356137\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:55 INFO 140345909798720] Epoch[23] Batch[10] avg_epoch_loss=-2.448342\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=-2.55898812784\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:55 INFO 140345909798720] Epoch[23] Batch [10]#011Speed: 127.32 samples/sec#011loss=-2.558988\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:55 INFO 140345909798720] processed a total of 766 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6659.905910491943, \"sum\": 6659.905910491943, \"min\": 6659.905910491943}}, \"EndTime\": 1580468335.950644, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468329.290322}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:55 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.014428869 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:55 INFO 140345909798720] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=23, train loss <loss>=-2.44834200697\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:56 INFO 140345909798720] Epoch[24] Batch[0] avg_epoch_loss=-2.714479\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:56 INFO 140345909798720] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=-2.71447918866\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:59 INFO 140345909798720] Epoch[24] Batch[5] avg_epoch_loss=-2.612166\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:59 INFO 140345909798720] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=-2.6121655026\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:58:59 INFO 140345909798720] Epoch[24] Batch [5]#011Speed: 124.96 samples/sec#011loss=-2.612166\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:02 INFO 140345909798720] processed a total of 740 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6130.223035812378, \"sum\": 6130.223035812378, \"min\": 6130.223035812378}}, \"EndTime\": 1580468342.081324, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468335.950732}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:02 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.710300215 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:02 INFO 140345909798720] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:02 INFO 140345909798720] #quality_metric: host=algo-1, epoch=24, train loss <loss>=-2.55547819395\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:02 INFO 140345909798720] Epoch[25] Batch[0] avg_epoch_loss=-3.081770\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:02 INFO 140345909798720] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=-3.08177020099\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:05 INFO 140345909798720] Epoch[25] Batch[5] avg_epoch_loss=-2.790071\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:05 INFO 140345909798720] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=-2.79007116094\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:05 INFO 140345909798720] Epoch[25] Batch [5]#011Speed: 127.00 samples/sec#011loss=-2.790071\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:08 INFO 140345909798720] processed a total of 723 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6073.194980621338, \"sum\": 6073.194980621338, \"min\": 6073.194980621338}}, \"EndTime\": 1580468348.155127, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468342.081438}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:08 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=119.044819927 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:08 INFO 140345909798720] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=25, train loss <loss>=-2.97454200951\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:08 INFO 140345909798720] Epoch[26] Batch[0] avg_epoch_loss=-2.242984\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=-2.24298384383\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:11 INFO 140345909798720] Epoch[26] Batch[5] avg_epoch_loss=-2.581499\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:11 INFO 140345909798720] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=-2.58149918565\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:11 INFO 140345909798720] Epoch[26] Batch [5]#011Speed: 127.89 samples/sec#011loss=-2.581499\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:14 INFO 140345909798720] processed a total of 732 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6079.864025115967, \"sum\": 6079.864025115967, \"min\": 6079.864025115967}}, \"EndTime\": 1580468354.235658, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468348.1552}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:14 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.395116043 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:14 INFO 140345909798720] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=26, train loss <loss>=-2.6656232473\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:15 INFO 140345909798720] Epoch[27] Batch[0] avg_epoch_loss=-2.240872\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:15 INFO 140345909798720] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=-2.24087173874\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:17 INFO 140345909798720] Epoch[27] Batch[5] avg_epoch_loss=-2.689464\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=-2.68946395049\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:17 INFO 140345909798720] Epoch[27] Batch [5]#011Speed: 125.52 samples/sec#011loss=-2.689464\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:20 INFO 140345909798720] processed a total of 728 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6088.536977767944, \"sum\": 6088.536977767944, \"min\": 6088.536977767944}}, \"EndTime\": 1580468360.324847, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468354.235739}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:20 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=119.566402639 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:20 INFO 140345909798720] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:20 INFO 140345909798720] #quality_metric: host=algo-1, epoch=27, train loss <loss>=-2.82984619141\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:21 INFO 140345909798720] Epoch[28] Batch[0] avg_epoch_loss=-2.768665\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:21 INFO 140345909798720] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=-2.76866459202\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:24 INFO 140345909798720] Epoch[28] Batch[5] avg_epoch_loss=-1.621788\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:24 INFO 140345909798720] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=-1.62178830198\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:24 INFO 140345909798720] Epoch[28] Batch [5]#011Speed: 125.63 samples/sec#011loss=-1.621788\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:26 INFO 140345909798720] Epoch[28] Batch[10] avg_epoch_loss=-1.792478\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:26 INFO 140345909798720] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=-1.99730535971\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:26 INFO 140345909798720] Epoch[28] Batch [10]#011Speed: 127.31 samples/sec#011loss=-1.997305\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:26 INFO 140345909798720] processed a total of 757 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6669.690847396851, \"sum\": 6669.690847396851, \"min\": 6669.690847396851}}, \"EndTime\": 1580468366.995062, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468360.324933}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:26 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.496331275 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:26 INFO 140345909798720] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:26 INFO 140345909798720] #quality_metric: host=algo-1, epoch=28, train loss <loss>=-1.79247787368\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:27 INFO 140345909798720] Epoch[29] Batch[0] avg_epoch_loss=-1.838014\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:27 INFO 140345909798720] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=-1.83801393251\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:30 INFO 140345909798720] Epoch[29] Batch[5] avg_epoch_loss=-2.004393\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:30 INFO 140345909798720] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=-2.00439281292\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:30 INFO 140345909798720] Epoch[29] Batch [5]#011Speed: 125.78 samples/sec#011loss=-2.004393\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:33 INFO 140345909798720] processed a total of 698 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6166.695833206177, \"sum\": 6166.695833206177, \"min\": 6166.695833206177}}, \"EndTime\": 1580468373.16226, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468366.99515}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:33 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.186045725 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:33 INFO 140345909798720] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:33 INFO 140345909798720] #quality_metric: host=algo-1, epoch=29, train loss <loss>=-2.14981978133\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:33 INFO 140345909798720] Epoch[30] Batch[0] avg_epoch_loss=-2.529392\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:33 INFO 140345909798720] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=-2.52939152073\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:36 INFO 140345909798720] Epoch[30] Batch[5] avg_epoch_loss=-2.604833\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:36 INFO 140345909798720] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=-2.60483252036\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:36 INFO 140345909798720] Epoch[30] Batch [5]#011Speed: 127.95 samples/sec#011loss=-2.604833\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:39 INFO 140345909798720] processed a total of 712 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6045.323848724365, \"sum\": 6045.323848724365, \"min\": 6045.323848724365}}, \"EndTime\": 1580468379.208244, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468373.16233}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:39 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.774501961 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:39 INFO 140345909798720] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:39 INFO 140345909798720] #quality_metric: host=algo-1, epoch=30, train loss <loss>=-2.5894309379\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:40 INFO 140345909798720] Epoch[31] Batch[0] avg_epoch_loss=-2.442360\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:40 INFO 140345909798720] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=-2.44236013052\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:42 INFO 140345909798720] Epoch[31] Batch[5] avg_epoch_loss=-2.630941\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:42 INFO 140345909798720] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=-2.63094058338\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:42 INFO 140345909798720] Epoch[31] Batch [5]#011Speed: 125.93 samples/sec#011loss=-2.630941\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:45 INFO 140345909798720] processed a total of 704 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6076.333045959473, \"sum\": 6076.333045959473, \"min\": 6076.333045959473}}, \"EndTime\": 1580468385.285224, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468379.208329}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:45 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.856741133 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:45 INFO 140345909798720] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=31, train loss <loss>=-2.70993017248\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:46 INFO 140345909798720] Epoch[32] Batch[0] avg_epoch_loss=-2.523383\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:46 INFO 140345909798720] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=-2.52338347564\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:49 INFO 140345909798720] Epoch[32] Batch[5] avg_epoch_loss=-2.815407\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=-2.81540721172\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:49 INFO 140345909798720] Epoch[32] Batch [5]#011Speed: 125.63 samples/sec#011loss=-2.815407\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:51 INFO 140345909798720] Epoch[32] Batch[10] avg_epoch_loss=-2.884435\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:51 INFO 140345909798720] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=-2.96726804166\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:51 INFO 140345909798720] Epoch[32] Batch [10]#011Speed: 128.01 samples/sec#011loss=-2.967268\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:51 INFO 140345909798720] processed a total of 749 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6646.795988082886, \"sum\": 6646.795988082886, \"min\": 6646.795988082886}}, \"EndTime\": 1580468391.932528, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468385.285309}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:51 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.683685027 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:51 INFO 140345909798720] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:51 INFO 140345909798720] #quality_metric: host=algo-1, epoch=32, train loss <loss>=-2.88443486169\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:52 INFO 140345909798720] Epoch[33] Batch[0] avg_epoch_loss=-2.784629\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:52 INFO 140345909798720] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=-2.78462920318\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:55 INFO 140345909798720] Epoch[33] Batch[5] avg_epoch_loss=-2.576813\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=-2.57681274414\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:55 INFO 140345909798720] Epoch[33] Batch [5]#011Speed: 126.54 samples/sec#011loss=-2.576813\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:58 INFO 140345909798720] processed a total of 728 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6123.993873596191, \"sum\": 6123.993873596191, \"min\": 6123.993873596191}}, \"EndTime\": 1580468398.056993, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468391.932616}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:58 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.873967453 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:58 INFO 140345909798720] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:58 INFO 140345909798720] #quality_metric: host=algo-1, epoch=33, train loss <loss>=-2.55257370408\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:58 INFO 140345909798720] Epoch[34] Batch[0] avg_epoch_loss=-3.004020\u001b[0m\n",
      "\u001b[34m[01/31/2020 10:59:58 INFO 140345909798720] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=-3.00401965992\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:01 INFO 140345909798720] Epoch[34] Batch[5] avg_epoch_loss=-2.627071\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:01 INFO 140345909798720] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=-2.62707127752\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:01 INFO 140345909798720] Epoch[34] Batch [5]#011Speed: 123.44 samples/sec#011loss=-2.627071\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:04 INFO 140345909798720] Epoch[34] Batch[10] avg_epoch_loss=-2.546921\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:04 INFO 140345909798720] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=-2.45074170087\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:04 INFO 140345909798720] Epoch[34] Batch [10]#011Speed: 125.91 samples/sec#011loss=-2.450742\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:04 INFO 140345909798720] processed a total of 769 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6763.4241580963135, \"sum\": 6763.4241580963135, \"min\": 6763.4241580963135}}, \"EndTime\": 1580468404.821029, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468398.057089}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:04 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.69757139 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:04 INFO 140345909798720] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:04 INFO 140345909798720] #quality_metric: host=algo-1, epoch=34, train loss <loss>=-2.54692146995\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:05 INFO 140345909798720] Epoch[35] Batch[0] avg_epoch_loss=-2.322181\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:05 INFO 140345909798720] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=-2.32218149546\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:08 INFO 140345909798720] Epoch[35] Batch[5] avg_epoch_loss=-2.559382\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=-2.55938150217\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:08 INFO 140345909798720] Epoch[35] Batch [5]#011Speed: 124.47 samples/sec#011loss=-2.559382\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:10 INFO 140345909798720] processed a total of 736 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6104.604005813599, \"sum\": 6104.604005813599, \"min\": 6104.604005813599}}, \"EndTime\": 1580468410.926197, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468404.821121}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:10 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.561958068 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:10 INFO 140345909798720] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:10 INFO 140345909798720] #quality_metric: host=algo-1, epoch=35, train loss <loss>=-2.63303418546\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:11 INFO 140345909798720] Epoch[36] Batch[0] avg_epoch_loss=-3.183611\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:11 INFO 140345909798720] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=-3.18361148319\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:14 INFO 140345909798720] Epoch[36] Batch[5] avg_epoch_loss=-2.755253\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=-2.75525263193\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:14 INFO 140345909798720] Epoch[36] Batch [5]#011Speed: 126.11 samples/sec#011loss=-2.755253\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:17 INFO 140345909798720] processed a total of 735 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6114.376068115234, \"sum\": 6114.376068115234, \"min\": 6114.376068115234}}, \"EndTime\": 1580468417.041086, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468410.926294}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:17 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.205949467 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:17 INFO 140345909798720] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=36, train loss <loss>=-2.83505799577\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:17 INFO 140345909798720] Epoch[37] Batch[0] avg_epoch_loss=-3.390916\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=-3.39091574179\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:20 INFO 140345909798720] Epoch[37] Batch[5] avg_epoch_loss=-3.092415\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:20 INFO 140345909798720] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=-3.09241471849\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:20 INFO 140345909798720] Epoch[37] Batch [5]#011Speed: 126.86 samples/sec#011loss=-3.092415\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:23 INFO 140345909798720] Epoch[37] Batch[10] avg_epoch_loss=-2.875223\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=-2.61459387702\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:23 INFO 140345909798720] Epoch[37] Batch [10]#011Speed: 126.62 samples/sec#011loss=-2.614594\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:23 INFO 140345909798720] processed a total of 753 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6698.215007781982, \"sum\": 6698.215007781982, \"min\": 6698.215007781982}}, \"EndTime\": 1580468423.73991, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468417.041175}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:23 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.41577698 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:23 INFO 140345909798720] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=37, train loss <loss>=-2.87522342691\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:24 INFO 140345909798720] Epoch[38] Batch[0] avg_epoch_loss=-2.698211\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:24 INFO 140345909798720] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=-2.69821125752\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:27 INFO 140345909798720] Epoch[38] Batch[5] avg_epoch_loss=-2.765953\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:27 INFO 140345909798720] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=-2.76595258283\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:27 INFO 140345909798720] Epoch[38] Batch [5]#011Speed: 126.52 samples/sec#011loss=-2.765953\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:30 INFO 140345909798720] Epoch[38] Batch[10] avg_epoch_loss=-2.959095\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:30 INFO 140345909798720] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=-3.19086650127\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:30 INFO 140345909798720] Epoch[38] Batch [10]#011Speed: 125.47 samples/sec#011loss=-3.190867\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:30 INFO 140345909798720] processed a total of 787 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6684.206008911133, \"sum\": 6684.206008911133, \"min\": 6684.206008911133}}, \"EndTime\": 1580468430.424634, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468423.740002}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:30 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.738053265 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:30 INFO 140345909798720] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:30 INFO 140345909798720] #quality_metric: host=algo-1, epoch=38, train loss <loss>=-2.95909527303\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:31 INFO 140345909798720] Epoch[39] Batch[0] avg_epoch_loss=-3.060735\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:31 INFO 140345909798720] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=-3.06073534166\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:34 INFO 140345909798720] Epoch[39] Batch[5] avg_epoch_loss=-2.946875\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:34 INFO 140345909798720] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=-2.94687501375\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:34 INFO 140345909798720] Epoch[39] Batch [5]#011Speed: 121.04 samples/sec#011loss=-2.946875\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:36 INFO 140345909798720] processed a total of 726 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6195.541858673096, \"sum\": 6195.541858673096, \"min\": 6195.541858673096}}, \"EndTime\": 1580468436.620612, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468430.42472}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:36 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.178878358 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:36 INFO 140345909798720] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:36 INFO 140345909798720] #quality_metric: host=algo-1, epoch=39, train loss <loss>=-2.99397187104\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:37 INFO 140345909798720] Epoch[40] Batch[0] avg_epoch_loss=-2.855111\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:37 INFO 140345909798720] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=-2.85511058086\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:40 INFO 140345909798720] Epoch[40] Batch[5] avg_epoch_loss=-3.060267\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:40 INFO 140345909798720] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=-3.06026688997\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:40 INFO 140345909798720] Epoch[40] Batch [5]#011Speed: 126.20 samples/sec#011loss=-3.060267\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:43 INFO 140345909798720] Epoch[40] Batch[10] avg_epoch_loss=-2.790147\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:43 INFO 140345909798720] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=-2.46600319115\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:43 INFO 140345909798720] Epoch[40] Batch [10]#011Speed: 127.32 samples/sec#011loss=-2.466003\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:43 INFO 140345909798720] processed a total of 756 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6652.264833450317, \"sum\": 6652.264833450317, \"min\": 6652.264833450317}}, \"EndTime\": 1580468443.273405, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468436.620684}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:43 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.643485331 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:43 INFO 140345909798720] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:43 INFO 140345909798720] #quality_metric: host=algo-1, epoch=40, train loss <loss>=-2.79014702687\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:44 INFO 140345909798720] Epoch[41] Batch[0] avg_epoch_loss=-2.973937\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:44 INFO 140345909798720] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=-2.97393654488\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:46 INFO 140345909798720] Epoch[41] Batch[5] avg_epoch_loss=-2.941757\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:46 INFO 140345909798720] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=-2.94175733962\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:46 INFO 140345909798720] Epoch[41] Batch [5]#011Speed: 127.77 samples/sec#011loss=-2.941757\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:49 INFO 140345909798720] processed a total of 734 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6057.546138763428, \"sum\": 6057.546138763428, \"min\": 6057.546138763428}}, \"EndTime\": 1580468449.331509, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468443.273487}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:49 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=121.16878369 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:49 INFO 140345909798720] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=41, train loss <loss>=-2.91299411671\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:50 INFO 140345909798720] Epoch[42] Batch[0] avg_epoch_loss=-2.364232\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:50 INFO 140345909798720] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=-2.36423244992\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:53 INFO 140345909798720] Epoch[42] Batch[5] avg_epoch_loss=-2.950466\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:53 INFO 140345909798720] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=-2.95046588107\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:53 INFO 140345909798720] Epoch[42] Batch [5]#011Speed: 126.19 samples/sec#011loss=-2.950466\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:55 INFO 140345909798720] processed a total of 725 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6043.938875198364, \"sum\": 6043.938875198364, \"min\": 6043.938875198364}}, \"EndTime\": 1580468455.37594, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468449.331583}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:55 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=119.952383067 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:55 INFO 140345909798720] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=42, train loss <loss>=-3.06561203003\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:56 INFO 140345909798720] Epoch[43] Batch[0] avg_epoch_loss=-3.167375\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:56 INFO 140345909798720] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=-3.16737530683\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:59 INFO 140345909798720] Epoch[43] Batch[5] avg_epoch_loss=-3.055364\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:59 INFO 140345909798720] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=-3.05536424791\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:00:59 INFO 140345909798720] Epoch[43] Batch [5]#011Speed: 126.98 samples/sec#011loss=-3.055364\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:01 INFO 140345909798720] processed a total of 707 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6027.7440547943115, \"sum\": 6027.7440547943115, \"min\": 6027.7440547943115}}, \"EndTime\": 1580468461.404239, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468455.376025}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:01 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.288431871 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:01 INFO 140345909798720] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:01 INFO 140345909798720] #quality_metric: host=algo-1, epoch=43, train loss <loss>=-2.94621810913\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:02 INFO 140345909798720] Epoch[44] Batch[0] avg_epoch_loss=-2.430809\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:02 INFO 140345909798720] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=-2.4308092272\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:05 INFO 140345909798720] Epoch[44] Batch[5] avg_epoch_loss=-2.770917\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:05 INFO 140345909798720] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=-2.77091663807\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:05 INFO 140345909798720] Epoch[44] Batch [5]#011Speed: 127.13 samples/sec#011loss=-2.770917\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:07 INFO 140345909798720] processed a total of 723 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6109.779119491577, \"sum\": 6109.779119491577, \"min\": 6109.779119491577}}, \"EndTime\": 1580468467.514577, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468461.404329}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:07 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.33262081 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:07 INFO 140345909798720] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:07 INFO 140345909798720] #quality_metric: host=algo-1, epoch=44, train loss <loss>=-2.84366937586\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:08 INFO 140345909798720] Epoch[45] Batch[0] avg_epoch_loss=-2.905671\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=-2.90567140321\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:11 INFO 140345909798720] Epoch[45] Batch[5] avg_epoch_loss=-3.004435\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:11 INFO 140345909798720] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=-3.00443549629\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:11 INFO 140345909798720] Epoch[45] Batch [5]#011Speed: 127.82 samples/sec#011loss=-3.004435\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:14 INFO 140345909798720] Epoch[45] Batch[10] avg_epoch_loss=-3.288880\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=-3.63021330962\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:14 INFO 140345909798720] Epoch[45] Batch [10]#011Speed: 126.08 samples/sec#011loss=-3.630213\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:14 INFO 140345909798720] processed a total of 769 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6694.4420337677, \"sum\": 6694.4420337677, \"min\": 6694.4420337677}}, \"EndTime\": 1580468474.209636, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468467.514657}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:14 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.868681976 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:14 INFO 140345909798720] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=45, train loss <loss>=-3.28887995689\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:15 INFO 140345909798720] Epoch[46] Batch[0] avg_epoch_loss=-2.927279\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:15 INFO 140345909798720] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=-2.92727908573\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:17 INFO 140345909798720] Epoch[46] Batch[5] avg_epoch_loss=-3.049838\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=-3.04983843554\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:17 INFO 140345909798720] Epoch[46] Batch [5]#011Speed: 126.10 samples/sec#011loss=-3.049838\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:20 INFO 140345909798720] Epoch[46] Batch[10] avg_epoch_loss=-3.282721\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:20 INFO 140345909798720] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=-3.56217964791\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:20 INFO 140345909798720] Epoch[46] Batch [10]#011Speed: 121.95 samples/sec#011loss=-3.562180\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:20 INFO 140345909798720] processed a total of 763 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6776.240110397339, \"sum\": 6776.240110397339, \"min\": 6776.240110397339}}, \"EndTime\": 1580468480.986707, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468474.209731}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:20 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.597140823 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:20 INFO 140345909798720] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:20 INFO 140345909798720] #quality_metric: host=algo-1, epoch=46, train loss <loss>=-3.2827208048\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:21 INFO 140345909798720] Epoch[47] Batch[0] avg_epoch_loss=-3.066391\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:21 INFO 140345909798720] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=-3.06639057881\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:24 INFO 140345909798720] Epoch[47] Batch[5] avg_epoch_loss=-3.227482\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:24 INFO 140345909798720] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=-3.22748201387\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:24 INFO 140345909798720] Epoch[47] Batch [5]#011Speed: 126.82 samples/sec#011loss=-3.227482\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:27 INFO 140345909798720] Epoch[47] Batch[10] avg_epoch_loss=-3.236842\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:27 INFO 140345909798720] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=-3.24807396966\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:27 INFO 140345909798720] Epoch[47] Batch [10]#011Speed: 127.80 samples/sec#011loss=-3.248074\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:27 INFO 140345909798720] processed a total of 759 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6704.813003540039, \"sum\": 6704.813003540039, \"min\": 6704.813003540039}}, \"EndTime\": 1580468487.69209, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468480.986797}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:27 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.200152988 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:27 INFO 140345909798720] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:27 INFO 140345909798720] #quality_metric: host=algo-1, epoch=47, train loss <loss>=-3.23684199378\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:28 INFO 140345909798720] Epoch[48] Batch[0] avg_epoch_loss=-2.398284\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:28 INFO 140345909798720] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=-2.39828449971\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:31 INFO 140345909798720] Epoch[48] Batch[5] avg_epoch_loss=-2.526266\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:31 INFO 140345909798720] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=-2.52626577154\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:31 INFO 140345909798720] Epoch[48] Batch [5]#011Speed: 126.35 samples/sec#011loss=-2.526266\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:33 INFO 140345909798720] processed a total of 732 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6076.531887054443, \"sum\": 6076.531887054443, \"min\": 6076.531887054443}}, \"EndTime\": 1580468493.769148, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468487.692177}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:33 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.46088909 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:33 INFO 140345909798720] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:33 INFO 140345909798720] #quality_metric: host=algo-1, epoch=48, train loss <loss>=-2.58455218753\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:34 INFO 140345909798720] Epoch[49] Batch[0] avg_epoch_loss=-2.974250\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:34 INFO 140345909798720] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=-2.97425038106\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:37 INFO 140345909798720] Epoch[49] Batch[5] avg_epoch_loss=-3.031220\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:37 INFO 140345909798720] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=-3.03121958552\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:37 INFO 140345909798720] Epoch[49] Batch [5]#011Speed: 127.77 samples/sec#011loss=-3.031220\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:39 INFO 140345909798720] processed a total of 717 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6062.361001968384, \"sum\": 6062.361001968384, \"min\": 6062.361001968384}}, \"EndTime\": 1580468499.832018, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468493.769234}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:39 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.266655225 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:39 INFO 140345909798720] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:39 INFO 140345909798720] #quality_metric: host=algo-1, epoch=49, train loss <loss>=-3.04490236849\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:40 INFO 140345909798720] Epoch[50] Batch[0] avg_epoch_loss=-3.189043\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:40 INFO 140345909798720] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=-3.18904258109\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:43 INFO 140345909798720] Epoch[50] Batch[5] avg_epoch_loss=-3.276276\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:43 INFO 140345909798720] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=-3.2762760128\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:43 INFO 140345909798720] Epoch[50] Batch [5]#011Speed: 126.91 samples/sec#011loss=-3.276276\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:45 INFO 140345909798720] processed a total of 714 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6108.713865280151, \"sum\": 6108.713865280151, \"min\": 6108.713865280151}}, \"EndTime\": 1580468505.941372, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468499.83211}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:45 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.879741335 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:45 INFO 140345909798720] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=50, train loss <loss>=-3.27683616844\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:46 INFO 140345909798720] Epoch[51] Batch[0] avg_epoch_loss=-2.061718\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:46 INFO 140345909798720] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=-2.06171809016\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:49 INFO 140345909798720] Epoch[51] Batch[5] avg_epoch_loss=-2.726020\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=-2.72601961016\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:49 INFO 140345909798720] Epoch[51] Batch [5]#011Speed: 127.12 samples/sec#011loss=-2.726020\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:52 INFO 140345909798720] Epoch[51] Batch[10] avg_epoch_loss=-3.018252\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:52 INFO 140345909798720] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=-3.36893145587\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:52 INFO 140345909798720] Epoch[51] Batch [10]#011Speed: 127.54 samples/sec#011loss=-3.368931\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:52 INFO 140345909798720] processed a total of 752 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6642.235994338989, \"sum\": 6642.235994338989, \"min\": 6642.235994338989}}, \"EndTime\": 1580468512.584127, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468505.941461}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:52 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.212721423 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:52 INFO 140345909798720] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:52 INFO 140345909798720] #quality_metric: host=algo-1, epoch=51, train loss <loss>=-3.0182522673\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:53 INFO 140345909798720] Epoch[52] Batch[0] avg_epoch_loss=-2.287739\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:53 INFO 140345909798720] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=-2.28773869695\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:56 INFO 140345909798720] Epoch[52] Batch[5] avg_epoch_loss=-2.604277\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:56 INFO 140345909798720] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=-2.60427657119\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:56 INFO 140345909798720] Epoch[52] Batch [5]#011Speed: 125.70 samples/sec#011loss=-2.604277\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:59 INFO 140345909798720] Epoch[52] Batch[10] avg_epoch_loss=-2.654395\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:59 INFO 140345909798720] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=-2.71453723392\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:59 INFO 140345909798720] Epoch[52] Batch [10]#011Speed: 127.75 samples/sec#011loss=-2.714537\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:59 INFO 140345909798720] processed a total of 759 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6680.124044418335, \"sum\": 6680.124044418335, \"min\": 6680.124044418335}}, \"EndTime\": 1580468519.264708, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468512.584217}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:59 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.618057448 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:59 INFO 140345909798720] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:01:59 INFO 140345909798720] #quality_metric: host=algo-1, epoch=52, train loss <loss>=-2.65439505425\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:00 INFO 140345909798720] Epoch[53] Batch[0] avg_epoch_loss=-3.022624\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:00 INFO 140345909798720] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=-3.02262383538\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:03 INFO 140345909798720] Epoch[53] Batch[5] avg_epoch_loss=-3.192672\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:03 INFO 140345909798720] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=-3.19267231709\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:03 INFO 140345909798720] Epoch[53] Batch [5]#011Speed: 125.20 samples/sec#011loss=-3.192672\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:05 INFO 140345909798720] processed a total of 700 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6201.470851898193, \"sum\": 6201.470851898193, \"min\": 6201.470851898193}}, \"EndTime\": 1580468525.466691, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468519.264818}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:05 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.874095646 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:05 INFO 140345909798720] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:05 INFO 140345909798720] #quality_metric: host=algo-1, epoch=53, train loss <loss>=-3.13751849613\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:06 INFO 140345909798720] Epoch[54] Batch[0] avg_epoch_loss=-0.870370\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:06 INFO 140345909798720] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=-0.870370297819\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:09 INFO 140345909798720] Epoch[54] Batch[5] avg_epoch_loss=-2.127253\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:09 INFO 140345909798720] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=-2.12725278494\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:09 INFO 140345909798720] Epoch[54] Batch [5]#011Speed: 126.42 samples/sec#011loss=-2.127253\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:11 INFO 140345909798720] processed a total of 700 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6127.403020858765, \"sum\": 6127.403020858765, \"min\": 6127.403020858765}}, \"EndTime\": 1580468531.594655, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468525.466777}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:11 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.238862771 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:11 INFO 140345909798720] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:11 INFO 140345909798720] #quality_metric: host=algo-1, epoch=54, train loss <loss>=-2.43636448834\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:12 INFO 140345909798720] Epoch[55] Batch[0] avg_epoch_loss=-2.324858\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:12 INFO 140345909798720] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=-2.32485817574\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:15 INFO 140345909798720] Epoch[55] Batch[5] avg_epoch_loss=-2.477198\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:15 INFO 140345909798720] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=-2.47719807668\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:15 INFO 140345909798720] Epoch[55] Batch [5]#011Speed: 126.05 samples/sec#011loss=-2.477198\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:17 INFO 140345909798720] processed a total of 724 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6068.511009216309, \"sum\": 6068.511009216309, \"min\": 6068.511009216309}}, \"EndTime\": 1580468537.663658, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468531.594722}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:17 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=119.302106687 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:17 INFO 140345909798720] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=55, train loss <loss>=-2.52103520986\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:18 INFO 140345909798720] Epoch[56] Batch[0] avg_epoch_loss=-2.938991\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:18 INFO 140345909798720] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=-2.93899103113\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:21 INFO 140345909798720] Epoch[56] Batch[5] avg_epoch_loss=-3.107033\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:21 INFO 140345909798720] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=-3.10703287898\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:21 INFO 140345909798720] Epoch[56] Batch [5]#011Speed: 125.98 samples/sec#011loss=-3.107033\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:23 INFO 140345909798720] processed a total of 694 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6076.508045196533, \"sum\": 6076.508045196533, \"min\": 6076.508045196533}}, \"EndTime\": 1580468543.740785, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468537.663737}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:23 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.207683486 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:23 INFO 140345909798720] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=56, train loss <loss>=-2.9012020008\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:24 INFO 140345909798720] Epoch[57] Batch[0] avg_epoch_loss=-3.204637\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:24 INFO 140345909798720] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=-3.20463747592\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:27 INFO 140345909798720] Epoch[57] Batch[5] avg_epoch_loss=-3.278758\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:27 INFO 140345909798720] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=-3.27875793732\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:27 INFO 140345909798720] Epoch[57] Batch [5]#011Speed: 126.67 samples/sec#011loss=-3.278758\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:29 INFO 140345909798720] processed a total of 716 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6084.136962890625, \"sum\": 6084.136962890625, \"min\": 6084.136962890625}}, \"EndTime\": 1580468549.825542, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468543.74088}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:29 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.680224645 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:29 INFO 140345909798720] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=57, train loss <loss>=-3.32976117521\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:30 INFO 140345909798720] Epoch[58] Batch[0] avg_epoch_loss=-2.390749\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:30 INFO 140345909798720] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=-2.39074933851\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:33 INFO 140345909798720] Epoch[58] Batch[5] avg_epoch_loss=-2.879757\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:33 INFO 140345909798720] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=-2.87975716806\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:33 INFO 140345909798720] Epoch[58] Batch [5]#011Speed: 127.06 samples/sec#011loss=-2.879757\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:36 INFO 140345909798720] Epoch[58] Batch[10] avg_epoch_loss=-2.934598\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:36 INFO 140345909798720] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=-3.00040798703\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:36 INFO 140345909798720] Epoch[58] Batch [10]#011Speed: 123.92 samples/sec#011loss=-3.000408\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:36 INFO 140345909798720] processed a total of 758 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6718.448877334595, \"sum\": 6718.448877334595, \"min\": 6718.448877334595}}, \"EndTime\": 1580468556.544674, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468549.825618}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:36 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.821106851 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:36 INFO 140345909798720] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:36 INFO 140345909798720] #quality_metric: host=algo-1, epoch=58, train loss <loss>=-2.93459844941\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:37 INFO 140345909798720] Epoch[59] Batch[0] avg_epoch_loss=-3.130422\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:37 INFO 140345909798720] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=-3.13042181891\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:40 INFO 140345909798720] Epoch[59] Batch[5] avg_epoch_loss=-3.049010\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:40 INFO 140345909798720] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=-3.04901019947\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:40 INFO 140345909798720] Epoch[59] Batch [5]#011Speed: 126.06 samples/sec#011loss=-3.049010\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:43 INFO 140345909798720] Epoch[59] Batch[10] avg_epoch_loss=-3.063885\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:43 INFO 140345909798720] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=-3.08173395105\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:43 INFO 140345909798720] Epoch[59] Batch [10]#011Speed: 127.31 samples/sec#011loss=-3.081734\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:43 INFO 140345909798720] processed a total of 769 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6658.216953277588, \"sum\": 6658.216953277588, \"min\": 6658.216953277588}}, \"EndTime\": 1580468563.203498, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468556.544762}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:43 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.493839161 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:43 INFO 140345909798720] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:43 INFO 140345909798720] #quality_metric: host=algo-1, epoch=59, train loss <loss>=-3.06388463201\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:44 INFO 140345909798720] Epoch[60] Batch[0] avg_epoch_loss=-2.032461\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:44 INFO 140345909798720] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=-2.03246059933\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:46 INFO 140345909798720] Epoch[60] Batch[5] avg_epoch_loss=-2.712193\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:46 INFO 140345909798720] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=-2.71219250103\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:46 INFO 140345909798720] Epoch[60] Batch [5]#011Speed: 125.10 samples/sec#011loss=-2.712193\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:49 INFO 140345909798720] Epoch[60] Batch[10] avg_epoch_loss=-2.922660\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=-3.17522088128\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:49 INFO 140345909798720] Epoch[60] Batch [10]#011Speed: 127.78 samples/sec#011loss=-3.175221\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:49 INFO 140345909798720] processed a total of 756 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6689.832925796509, \"sum\": 6689.832925796509, \"min\": 6689.832925796509}}, \"EndTime\": 1580468569.893795, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468563.203588}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:49 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.005075349 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:49 INFO 140345909798720] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=60, train loss <loss>=-2.9226599466\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:50 INFO 140345909798720] Epoch[61] Batch[0] avg_epoch_loss=-2.801522\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:50 INFO 140345909798720] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=-2.80152171367\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:53 INFO 140345909798720] Epoch[61] Batch[5] avg_epoch_loss=-3.031083\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:53 INFO 140345909798720] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=-3.03108349362\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:53 INFO 140345909798720] Epoch[61] Batch [5]#011Speed: 126.71 samples/sec#011loss=-3.031083\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:56 INFO 140345909798720] Epoch[61] Batch[10] avg_epoch_loss=-3.335732\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:56 INFO 140345909798720] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=-3.70131015262\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:56 INFO 140345909798720] Epoch[61] Batch [10]#011Speed: 126.82 samples/sec#011loss=-3.701310\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:56 INFO 140345909798720] processed a total of 741 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6678.927898406982, \"sum\": 6678.927898406982, \"min\": 6678.927898406982}}, \"EndTime\": 1580468576.573254, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468569.893884}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:56 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=110.943791495 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:56 INFO 140345909798720] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:56 INFO 140345909798720] #quality_metric: host=algo-1, epoch=61, train loss <loss>=-3.33573197498\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:57 INFO 140345909798720] Epoch[62] Batch[0] avg_epoch_loss=-2.735600\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:02:57 INFO 140345909798720] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=-2.73559982712\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:00 INFO 140345909798720] Epoch[62] Batch[5] avg_epoch_loss=-3.258293\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:00 INFO 140345909798720] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=-3.25829342679\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:00 INFO 140345909798720] Epoch[62] Batch [5]#011Speed: 126.48 samples/sec#011loss=-3.258293\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:03 INFO 140345909798720] Epoch[62] Batch[10] avg_epoch_loss=-3.312232\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:03 INFO 140345909798720] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=-3.37695881612\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:03 INFO 140345909798720] Epoch[62] Batch [10]#011Speed: 126.64 samples/sec#011loss=-3.376959\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:03 INFO 140345909798720] processed a total of 772 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6682.106971740723, \"sum\": 6682.106971740723, \"min\": 6682.106971740723}}, \"EndTime\": 1580468583.25588, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468576.573344}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:03 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.5300514 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:03 INFO 140345909798720] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:03 INFO 140345909798720] #quality_metric: host=algo-1, epoch=62, train loss <loss>=-3.31223224012\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:04 INFO 140345909798720] Epoch[63] Batch[0] avg_epoch_loss=-2.887181\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:04 INFO 140345909798720] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=-2.88718146247\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:07 INFO 140345909798720] Epoch[63] Batch[5] avg_epoch_loss=-3.150866\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:07 INFO 140345909798720] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=-3.15086601876\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:07 INFO 140345909798720] Epoch[63] Batch [5]#011Speed: 125.35 samples/sec#011loss=-3.150866\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:09 INFO 140345909798720] processed a total of 691 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6075.824975967407, \"sum\": 6075.824975967407, \"min\": 6075.824975967407}}, \"EndTime\": 1580468589.33224, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468583.255972}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:09 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.727055371 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:09 INFO 140345909798720] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:09 INFO 140345909798720] #quality_metric: host=algo-1, epoch=63, train loss <loss>=-3.22934281633\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:10 INFO 140345909798720] Epoch[64] Batch[0] avg_epoch_loss=-3.187120\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:10 INFO 140345909798720] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=-3.18712017987\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:13 INFO 140345909798720] Epoch[64] Batch[5] avg_epoch_loss=-3.262459\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:13 INFO 140345909798720] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=-3.2624594886\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:13 INFO 140345909798720] Epoch[64] Batch [5]#011Speed: 126.89 samples/sec#011loss=-3.262459\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:15 INFO 140345909798720] processed a total of 723 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6118.399143218994, \"sum\": 6118.399143218994, \"min\": 6118.399143218994}}, \"EndTime\": 1580468595.451137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468589.332326}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:15 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.166139043 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:15 INFO 140345909798720] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:15 INFO 140345909798720] #quality_metric: host=algo-1, epoch=64, train loss <loss>=-3.35442525503\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:16 INFO 140345909798720] Epoch[65] Batch[0] avg_epoch_loss=-3.389103\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:16 INFO 140345909798720] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=-3.38910324509\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:19 INFO 140345909798720] Epoch[65] Batch[5] avg_epoch_loss=-3.331127\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:19 INFO 140345909798720] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=-3.33112713238\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:19 INFO 140345909798720] Epoch[65] Batch [5]#011Speed: 126.66 samples/sec#011loss=-3.331127\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:22 INFO 140345909798720] Epoch[65] Batch[10] avg_epoch_loss=-3.324918\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:22 INFO 140345909798720] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=-3.31746809676\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:22 INFO 140345909798720] Epoch[65] Batch [10]#011Speed: 126.15 samples/sec#011loss=-3.317468\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:22 INFO 140345909798720] processed a total of 800 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6671.244859695435, \"sum\": 6671.244859695435, \"min\": 6671.244859695435}}, \"EndTime\": 1580468602.122867, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468595.451204}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:22 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=119.915309161 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:22 INFO 140345909798720] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:22 INFO 140345909798720] #quality_metric: host=algo-1, epoch=65, train loss <loss>=-3.32491847983\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:22 INFO 140345909798720] Epoch[66] Batch[0] avg_epoch_loss=-3.795170\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:22 INFO 140345909798720] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=-3.79516972722\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:25 INFO 140345909798720] Epoch[66] Batch[5] avg_epoch_loss=-3.508692\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:25 INFO 140345909798720] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=-3.50869156434\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:25 INFO 140345909798720] Epoch[66] Batch [5]#011Speed: 125.66 samples/sec#011loss=-3.508692\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:28 INFO 140345909798720] Epoch[66] Batch[10] avg_epoch_loss=-3.260315\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:28 INFO 140345909798720] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=-2.96226390117\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:28 INFO 140345909798720] Epoch[66] Batch [10]#011Speed: 127.78 samples/sec#011loss=-2.962264\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:28 INFO 140345909798720] processed a total of 747 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6649.125099182129, \"sum\": 6649.125099182129, \"min\": 6649.125099182129}}, \"EndTime\": 1580468608.772458, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468602.122956}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:28 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.34322698 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:28 INFO 140345909798720] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:28 INFO 140345909798720] #quality_metric: host=algo-1, epoch=66, train loss <loss>=-3.26031535381\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:29 INFO 140345909798720] Epoch[67] Batch[0] avg_epoch_loss=-2.195136\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=-2.19513578673\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:32 INFO 140345909798720] Epoch[67] Batch[5] avg_epoch_loss=-2.509880\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=-2.50987958478\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:32 INFO 140345909798720] Epoch[67] Batch [5]#011Speed: 125.18 samples/sec#011loss=-2.509880\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:34 INFO 140345909798720] processed a total of 728 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6095.329999923706, \"sum\": 6095.329999923706, \"min\": 6095.329999923706}}, \"EndTime\": 1580468614.868363, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468608.772556}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:34 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=119.432583178 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:34 INFO 140345909798720] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:34 INFO 140345909798720] #quality_metric: host=algo-1, epoch=67, train loss <loss>=-2.57161671407\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:35 INFO 140345909798720] Epoch[68] Batch[0] avg_epoch_loss=-2.613342\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:35 INFO 140345909798720] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=-2.61334166656\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:38 INFO 140345909798720] Epoch[68] Batch[5] avg_epoch_loss=-2.854930\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:38 INFO 140345909798720] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=-2.85493025909\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:38 INFO 140345909798720] Epoch[68] Batch [5]#011Speed: 127.09 samples/sec#011loss=-2.854930\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:41 INFO 140345909798720] Epoch[68] Batch[10] avg_epoch_loss=-2.990826\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:41 INFO 140345909798720] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=-3.1539008888\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:41 INFO 140345909798720] Epoch[68] Batch [10]#011Speed: 126.67 samples/sec#011loss=-3.153901\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:41 INFO 140345909798720] processed a total of 747 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6669.277906417847, \"sum\": 6669.277906417847, \"min\": 6669.277906417847}}, \"EndTime\": 1580468621.538293, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468614.868451}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:41 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.003558209 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:41 INFO 140345909798720] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:41 INFO 140345909798720] #quality_metric: host=algo-1, epoch=68, train loss <loss>=-2.99082599987\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:42 INFO 140345909798720] Epoch[69] Batch[0] avg_epoch_loss=-3.504627\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:42 INFO 140345909798720] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=-3.50462712468\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:45 INFO 140345909798720] Epoch[69] Batch[5] avg_epoch_loss=-3.321962\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=-3.32196209882\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:45 INFO 140345909798720] Epoch[69] Batch [5]#011Speed: 126.90 samples/sec#011loss=-3.321962\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:48 INFO 140345909798720] Epoch[69] Batch[10] avg_epoch_loss=-3.334856\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=-3.35032806396\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:48 INFO 140345909798720] Epoch[69] Batch [10]#011Speed: 127.60 samples/sec#011loss=-3.350328\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:48 INFO 140345909798720] processed a total of 743 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6678.768873214722, \"sum\": 6678.768873214722, \"min\": 6678.768873214722}}, \"EndTime\": 1580468628.217518, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468621.538381}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:48 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=111.244894824 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:48 INFO 140345909798720] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=69, train loss <loss>=-3.33485571934\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:49 INFO 140345909798720] Epoch[70] Batch[0] avg_epoch_loss=-2.580166\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=-2.58016617234\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:51 INFO 140345909798720] Epoch[70] Batch[5] avg_epoch_loss=-2.641837\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:51 INFO 140345909798720] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=-2.64183714583\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:51 INFO 140345909798720] Epoch[70] Batch [5]#011Speed: 126.96 samples/sec#011loss=-2.641837\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:54 INFO 140345909798720] processed a total of 707 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6068.928003311157, \"sum\": 6068.928003311157, \"min\": 6068.928003311157}}, \"EndTime\": 1580468634.287138, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468628.217655}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:54 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.485231609 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:54 INFO 140345909798720] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:54 INFO 140345909798720] #quality_metric: host=algo-1, epoch=70, train loss <loss>=-2.75565624753\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:55 INFO 140345909798720] Epoch[71] Batch[0] avg_epoch_loss=-2.641648\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=-2.64164775127\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:58 INFO 140345909798720] Epoch[71] Batch[5] avg_epoch_loss=-2.957492\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:58 INFO 140345909798720] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=-2.9574916599\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:03:58 INFO 140345909798720] Epoch[71] Batch [5]#011Speed: 125.62 samples/sec#011loss=-2.957492\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:00 INFO 140345909798720] Epoch[71] Batch[10] avg_epoch_loss=-2.906661\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:00 INFO 140345909798720] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=-2.84566425633\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:00 INFO 140345909798720] Epoch[71] Batch [10]#011Speed: 125.32 samples/sec#011loss=-2.845664\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:00 INFO 140345909798720] processed a total of 758 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6710.032939910889, \"sum\": 6710.032939910889, \"min\": 6710.032939910889}}, \"EndTime\": 1580468640.998745, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468634.287604}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:00 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.962992788 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:00 INFO 140345909798720] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:00 INFO 140345909798720] #quality_metric: host=algo-1, epoch=71, train loss <loss>=-2.90666102191\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:01 INFO 140345909798720] Epoch[72] Batch[0] avg_epoch_loss=-2.956261\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:01 INFO 140345909798720] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=-2.95626109355\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:04 INFO 140345909798720] Epoch[72] Batch[5] avg_epoch_loss=-3.135576\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:04 INFO 140345909798720] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=-3.13557640282\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:04 INFO 140345909798720] Epoch[72] Batch [5]#011Speed: 125.61 samples/sec#011loss=-3.135576\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:07 INFO 140345909798720] processed a total of 732 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6137.346029281616, \"sum\": 6137.346029281616, \"min\": 6137.346029281616}}, \"EndTime\": 1580468647.136588, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468640.998835}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:07 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=119.267209228 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:07 INFO 140345909798720] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:07 INFO 140345909798720] #quality_metric: host=algo-1, epoch=72, train loss <loss>=-3.1735439816\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:07 INFO 140345909798720] Epoch[73] Batch[0] avg_epoch_loss=-3.676038\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:07 INFO 140345909798720] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=-3.67603817502\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:10 INFO 140345909798720] Epoch[73] Batch[5] avg_epoch_loss=-3.495486\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:10 INFO 140345909798720] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=-3.49548552917\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:10 INFO 140345909798720] Epoch[73] Batch [5]#011Speed: 124.93 samples/sec#011loss=-3.495486\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:13 INFO 140345909798720] processed a total of 712 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6103.738069534302, \"sum\": 6103.738069534302, \"min\": 6103.738069534302}}, \"EndTime\": 1580468653.240869, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468647.136679}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:13 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.647154075 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:13 INFO 140345909798720] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:13 INFO 140345909798720] #quality_metric: host=algo-1, epoch=73, train loss <loss>=-3.49575974748\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:14 INFO 140345909798720] Epoch[74] Batch[0] avg_epoch_loss=-2.798515\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=-2.79851531982\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:17 INFO 140345909798720] Epoch[74] Batch[5] avg_epoch_loss=-3.041177\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=-3.04117718258\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:17 INFO 140345909798720] Epoch[74] Batch [5]#011Speed: 119.97 samples/sec#011loss=-3.041177\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:19 INFO 140345909798720] processed a total of 738 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6284.991025924683, \"sum\": 6284.991025924683, \"min\": 6284.991025924683}}, \"EndTime\": 1580468659.526384, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468653.240967}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:19 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.420227894 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:19 INFO 140345909798720] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:19 INFO 140345909798720] #quality_metric: host=algo-1, epoch=74, train loss <loss>=-3.04214685801\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:20 INFO 140345909798720] Epoch[75] Batch[0] avg_epoch_loss=-3.374772\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:20 INFO 140345909798720] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=-3.37477214916\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:23 INFO 140345909798720] Epoch[75] Batch[5] avg_epoch_loss=-3.063433\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=-3.06343281376\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:23 INFO 140345909798720] Epoch[75] Batch [5]#011Speed: 126.76 samples/sec#011loss=-3.063433\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:25 INFO 140345909798720] processed a total of 740 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6096.687078475952, \"sum\": 6096.687078475952, \"min\": 6096.687078475952}}, \"EndTime\": 1580468665.623629, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468659.526471}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:25 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=121.374846824 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:25 INFO 140345909798720] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:25 INFO 140345909798720] #quality_metric: host=algo-1, epoch=75, train loss <loss>=-3.23188377587\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:26 INFO 140345909798720] Epoch[76] Batch[0] avg_epoch_loss=-3.139426\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:26 INFO 140345909798720] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=-3.13942615406\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:29 INFO 140345909798720] Epoch[76] Batch[5] avg_epoch_loss=-3.502972\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=-3.50297185537\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:29 INFO 140345909798720] Epoch[76] Batch [5]#011Speed: 128.10 samples/sec#011loss=-3.502972\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:32 INFO 140345909798720] Epoch[76] Batch[10] avg_epoch_loss=-3.598627\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=-3.71341272303\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:32 INFO 140345909798720] Epoch[76] Batch [10]#011Speed: 126.20 samples/sec#011loss=-3.713413\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:32 INFO 140345909798720] processed a total of 761 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6674.5569705963135, \"sum\": 6674.5569705963135, \"min\": 6674.5569705963135}}, \"EndTime\": 1580468672.298818, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468665.623716}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:32 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.012850633 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:32 INFO 140345909798720] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=76, train loss <loss>=-3.59862679521\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:33 INFO 140345909798720] Epoch[77] Batch[0] avg_epoch_loss=-4.147333\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:33 INFO 140345909798720] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=-4.14733268119\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:36 INFO 140345909798720] Epoch[77] Batch[5] avg_epoch_loss=-3.752502\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:36 INFO 140345909798720] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=-3.75250178844\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:36 INFO 140345909798720] Epoch[77] Batch [5]#011Speed: 115.82 samples/sec#011loss=-3.752502\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:38 INFO 140345909798720] processed a total of 712 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6334.09309387207, \"sum\": 6334.09309387207, \"min\": 6334.09309387207}}, \"EndTime\": 1580468678.63345, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468672.298904}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:38 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.405262082 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:38 INFO 140345909798720] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:38 INFO 140345909798720] #quality_metric: host=algo-1, epoch=77, train loss <loss>=-3.61954331269\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:39 INFO 140345909798720] Epoch[78] Batch[0] avg_epoch_loss=-3.705969\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:39 INFO 140345909798720] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=-3.70596932076\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:42 INFO 140345909798720] Epoch[78] Batch[5] avg_epoch_loss=-3.617096\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:42 INFO 140345909798720] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=-3.61709618783\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:42 INFO 140345909798720] Epoch[78] Batch [5]#011Speed: 124.80 samples/sec#011loss=-3.617096\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:45 INFO 140345909798720] Epoch[78] Batch[10] avg_epoch_loss=-3.584156\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=-3.54462758657\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:45 INFO 140345909798720] Epoch[78] Batch [10]#011Speed: 127.68 samples/sec#011loss=-3.544628\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:45 INFO 140345909798720] processed a total of 770 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6690.809011459351, \"sum\": 6690.809011459351, \"min\": 6690.809011459351}}, \"EndTime\": 1580468685.324778, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468678.633539}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:45 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.080954873 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:45 INFO 140345909798720] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=78, train loss <loss>=-3.58415591453\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:46 INFO 140345909798720] Epoch[79] Batch[0] avg_epoch_loss=-2.663669\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:46 INFO 140345909798720] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=-2.66366927688\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:49 INFO 140345909798720] Epoch[79] Batch[5] avg_epoch_loss=-2.680158\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=-2.6801578075\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:49 INFO 140345909798720] Epoch[79] Batch [5]#011Speed: 125.60 samples/sec#011loss=-2.680158\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:52 INFO 140345909798720] Epoch[79] Batch[10] avg_epoch_loss=-2.591695\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:52 INFO 140345909798720] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=-2.48554060652\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:52 INFO 140345909798720] Epoch[79] Batch [10]#011Speed: 125.80 samples/sec#011loss=-2.485541\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:52 INFO 140345909798720] processed a total of 762 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6693.941831588745, \"sum\": 6693.941831588745, \"min\": 6693.941831588745}}, \"EndTime\": 1580468692.019231, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468685.324869}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:52 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.832042816 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:52 INFO 140345909798720] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:52 INFO 140345909798720] #quality_metric: host=algo-1, epoch=79, train loss <loss>=-2.59169544342\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:52 INFO 140345909798720] Epoch[80] Batch[0] avg_epoch_loss=-3.149340\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:52 INFO 140345909798720] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=-3.14934044915\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:55 INFO 140345909798720] Epoch[80] Batch[5] avg_epoch_loss=-3.242574\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=-3.24257446839\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:55 INFO 140345909798720] Epoch[80] Batch [5]#011Speed: 126.37 samples/sec#011loss=-3.242574\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:58 INFO 140345909798720] processed a total of 732 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6098.052024841309, \"sum\": 6098.052024841309, \"min\": 6098.052024841309}}, \"EndTime\": 1580468698.117817, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468692.019323}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:58 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.035658001 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:58 INFO 140345909798720] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:58 INFO 140345909798720] #quality_metric: host=algo-1, epoch=80, train loss <loss>=-3.34636036641\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:58 INFO 140345909798720] Epoch[81] Batch[0] avg_epoch_loss=-3.816489\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:04:58 INFO 140345909798720] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=-3.81648914234\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:01 INFO 140345909798720] Epoch[81] Batch[5] avg_epoch_loss=-3.205588\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:01 INFO 140345909798720] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=-3.20558750737\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:01 INFO 140345909798720] Epoch[81] Batch [5]#011Speed: 124.72 samples/sec#011loss=-3.205588\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:04 INFO 140345909798720] Epoch[81] Batch[10] avg_epoch_loss=-3.146278\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:04 INFO 140345909798720] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=-3.0751066878\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:04 INFO 140345909798720] Epoch[81] Batch [10]#011Speed: 127.70 samples/sec#011loss=-3.075107\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:04 INFO 140345909798720] processed a total of 748 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6677.896976470947, \"sum\": 6677.896976470947, \"min\": 6677.896976470947}}, \"EndTime\": 1580468704.796498, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468698.117907}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:04 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.008996309 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:04 INFO 140345909798720] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:04 INFO 140345909798720] #quality_metric: host=algo-1, epoch=81, train loss <loss>=-3.14627804393\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:05 INFO 140345909798720] Epoch[82] Batch[0] avg_epoch_loss=-3.320543\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:05 INFO 140345909798720] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=-3.32054344383\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:08 INFO 140345909798720] Epoch[82] Batch[5] avg_epoch_loss=-2.890659\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=-2.89065940101\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:08 INFO 140345909798720] Epoch[82] Batch [5]#011Speed: 125.05 samples/sec#011loss=-2.890659\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:11 INFO 140345909798720] Epoch[82] Batch[10] avg_epoch_loss=-3.031934\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:11 INFO 140345909798720] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=-3.20146269927\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:11 INFO 140345909798720] Epoch[82] Batch [10]#011Speed: 123.45 samples/sec#011loss=-3.201463\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:11 INFO 140345909798720] processed a total of 745 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6781.59499168396, \"sum\": 6781.59499168396, \"min\": 6781.59499168396}}, \"EndTime\": 1580468711.578647, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468704.796592}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:11 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=109.854103787 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:11 INFO 140345909798720] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:11 INFO 140345909798720] #quality_metric: host=algo-1, epoch=82, train loss <loss>=-3.03193362749\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:12 INFO 140345909798720] Epoch[83] Batch[0] avg_epoch_loss=-3.319643\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:12 INFO 140345909798720] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=-3.31964338148\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:15 INFO 140345909798720] Epoch[83] Batch[5] avg_epoch_loss=-3.330169\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:15 INFO 140345909798720] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=-3.33016892167\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:15 INFO 140345909798720] Epoch[83] Batch [5]#011Speed: 125.44 samples/sec#011loss=-3.330169\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:18 INFO 140345909798720] Epoch[83] Batch[10] avg_epoch_loss=-3.304001\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:18 INFO 140345909798720] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=-3.2725999162\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:18 INFO 140345909798720] Epoch[83] Batch [10]#011Speed: 126.72 samples/sec#011loss=-3.272600\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:18 INFO 140345909798720] processed a total of 772 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6709.47003364563, \"sum\": 6709.47003364563, \"min\": 6709.47003364563}}, \"EndTime\": 1580468718.288639, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468711.578735}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:18 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.059073546 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:18 INFO 140345909798720] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:18 INFO 140345909798720] #quality_metric: host=algo-1, epoch=83, train loss <loss>=-3.30400119191\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:19 INFO 140345909798720] Epoch[84] Batch[0] avg_epoch_loss=-3.320189\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:19 INFO 140345909798720] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=-3.32018878009\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:22 INFO 140345909798720] Epoch[84] Batch[5] avg_epoch_loss=-3.541332\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:22 INFO 140345909798720] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=-3.54133224487\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:22 INFO 140345909798720] Epoch[84] Batch [5]#011Speed: 125.95 samples/sec#011loss=-3.541332\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:24 INFO 140345909798720] Epoch[84] Batch[10] avg_epoch_loss=-3.332200\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:24 INFO 140345909798720] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=-3.08124133961\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:24 INFO 140345909798720] Epoch[84] Batch [10]#011Speed: 126.81 samples/sec#011loss=-3.081241\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:24 INFO 140345909798720] processed a total of 784 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6672.405004501343, \"sum\": 6672.405004501343, \"min\": 6672.405004501343}}, \"EndTime\": 1580468724.961808, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468718.288728}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:24 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.496612436 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:24 INFO 140345909798720] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:24 INFO 140345909798720] #quality_metric: host=algo-1, epoch=84, train loss <loss>=-3.33220001521\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:25 INFO 140345909798720] Epoch[85] Batch[0] avg_epoch_loss=-3.833321\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:25 INFO 140345909798720] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=-3.83332123628\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:28 INFO 140345909798720] Epoch[85] Batch[5] avg_epoch_loss=-3.453045\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:28 INFO 140345909798720] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=-3.45304530376\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:28 INFO 140345909798720] Epoch[85] Batch [5]#011Speed: 126.66 samples/sec#011loss=-3.453045\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:31 INFO 140345909798720] processed a total of 728 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6054.116010665894, \"sum\": 6054.116010665894, \"min\": 6054.116010665894}}, \"EndTime\": 1580468731.016468, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468724.961896}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:31 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.246027567 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:31 INFO 140345909798720] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:31 INFO 140345909798720] #quality_metric: host=algo-1, epoch=85, train loss <loss>=-3.15730953732\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:31 INFO 140345909798720] Epoch[86] Batch[0] avg_epoch_loss=-3.378720\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:31 INFO 140345909798720] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=-3.37871984533\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:34 INFO 140345909798720] Epoch[86] Batch[5] avg_epoch_loss=-3.077052\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:34 INFO 140345909798720] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=-3.07705172977\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:34 INFO 140345909798720] Epoch[86] Batch [5]#011Speed: 126.51 samples/sec#011loss=-3.077052\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:37 INFO 140345909798720] processed a total of 719 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6121.351957321167, \"sum\": 6121.351957321167, \"min\": 6121.351957321167}}, \"EndTime\": 1580468737.138453, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468731.016564}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:37 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.455484879 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:37 INFO 140345909798720] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:37 INFO 140345909798720] #quality_metric: host=algo-1, epoch=86, train loss <loss>=-3.1154064694\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:37 INFO 140345909798720] Epoch[87] Batch[0] avg_epoch_loss=-3.387504\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:37 INFO 140345909798720] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=-3.38750416524\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:40 INFO 140345909798720] Epoch[87] Batch[5] avg_epoch_loss=-3.456487\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:40 INFO 140345909798720] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=-3.45648677929\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:40 INFO 140345909798720] Epoch[87] Batch [5]#011Speed: 126.47 samples/sec#011loss=-3.456487\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:43 INFO 140345909798720] processed a total of 737 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6079.848051071167, \"sum\": 6079.848051071167, \"min\": 6079.848051071167}}, \"EndTime\": 1580468743.219067, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468737.138525}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:43 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=121.217544095 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:43 INFO 140345909798720] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:43 INFO 140345909798720] #quality_metric: host=algo-1, epoch=87, train loss <loss>=-3.50994691591\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:44 INFO 140345909798720] Epoch[88] Batch[0] avg_epoch_loss=-3.583785\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:44 INFO 140345909798720] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=-3.58378477354\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:46 INFO 140345909798720] Epoch[88] Batch[5] avg_epoch_loss=-3.484478\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:46 INFO 140345909798720] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=-3.48447840923\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:46 INFO 140345909798720] Epoch[88] Batch [5]#011Speed: 127.61 samples/sec#011loss=-3.484478\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:49 INFO 140345909798720] Epoch[88] Batch[10] avg_epoch_loss=-3.623841\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=-3.7910750518\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:49 INFO 140345909798720] Epoch[88] Batch [10]#011Speed: 127.21 samples/sec#011loss=-3.791075\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:49 INFO 140345909798720] processed a total of 746 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6659.005880355835, \"sum\": 6659.005880355835, \"min\": 6659.005880355835}}, \"EndTime\": 1580468749.878666, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468743.219157}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:49 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.026492086 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:49 INFO 140345909798720] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=88, train loss <loss>=-3.62384051949\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:50 INFO 140345909798720] Epoch[89] Batch[0] avg_epoch_loss=-2.147973\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:50 INFO 140345909798720] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=-2.14797293173\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:53 INFO 140345909798720] Epoch[89] Batch[5] avg_epoch_loss=-2.653495\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:53 INFO 140345909798720] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=-2.65349510124\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:53 INFO 140345909798720] Epoch[89] Batch [5]#011Speed: 127.24 samples/sec#011loss=-2.653495\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:55 INFO 140345909798720] processed a total of 706 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6029.739141464233, \"sum\": 6029.739141464233, \"min\": 6029.739141464233}}, \"EndTime\": 1580468755.908923, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468749.878759}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:55 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.084038533 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:55 INFO 140345909798720] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=89, train loss <loss>=-2.67077191327\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:56 INFO 140345909798720] Epoch[90] Batch[0] avg_epoch_loss=-3.010417\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:56 INFO 140345909798720] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=-3.01041659793\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:59 INFO 140345909798720] Epoch[90] Batch[5] avg_epoch_loss=-2.884409\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:59 INFO 140345909798720] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=-2.88440907109\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:05:59 INFO 140345909798720] Epoch[90] Batch [5]#011Speed: 126.76 samples/sec#011loss=-2.884409\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:01 INFO 140345909798720] processed a total of 730 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6060.01615524292, \"sum\": 6060.01615524292, \"min\": 6060.01615524292}}, \"EndTime\": 1580468761.969485, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468755.909004}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:01 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.458848374 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:01 INFO 140345909798720] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:01 INFO 140345909798720] #quality_metric: host=algo-1, epoch=90, train loss <loss>=-3.10432667088\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:02 INFO 140345909798720] Epoch[91] Batch[0] avg_epoch_loss=-3.300704\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:02 INFO 140345909798720] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=-3.30070392506\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:05 INFO 140345909798720] Epoch[91] Batch[5] avg_epoch_loss=-3.328388\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:05 INFO 140345909798720] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=-3.32838783608\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:05 INFO 140345909798720] Epoch[91] Batch [5]#011Speed: 126.14 samples/sec#011loss=-3.328388\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:08 INFO 140345909798720] processed a total of 715 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6072.207927703857, \"sum\": 6072.207927703857, \"min\": 6072.207927703857}}, \"EndTime\": 1580468768.042337, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468761.96959}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:08 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.747108343 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:08 INFO 140345909798720] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=91, train loss <loss>=-3.37559866003\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:08 INFO 140345909798720] Epoch[92] Batch[0] avg_epoch_loss=-3.300517\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=-3.30051669559\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:11 INFO 140345909798720] Epoch[92] Batch[5] avg_epoch_loss=-3.407156\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:11 INFO 140345909798720] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=-3.40715566412\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:11 INFO 140345909798720] Epoch[92] Batch [5]#011Speed: 126.94 samples/sec#011loss=-3.407156\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:14 INFO 140345909798720] processed a total of 704 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6050.868988037109, \"sum\": 6050.868988037109, \"min\": 6050.868988037109}}, \"EndTime\": 1580468774.09373, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468768.042423}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:14 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.344233996 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:14 INFO 140345909798720] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=92, train loss <loss>=-3.42027723983\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:14 INFO 140345909798720] Epoch[93] Batch[0] avg_epoch_loss=-3.489646\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=-3.48964629302\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:17 INFO 140345909798720] Epoch[93] Batch[5] avg_epoch_loss=-3.452246\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=-3.45224607313\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:17 INFO 140345909798720] Epoch[93] Batch [5]#011Speed: 127.26 samples/sec#011loss=-3.452246\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:20 INFO 140345909798720] processed a total of 740 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6068.647146224976, \"sum\": 6068.647146224976, \"min\": 6068.647146224976}}, \"EndTime\": 1580468780.162933, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468774.093826}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:20 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=121.935402916 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:20 INFO 140345909798720] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:20 INFO 140345909798720] #quality_metric: host=algo-1, epoch=93, train loss <loss>=-3.45639992791\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:20 INFO 140345909798720] Epoch[94] Batch[0] avg_epoch_loss=-3.876680\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:20 INFO 140345909798720] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=-3.876679704\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:23 INFO 140345909798720] Epoch[94] Batch[5] avg_epoch_loss=-3.523620\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=-3.52362022744\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:23 INFO 140345909798720] Epoch[94] Batch [5]#011Speed: 126.95 samples/sec#011loss=-3.523620\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:26 INFO 140345909798720] Epoch[94] Batch[10] avg_epoch_loss=-3.536659\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:26 INFO 140345909798720] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=-3.55230618039\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:26 INFO 140345909798720] Epoch[94] Batch [10]#011Speed: 127.01 samples/sec#011loss=-3.552306\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:26 INFO 140345909798720] processed a total of 777 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6659.790992736816, \"sum\": 6659.790992736816, \"min\": 6659.790992736816}}, \"EndTime\": 1580468786.823388, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468780.163029}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:26 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.666861459 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:26 INFO 140345909798720] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:26 INFO 140345909798720] #quality_metric: host=algo-1, epoch=94, train loss <loss>=-3.53665929696\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:27 INFO 140345909798720] Epoch[95] Batch[0] avg_epoch_loss=-3.323869\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:27 INFO 140345909798720] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=-3.32386924125\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:30 INFO 140345909798720] Epoch[95] Batch[5] avg_epoch_loss=-3.046538\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:30 INFO 140345909798720] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=-3.04653817254\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:30 INFO 140345909798720] Epoch[95] Batch [5]#011Speed: 126.59 samples/sec#011loss=-3.046538\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:33 INFO 140345909798720] Epoch[95] Batch[10] avg_epoch_loss=-3.022889\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:33 INFO 140345909798720] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=-2.99451054753\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:33 INFO 140345909798720] Epoch[95] Batch [10]#011Speed: 127.53 samples/sec#011loss=-2.994511\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:33 INFO 140345909798720] processed a total of 755 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6632.998943328857, \"sum\": 6632.998943328857, \"min\": 6632.998943328857}}, \"EndTime\": 1580468793.456962, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468786.823546}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:33 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.822636435 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:33 INFO 140345909798720] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:33 INFO 140345909798720] #quality_metric: host=algo-1, epoch=95, train loss <loss>=-3.02288925208\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:34 INFO 140345909798720] Epoch[96] Batch[0] avg_epoch_loss=-3.610373\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:34 INFO 140345909798720] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=-3.61037341968\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:37 INFO 140345909798720] Epoch[96] Batch[5] avg_epoch_loss=-3.235427\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:37 INFO 140345909798720] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=-3.23542689418\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:37 INFO 140345909798720] Epoch[96] Batch [5]#011Speed: 126.50 samples/sec#011loss=-3.235427\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:39 INFO 140345909798720] processed a total of 708 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6064.141035079956, \"sum\": 6064.141035079956, \"min\": 6064.141035079956}}, \"EndTime\": 1580468799.5216, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468793.457051}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:39 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.749152541 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:39 INFO 140345909798720] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:39 INFO 140345909798720] #quality_metric: host=algo-1, epoch=96, train loss <loss>=-3.0525351447\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:40 INFO 140345909798720] Epoch[97] Batch[0] avg_epoch_loss=-3.214485\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:40 INFO 140345909798720] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=-3.21448496226\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:43 INFO 140345909798720] Epoch[97] Batch[5] avg_epoch_loss=-3.262687\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:43 INFO 140345909798720] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=-3.26268744254\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:43 INFO 140345909798720] Epoch[97] Batch [5]#011Speed: 126.82 samples/sec#011loss=-3.262687\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:45 INFO 140345909798720] processed a total of 701 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6032.191038131714, \"sum\": 6032.191038131714, \"min\": 6032.191038131714}}, \"EndTime\": 1580468805.554359, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468799.521691}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:45 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.207073216 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:45 INFO 140345909798720] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=97, train loss <loss>=-3.23642400793\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:46 INFO 140345909798720] Epoch[98] Batch[0] avg_epoch_loss=-2.717149\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:46 INFO 140345909798720] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=-2.71714906435\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:49 INFO 140345909798720] Epoch[98] Batch[5] avg_epoch_loss=-3.080226\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=-3.08022645143\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:49 INFO 140345909798720] Epoch[98] Batch [5]#011Speed: 125.71 samples/sec#011loss=-3.080226\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:51 INFO 140345909798720] processed a total of 695 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6043.601036071777, \"sum\": 6043.601036071777, \"min\": 6043.601036071777}}, \"EndTime\": 1580468811.598567, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468805.554431}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:51 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.994964554 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:51 INFO 140345909798720] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:51 INFO 140345909798720] #quality_metric: host=algo-1, epoch=98, train loss <loss>=-3.10077531144\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:52 INFO 140345909798720] Epoch[99] Batch[0] avg_epoch_loss=-3.519671\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:52 INFO 140345909798720] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=-3.5196710535\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:55 INFO 140345909798720] Epoch[99] Batch[5] avg_epoch_loss=-3.552602\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=-3.55260216653\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:55 INFO 140345909798720] Epoch[99] Batch [5]#011Speed: 125.70 samples/sec#011loss=-3.552602\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:58 INFO 140345909798720] Epoch[99] Batch[10] avg_epoch_loss=-3.639672\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:58 INFO 140345909798720] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=-3.74415567759\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:58 INFO 140345909798720] Epoch[99] Batch [10]#011Speed: 126.75 samples/sec#011loss=-3.744156\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:58 INFO 140345909798720] processed a total of 800 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6777.34112739563, \"sum\": 6777.34112739563, \"min\": 6777.34112739563}}, \"EndTime\": 1580468818.376428, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468811.598665}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:58 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.03807444 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:58 INFO 140345909798720] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:58 INFO 140345909798720] #quality_metric: host=algo-1, epoch=99, train loss <loss>=-3.63967194428\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:59 INFO 140345909798720] Epoch[100] Batch[0] avg_epoch_loss=-3.030873\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:06:59 INFO 140345909798720] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=-3.03087265427\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:02 INFO 140345909798720] Epoch[100] Batch[5] avg_epoch_loss=-3.536841\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:02 INFO 140345909798720] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=-3.53684066223\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:02 INFO 140345909798720] Epoch[100] Batch [5]#011Speed: 123.87 samples/sec#011loss=-3.536841\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:04 INFO 140345909798720] processed a total of 709 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6173.277854919434, \"sum\": 6173.277854919434, \"min\": 6173.277854919434}}, \"EndTime\": 1580468824.550275, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468818.37652}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:04 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.847537748 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:04 INFO 140345909798720] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:04 INFO 140345909798720] #quality_metric: host=algo-1, epoch=100, train loss <loss>=-3.72395475233\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:05 INFO 140345909798720] Epoch[101] Batch[0] avg_epoch_loss=-3.464208\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:05 INFO 140345909798720] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=-3.46420824206\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:08 INFO 140345909798720] Epoch[101] Batch[5] avg_epoch_loss=-3.668627\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=-3.66862735233\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:08 INFO 140345909798720] Epoch[101] Batch [5]#011Speed: 125.78 samples/sec#011loss=-3.668627\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:11 INFO 140345909798720] Epoch[101] Batch[10] avg_epoch_loss=-3.789445\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:11 INFO 140345909798720] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=-3.9344270036\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:11 INFO 140345909798720] Epoch[101] Batch [10]#011Speed: 127.52 samples/sec#011loss=-3.934427\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:11 INFO 140345909798720] processed a total of 757 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6646.628141403198, \"sum\": 6646.628141403198, \"min\": 6646.628141403198}}, \"EndTime\": 1580468831.197592, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468824.550358}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:11 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.890092332 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:11 INFO 140345909798720] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:11 INFO 140345909798720] #quality_metric: host=algo-1, epoch=101, train loss <loss>=-3.78944537563\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:12 INFO 140345909798720] Epoch[102] Batch[0] avg_epoch_loss=-3.818680\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:12 INFO 140345909798720] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=-3.81867980957\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:14 INFO 140345909798720] Epoch[102] Batch[5] avg_epoch_loss=-3.652104\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=-3.65210356154\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:14 INFO 140345909798720] Epoch[102] Batch [5]#011Speed: 125.68 samples/sec#011loss=-3.652104\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:17 INFO 140345909798720] processed a total of 722 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6103.302955627441, \"sum\": 6103.302955627441, \"min\": 6103.302955627441}}, \"EndTime\": 1580468837.301416, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468831.197683}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:17 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.292882011 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:17 INFO 140345909798720] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=102, train loss <loss>=-3.76380064681\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:18 INFO 140345909798720] Epoch[103] Batch[0] avg_epoch_loss=-3.654412\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:18 INFO 140345909798720] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=-3.65441152212\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:21 INFO 140345909798720] Epoch[103] Batch[5] avg_epoch_loss=-3.675189\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:21 INFO 140345909798720] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=-3.67518894092\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:21 INFO 140345909798720] Epoch[103] Batch [5]#011Speed: 126.73 samples/sec#011loss=-3.675189\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:23 INFO 140345909798720] processed a total of 736 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6106.559991836548, \"sum\": 6106.559991836548, \"min\": 6106.559991836548}}, \"EndTime\": 1580468843.408581, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468837.301527}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:23 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.523440696 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:23 INFO 140345909798720] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=103, train loss <loss>=-3.65511406563\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:24 INFO 140345909798720] Epoch[104] Batch[0] avg_epoch_loss=-3.620835\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:24 INFO 140345909798720] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=-3.62083476299\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:27 INFO 140345909798720] Epoch[104] Batch[5] avg_epoch_loss=-3.804122\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:27 INFO 140345909798720] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=-3.80412223747\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:27 INFO 140345909798720] Epoch[104] Batch [5]#011Speed: 127.49 samples/sec#011loss=-3.804122\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:29 INFO 140345909798720] processed a total of 699 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6047.529935836792, \"sum\": 6047.529935836792, \"min\": 6047.529935836792}}, \"EndTime\": 1580468849.456665, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468843.408674}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:29 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.581992583 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:29 INFO 140345909798720] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=104, train loss <loss>=-3.82886793807\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:30 INFO 140345909798720] Epoch[105] Batch[0] avg_epoch_loss=-3.504950\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:30 INFO 140345909798720] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=-3.50494962125\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:33 INFO 140345909798720] Epoch[105] Batch[5] avg_epoch_loss=-3.477379\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:33 INFO 140345909798720] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=-3.47737887958\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:33 INFO 140345909798720] Epoch[105] Batch [5]#011Speed: 126.81 samples/sec#011loss=-3.477379\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:36 INFO 140345909798720] Epoch[105] Batch[10] avg_epoch_loss=-3.518937\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:36 INFO 140345909798720] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=-3.56880604512\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:36 INFO 140345909798720] Epoch[105] Batch [10]#011Speed: 124.97 samples/sec#011loss=-3.568806\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:36 INFO 140345909798720] processed a total of 742 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6691.40100479126, \"sum\": 6691.40100479126, \"min\": 6691.40100479126}}, \"EndTime\": 1580468856.148789, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468849.456747}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:36 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=110.886496577 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:36 INFO 140345909798720] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:36 INFO 140345909798720] #quality_metric: host=algo-1, epoch=105, train loss <loss>=-3.5189366821\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:36 INFO 140345909798720] Epoch[106] Batch[0] avg_epoch_loss=-2.938731\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:36 INFO 140345909798720] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=-2.93873101312\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:39 INFO 140345909798720] Epoch[106] Batch[5] avg_epoch_loss=-3.324977\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:39 INFO 140345909798720] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=-3.32497735926\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:39 INFO 140345909798720] Epoch[106] Batch [5]#011Speed: 125.90 samples/sec#011loss=-3.324977\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:42 INFO 140345909798720] processed a total of 733 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6082.259178161621, \"sum\": 6082.259178161621, \"min\": 6082.259178161621}}, \"EndTime\": 1580468862.231606, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468856.148876}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:42 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.512153386 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:42 INFO 140345909798720] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:42 INFO 140345909798720] #quality_metric: host=algo-1, epoch=106, train loss <loss>=-3.31209564209\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:43 INFO 140345909798720] Epoch[107] Batch[0] avg_epoch_loss=-3.678216\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:43 INFO 140345909798720] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=-3.67821605785\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:45 INFO 140345909798720] Epoch[107] Batch[5] avg_epoch_loss=-3.752017\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=-3.75201690949\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:45 INFO 140345909798720] Epoch[107] Batch [5]#011Speed: 125.96 samples/sec#011loss=-3.752017\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:48 INFO 140345909798720] processed a total of 709 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6135.715007781982, \"sum\": 6135.715007781982, \"min\": 6135.715007781982}}, \"EndTime\": 1580468868.367923, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468862.231687}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:48 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.550862621 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:48 INFO 140345909798720] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=107, train loss <loss>=-3.73993662241\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:49 INFO 140345909798720] Epoch[108] Batch[0] avg_epoch_loss=-3.972562\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=-3.97256222287\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:52 INFO 140345909798720] Epoch[108] Batch[5] avg_epoch_loss=-3.497594\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:52 INFO 140345909798720] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=-3.49759433506\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:52 INFO 140345909798720] Epoch[108] Batch [5]#011Speed: 127.19 samples/sec#011loss=-3.497594\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:55 INFO 140345909798720] Epoch[108] Batch[10] avg_epoch_loss=-3.641506\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=-3.81420032398\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:55 INFO 140345909798720] Epoch[108] Batch [10]#011Speed: 126.63 samples/sec#011loss=-3.814200\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:55 INFO 140345909798720] processed a total of 755 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6670.695066452026, \"sum\": 6670.695066452026, \"min\": 6670.695066452026}}, \"EndTime\": 1580468875.039398, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468868.367998}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:55 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.179371908 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:55 INFO 140345909798720] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=108, train loss <loss>=-3.6415061482\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:55 INFO 140345909798720] Epoch[109] Batch[0] avg_epoch_loss=-3.224883\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=-3.2248834146\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:58 INFO 140345909798720] Epoch[109] Batch[5] avg_epoch_loss=-3.568616\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:58 INFO 140345909798720] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=-3.56861561268\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:07:58 INFO 140345909798720] Epoch[109] Batch [5]#011Speed: 125.96 samples/sec#011loss=-3.568616\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:01 INFO 140345909798720] Epoch[109] Batch[10] avg_epoch_loss=-3.582995\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:01 INFO 140345909798720] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=-3.60025069778\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:01 INFO 140345909798720] Epoch[109] Batch [10]#011Speed: 127.45 samples/sec#011loss=-3.600251\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:01 INFO 140345909798720] processed a total of 756 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6698.042154312134, \"sum\": 6698.042154312134, \"min\": 6698.042154312134}}, \"EndTime\": 1580468881.737912, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468875.039488}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:01 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.866565184 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:01 INFO 140345909798720] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:01 INFO 140345909798720] #quality_metric: host=algo-1, epoch=109, train loss <loss>=-3.58299519682\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:02 INFO 140345909798720] Epoch[110] Batch[0] avg_epoch_loss=-2.176290\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:02 INFO 140345909798720] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=-2.17629035744\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:05 INFO 140345909798720] Epoch[110] Batch[5] avg_epoch_loss=-3.036293\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:05 INFO 140345909798720] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=-3.03629265175\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:05 INFO 140345909798720] Epoch[110] Batch [5]#011Speed: 124.99 samples/sec#011loss=-3.036293\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:08 INFO 140345909798720] Epoch[110] Batch[10] avg_epoch_loss=-3.228452\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=-3.45904371932\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:08 INFO 140345909798720] Epoch[110] Batch [10]#011Speed: 126.33 samples/sec#011loss=-3.459044\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:08 INFO 140345909798720] processed a total of 752 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6764.610052108765, \"sum\": 6764.610052108765, \"min\": 6764.610052108765}}, \"EndTime\": 1580468888.50309, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468881.738002}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:08 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=111.164919397 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:08 INFO 140345909798720] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=110, train loss <loss>=-3.22845222792\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:09 INFO 140345909798720] Epoch[111] Batch[0] avg_epoch_loss=-3.669436\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:09 INFO 140345909798720] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=-3.66943606815\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:12 INFO 140345909798720] Epoch[111] Batch[5] avg_epoch_loss=-3.625536\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:12 INFO 140345909798720] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=-3.62553646328\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:12 INFO 140345909798720] Epoch[111] Batch [5]#011Speed: 127.01 samples/sec#011loss=-3.625536\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:15 INFO 140345909798720] Epoch[111] Batch[10] avg_epoch_loss=-3.542864\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:15 INFO 140345909798720] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=-3.44365692139\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:15 INFO 140345909798720] Epoch[111] Batch [10]#011Speed: 126.77 samples/sec#011loss=-3.443657\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:15 INFO 140345909798720] processed a total of 763 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6654.790878295898, \"sum\": 6654.790878295898, \"min\": 6654.790878295898}}, \"EndTime\": 1580468895.15852, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468888.503162}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:15 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.651961713 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:15 INFO 140345909798720] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:15 INFO 140345909798720] #quality_metric: host=algo-1, epoch=111, train loss <loss>=-3.54286394424\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:15 INFO 140345909798720] Epoch[112] Batch[0] avg_epoch_loss=-3.290514\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:15 INFO 140345909798720] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=-3.29051394076\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:19 INFO 140345909798720] Epoch[112] Batch[5] avg_epoch_loss=-2.587544\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:19 INFO 140345909798720] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=-2.58754407178\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:19 INFO 140345909798720] Epoch[112] Batch [5]#011Speed: 120.35 samples/sec#011loss=-2.587544\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:21 INFO 140345909798720] Epoch[112] Batch[10] avg_epoch_loss=-2.811992\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:21 INFO 140345909798720] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=-3.0813295519\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:21 INFO 140345909798720] Epoch[112] Batch [10]#011Speed: 127.75 samples/sec#011loss=-3.081330\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:21 INFO 140345909798720] processed a total of 753 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6782.79709815979, \"sum\": 6782.79709815979, \"min\": 6782.79709815979}}, \"EndTime\": 1580468901.941811, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468895.158608}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:21 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=111.014055463 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:21 INFO 140345909798720] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:21 INFO 140345909798720] #quality_metric: host=algo-1, epoch=112, train loss <loss>=-2.81199201729\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:22 INFO 140345909798720] Epoch[113] Batch[0] avg_epoch_loss=-2.531580\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:22 INFO 140345909798720] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=-2.53157991976\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:25 INFO 140345909798720] Epoch[113] Batch[5] avg_epoch_loss=-2.727669\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:25 INFO 140345909798720] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=-2.72766862474\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:25 INFO 140345909798720] Epoch[113] Batch [5]#011Speed: 124.82 samples/sec#011loss=-2.727669\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:28 INFO 140345909798720] Epoch[113] Batch[10] avg_epoch_loss=-2.960461\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:28 INFO 140345909798720] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=-3.23981162406\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:28 INFO 140345909798720] Epoch[113] Batch [10]#011Speed: 126.78 samples/sec#011loss=-3.239812\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:28 INFO 140345909798720] processed a total of 748 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6693.182945251465, \"sum\": 6693.182945251465, \"min\": 6693.182945251465}}, \"EndTime\": 1580468908.635554, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468901.9419}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:28 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=111.753229967 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:28 INFO 140345909798720] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:28 INFO 140345909798720] #quality_metric: host=algo-1, epoch=113, train loss <loss>=-2.96046089716\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:29 INFO 140345909798720] Epoch[114] Batch[0] avg_epoch_loss=-3.519434\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=-3.51943433607\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:32 INFO 140345909798720] Epoch[114] Batch[5] avg_epoch_loss=-3.371109\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=-3.37110921499\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:32 INFO 140345909798720] Epoch[114] Batch [5]#011Speed: 127.05 samples/sec#011loss=-3.371109\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:35 INFO 140345909798720] Epoch[114] Batch[10] avg_epoch_loss=-3.453665\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:35 INFO 140345909798720] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=-3.55273284912\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:35 INFO 140345909798720] Epoch[114] Batch [10]#011Speed: 120.25 samples/sec#011loss=-3.552733\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:35 INFO 140345909798720] processed a total of 777 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6809.095859527588, \"sum\": 6809.095859527588, \"min\": 6809.095859527588}}, \"EndTime\": 1580468915.445191, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468908.635648}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:35 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.109181818 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:35 INFO 140345909798720] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:35 INFO 140345909798720] #quality_metric: host=algo-1, epoch=114, train loss <loss>=-3.45366541232\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:36 INFO 140345909798720] Epoch[115] Batch[0] avg_epoch_loss=-3.329616\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:36 INFO 140345909798720] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=-3.32961582493\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:39 INFO 140345909798720] Epoch[115] Batch[5] avg_epoch_loss=-2.891070\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:39 INFO 140345909798720] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=-2.89107028858\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:39 INFO 140345909798720] Epoch[115] Batch [5]#011Speed: 125.44 samples/sec#011loss=-2.891070\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:41 INFO 140345909798720] processed a total of 709 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6151.6969203948975, \"sum\": 6151.6969203948975, \"min\": 6151.6969203948975}}, \"EndTime\": 1580468921.597544, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468915.445323}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:41 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.250353452 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:41 INFO 140345909798720] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:41 INFO 140345909798720] #quality_metric: host=algo-1, epoch=115, train loss <loss>=-2.83596280072\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:42 INFO 140345909798720] Epoch[116] Batch[0] avg_epoch_loss=-2.950466\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:42 INFO 140345909798720] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=-2.95046564051\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:45 INFO 140345909798720] Epoch[116] Batch[5] avg_epoch_loss=-2.850930\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=-2.85092987885\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:45 INFO 140345909798720] Epoch[116] Batch [5]#011Speed: 124.99 samples/sec#011loss=-2.850930\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:47 INFO 140345909798720] processed a total of 733 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6093.371868133545, \"sum\": 6093.371868133545, \"min\": 6093.371868133545}}, \"EndTime\": 1580468927.691646, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468921.597628}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:47 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.292055358 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:47 INFO 140345909798720] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:47 INFO 140345909798720] #quality_metric: host=algo-1, epoch=116, train loss <loss>=-2.90871903703\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:48 INFO 140345909798720] Epoch[117] Batch[0] avg_epoch_loss=-2.727656\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=-2.72765577162\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:51 INFO 140345909798720] Epoch[117] Batch[5] avg_epoch_loss=-3.023553\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:51 INFO 140345909798720] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=-3.02355297192\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:51 INFO 140345909798720] Epoch[117] Batch [5]#011Speed: 126.90 samples/sec#011loss=-3.023553\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:53 INFO 140345909798720] processed a total of 707 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6051.259994506836, \"sum\": 6051.259994506836, \"min\": 6051.259994506836}}, \"EndTime\": 1580468933.743401, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468927.691736}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:53 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.83262146 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:53 INFO 140345909798720] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:53 INFO 140345909798720] #quality_metric: host=algo-1, epoch=117, train loss <loss>=-3.06560211182\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:54 INFO 140345909798720] Epoch[118] Batch[0] avg_epoch_loss=-3.863070\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:54 INFO 140345909798720] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=-3.86306968895\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:57 INFO 140345909798720] Epoch[118] Batch[5] avg_epoch_loss=-3.695983\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:57 INFO 140345909798720] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=-3.69598289009\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:08:57 INFO 140345909798720] Epoch[118] Batch [5]#011Speed: 127.11 samples/sec#011loss=-3.695983\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:00 INFO 140345909798720] Epoch[118] Batch[10] avg_epoch_loss=-3.704964\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:00 INFO 140345909798720] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=-3.71574146168\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:00 INFO 140345909798720] Epoch[118] Batch [10]#011Speed: 126.21 samples/sec#011loss=-3.715741\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:00 INFO 140345909798720] processed a total of 748 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6660.200119018555, \"sum\": 6660.200119018555, \"min\": 6660.200119018555}}, \"EndTime\": 1580468940.404256, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468933.743491}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:00 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.3067466 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:00 INFO 140345909798720] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:00 INFO 140345909798720] #quality_metric: host=algo-1, epoch=118, train loss <loss>=-3.70496405899\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:01 INFO 140345909798720] Epoch[119] Batch[0] avg_epoch_loss=-3.005701\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:01 INFO 140345909798720] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=-3.00570121971\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:04 INFO 140345909798720] Epoch[119] Batch[5] avg_epoch_loss=-3.560982\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:04 INFO 140345909798720] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=-3.56098195669\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:04 INFO 140345909798720] Epoch[119] Batch [5]#011Speed: 125.21 samples/sec#011loss=-3.560982\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:07 INFO 140345909798720] Epoch[119] Batch[10] avg_epoch_loss=-3.662807\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:07 INFO 140345909798720] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=-3.78499788851\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:07 INFO 140345909798720] Epoch[119] Batch [10]#011Speed: 127.71 samples/sec#011loss=-3.784998\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:07 INFO 140345909798720] processed a total of 785 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6674.295902252197, \"sum\": 6674.295902252197, \"min\": 6674.295902252197}}, \"EndTime\": 1580468947.079011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468940.404347}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:07 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.613146524 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:07 INFO 140345909798720] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:07 INFO 140345909798720] #quality_metric: host=algo-1, epoch=119, train loss <loss>=-3.66280738025\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:07 INFO 140345909798720] Epoch[120] Batch[0] avg_epoch_loss=-4.079930\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:07 INFO 140345909798720] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=-4.07993007351\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:10 INFO 140345909798720] Epoch[120] Batch[5] avg_epoch_loss=-3.660345\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:10 INFO 140345909798720] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=-3.66034451047\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:10 INFO 140345909798720] Epoch[120] Batch [5]#011Speed: 126.65 samples/sec#011loss=-3.660345\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:13 INFO 140345909798720] processed a total of 735 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6051.736116409302, \"sum\": 6051.736116409302, \"min\": 6051.736116409302}}, \"EndTime\": 1580468953.131291, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468947.079102}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:13 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=121.449985481 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:13 INFO 140345909798720] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:13 INFO 140345909798720] #quality_metric: host=algo-1, epoch=120, train loss <loss>=-3.70088331893\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:13 INFO 140345909798720] Epoch[121] Batch[0] avg_epoch_loss=-3.708878\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:13 INFO 140345909798720] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=-3.70887756348\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:16 INFO 140345909798720] Epoch[121] Batch[5] avg_epoch_loss=-3.995895\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:16 INFO 140345909798720] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=-3.99589462968\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:16 INFO 140345909798720] Epoch[121] Batch [5]#011Speed: 126.47 samples/sec#011loss=-3.995895\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:19 INFO 140345909798720] processed a total of 736 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6143.736124038696, \"sum\": 6143.736124038696, \"min\": 6143.736124038696}}, \"EndTime\": 1580468959.275548, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468953.131386}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:19 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=119.793557606 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:19 INFO 140345909798720] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:19 INFO 140345909798720] #quality_metric: host=algo-1, epoch=121, train loss <loss>=-3.94789428711\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:20 INFO 140345909798720] Epoch[122] Batch[0] avg_epoch_loss=-3.531096\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:20 INFO 140345909798720] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=-3.53109576251\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:23 INFO 140345909798720] Epoch[122] Batch[5] avg_epoch_loss=-3.621588\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=-3.62158814851\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:23 INFO 140345909798720] Epoch[122] Batch [5]#011Speed: 126.91 samples/sec#011loss=-3.621588\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:25 INFO 140345909798720] processed a total of 731 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6109.7540855407715, \"sum\": 6109.7540855407715, \"min\": 6109.7540855407715}}, \"EndTime\": 1580468965.385897, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468959.275649}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:25 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=119.641444524 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:25 INFO 140345909798720] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:25 INFO 140345909798720] #quality_metric: host=algo-1, epoch=122, train loss <loss>=-3.43342097514\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:26 INFO 140345909798720] Epoch[123] Batch[0] avg_epoch_loss=-3.610870\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:26 INFO 140345909798720] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=-3.61086994893\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:29 INFO 140345909798720] Epoch[123] Batch[5] avg_epoch_loss=-3.351875\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=-3.35187489278\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:29 INFO 140345909798720] Epoch[123] Batch [5]#011Speed: 127.03 samples/sec#011loss=-3.351875\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:32 INFO 140345909798720] Epoch[123] Batch[10] avg_epoch_loss=-3.451685\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=-3.57145686794\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:32 INFO 140345909798720] Epoch[123] Batch [10]#011Speed: 126.61 samples/sec#011loss=-3.571457\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:32 INFO 140345909798720] processed a total of 781 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6670.439004898071, \"sum\": 6670.439004898071, \"min\": 6670.439004898071}}, \"EndTime\": 1580468972.056914, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468965.386015}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:32 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.081346007 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:32 INFO 140345909798720] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=123, train loss <loss>=-3.45168488149\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:32 INFO 140345909798720] Epoch[124] Batch[0] avg_epoch_loss=-3.881132\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=-3.8811315588\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:35 INFO 140345909798720] Epoch[124] Batch[5] avg_epoch_loss=-3.739916\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:35 INFO 140345909798720] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=-3.73991565876\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:35 INFO 140345909798720] Epoch[124] Batch [5]#011Speed: 125.83 samples/sec#011loss=-3.739916\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:38 INFO 140345909798720] processed a total of 715 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6086.915016174316, \"sum\": 6086.915016174316, \"min\": 6086.915016174316}}, \"EndTime\": 1580468978.14437, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468972.057008}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:38 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.461824668 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:38 INFO 140345909798720] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:38 INFO 140345909798720] #quality_metric: host=algo-1, epoch=124, train loss <loss>=-3.8482943973\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:38 INFO 140345909798720] Epoch[125] Batch[0] avg_epoch_loss=-3.154721\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:38 INFO 140345909798720] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=-3.1547212343\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:41 INFO 140345909798720] Epoch[125] Batch[5] avg_epoch_loss=-3.356256\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:41 INFO 140345909798720] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=-3.35625560864\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:41 INFO 140345909798720] Epoch[125] Batch [5]#011Speed: 127.00 samples/sec#011loss=-3.356256\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:44 INFO 140345909798720] Epoch[125] Batch[10] avg_epoch_loss=-3.690394\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:44 INFO 140345909798720] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=-4.09135989627\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:44 INFO 140345909798720] Epoch[125] Batch [10]#011Speed: 125.75 samples/sec#011loss=-4.091360\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:44 INFO 140345909798720] processed a total of 779 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6675.337076187134, \"sum\": 6675.337076187134, \"min\": 6675.337076187134}}, \"EndTime\": 1580468984.82025, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468978.144497}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:44 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.696026108 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:44 INFO 140345909798720] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:44 INFO 140345909798720] #quality_metric: host=algo-1, epoch=125, train loss <loss>=-3.6903939212\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:45 INFO 140345909798720] Epoch[126] Batch[0] avg_epoch_loss=-3.748662\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=-3.74866176296\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:48 INFO 140345909798720] Epoch[126] Batch[5] avg_epoch_loss=-3.732725\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=-3.73272505752\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:48 INFO 140345909798720] Epoch[126] Batch [5]#011Speed: 127.37 samples/sec#011loss=-3.732725\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:50 INFO 140345909798720] processed a total of 711 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6075.774908065796, \"sum\": 6075.774908065796, \"min\": 6075.774908065796}}, \"EndTime\": 1580468990.896573, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468984.820339}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:50 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.018546741 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:50 INFO 140345909798720] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:50 INFO 140345909798720] #quality_metric: host=algo-1, epoch=126, train loss <loss>=-3.96009632832\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:51 INFO 140345909798720] Epoch[127] Batch[0] avg_epoch_loss=-3.884663\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:51 INFO 140345909798720] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=-3.88466252507\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:54 INFO 140345909798720] Epoch[127] Batch[5] avg_epoch_loss=-3.744320\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:54 INFO 140345909798720] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=-3.74432022507\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:54 INFO 140345909798720] Epoch[127] Batch [5]#011Speed: 126.56 samples/sec#011loss=-3.744320\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:56 INFO 140345909798720] processed a total of 697 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6087.964057922363, \"sum\": 6087.964057922363, \"min\": 6087.964057922363}}, \"EndTime\": 1580468996.98511, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468990.896716}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:56 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.485712949 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:56 INFO 140345909798720] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:56 INFO 140345909798720] #quality_metric: host=algo-1, epoch=127, train loss <loss>=-3.74469258076\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:57 INFO 140345909798720] Epoch[128] Batch[0] avg_epoch_loss=-3.019223\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:09:57 INFO 140345909798720] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=-3.01922298122\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:00 INFO 140345909798720] Epoch[128] Batch[5] avg_epoch_loss=-3.181381\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:00 INFO 140345909798720] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=-3.18138095065\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:00 INFO 140345909798720] Epoch[128] Batch [5]#011Speed: 125.94 samples/sec#011loss=-3.181381\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:03 INFO 140345909798720] processed a total of 701 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6077.2600173950195, \"sum\": 6077.2600173950195, \"min\": 6077.2600173950195}}, \"EndTime\": 1580469003.062928, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580468996.985197}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:03 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.342835527 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:03 INFO 140345909798720] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:03 INFO 140345909798720] #quality_metric: host=algo-1, epoch=128, train loss <loss>=-3.18976434244\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:03 INFO 140345909798720] Epoch[129] Batch[0] avg_epoch_loss=-3.088516\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:03 INFO 140345909798720] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=-3.08851602915\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:06 INFO 140345909798720] Epoch[129] Batch[5] avg_epoch_loss=-3.474774\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:06 INFO 140345909798720] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=-3.47477436925\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:06 INFO 140345909798720] Epoch[129] Batch [5]#011Speed: 125.14 samples/sec#011loss=-3.474774\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:09 INFO 140345909798720] processed a total of 685 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6069.288015365601, \"sum\": 6069.288015365601, \"min\": 6069.288015365601}}, \"EndTime\": 1580469009.132981, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469003.063011}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:09 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.860678394 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:09 INFO 140345909798720] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:09 INFO 140345909798720] #quality_metric: host=algo-1, epoch=129, train loss <loss>=-3.70482054014\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:09 INFO 140345909798720] Epoch[130] Batch[0] avg_epoch_loss=-3.592343\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:09 INFO 140345909798720] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=-3.59234289221\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:12 INFO 140345909798720] Epoch[130] Batch[5] avg_epoch_loss=-3.900887\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:12 INFO 140345909798720] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=-3.90088701678\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:12 INFO 140345909798720] Epoch[130] Batch [5]#011Speed: 126.73 samples/sec#011loss=-3.900887\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:15 INFO 140345909798720] Epoch[130] Batch[10] avg_epoch_loss=-3.765343\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:15 INFO 140345909798720] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=-3.60269016575\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:15 INFO 140345909798720] Epoch[130] Batch [10]#011Speed: 125.94 samples/sec#011loss=-3.602690\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:15 INFO 140345909798720] processed a total of 749 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6685.20712852478, \"sum\": 6685.20712852478, \"min\": 6685.20712852478}}, \"EndTime\": 1580469015.818723, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469009.133078}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:15 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.036251782 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:15 INFO 140345909798720] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:15 INFO 140345909798720] #quality_metric: host=algo-1, epoch=130, train loss <loss>=-3.76534299358\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:16 INFO 140345909798720] Epoch[131] Batch[0] avg_epoch_loss=-3.272068\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:16 INFO 140345909798720] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=-3.27206792058\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:19 INFO 140345909798720] Epoch[131] Batch[5] avg_epoch_loss=-3.617451\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:19 INFO 140345909798720] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=-3.61745092031\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:19 INFO 140345909798720] Epoch[131] Batch [5]#011Speed: 125.57 samples/sec#011loss=-3.617451\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:21 INFO 140345909798720] processed a total of 730 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6127.564907073975, \"sum\": 6127.564907073975, \"min\": 6127.564907073975}}, \"EndTime\": 1580469021.946772, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469015.818811}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:21 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=119.131277267 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:21 INFO 140345909798720] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:21 INFO 140345909798720] #quality_metric: host=algo-1, epoch=131, train loss <loss>=-3.66779948054\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:22 INFO 140345909798720] Epoch[132] Batch[0] avg_epoch_loss=-3.580161\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:22 INFO 140345909798720] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=-3.58016142974\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:25 INFO 140345909798720] Epoch[132] Batch[5] avg_epoch_loss=-3.880981\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:25 INFO 140345909798720] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=-3.88098103291\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:25 INFO 140345909798720] Epoch[132] Batch [5]#011Speed: 126.38 samples/sec#011loss=-3.880981\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:28 INFO 140345909798720] Epoch[132] Batch[10] avg_epoch_loss=-4.091678\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:28 INFO 140345909798720] #quality_metric: host=algo-1, epoch=132, batch=10 train loss <loss>=-4.34451401169\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:28 INFO 140345909798720] Epoch[132] Batch [10]#011Speed: 127.10 samples/sec#011loss=-4.344514\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:28 INFO 140345909798720] processed a total of 755 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6678.436994552612, \"sum\": 6678.436994552612, \"min\": 6678.436994552612}}, \"EndTime\": 1580469028.625815, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469021.94686}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:28 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.047998623 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:28 INFO 140345909798720] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:28 INFO 140345909798720] #quality_metric: host=algo-1, epoch=132, train loss <loss>=-4.09167784145\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:29 INFO 140345909798720] Epoch[133] Batch[0] avg_epoch_loss=-3.763200\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=-3.76319967734\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:32 INFO 140345909798720] Epoch[133] Batch[5] avg_epoch_loss=-3.687000\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=-3.68700034339\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:32 INFO 140345909798720] Epoch[133] Batch [5]#011Speed: 123.57 samples/sec#011loss=-3.687000\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:34 INFO 140345909798720] processed a total of 716 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6129.479885101318, \"sum\": 6129.479885101318, \"min\": 6129.479885101318}}, \"EndTime\": 1580469034.755917, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469028.625913}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:34 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.809200038 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:34 INFO 140345909798720] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:34 INFO 140345909798720] #quality_metric: host=algo-1, epoch=133, train loss <loss>=-3.51957482003\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:35 INFO 140345909798720] Epoch[134] Batch[0] avg_epoch_loss=-4.010698\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:35 INFO 140345909798720] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=-4.01069764833\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:38 INFO 140345909798720] Epoch[134] Batch[5] avg_epoch_loss=-3.972980\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:38 INFO 140345909798720] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=-3.9729796401\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:38 INFO 140345909798720] Epoch[134] Batch [5]#011Speed: 126.93 samples/sec#011loss=-3.972980\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:41 INFO 140345909798720] Epoch[134] Batch[10] avg_epoch_loss=-3.970270\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:41 INFO 140345909798720] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=-3.9670176738\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:41 INFO 140345909798720] Epoch[134] Batch [10]#011Speed: 124.67 samples/sec#011loss=-3.967018\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:41 INFO 140345909798720] processed a total of 793 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6733.246088027954, \"sum\": 6733.246088027954, \"min\": 6733.246088027954}}, \"EndTime\": 1580469041.489777, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469034.756047}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:41 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.771534665 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:41 INFO 140345909798720] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:41 INFO 140345909798720] #quality_metric: host=algo-1, epoch=134, train loss <loss>=-3.97026965542\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:42 INFO 140345909798720] Epoch[135] Batch[0] avg_epoch_loss=-3.533112\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:42 INFO 140345909798720] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=-3.53311198467\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:45 INFO 140345909798720] Epoch[135] Batch[5] avg_epoch_loss=-3.792277\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=-3.79227650273\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:45 INFO 140345909798720] Epoch[135] Batch [5]#011Speed: 126.53 samples/sec#011loss=-3.792277\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:47 INFO 140345909798720] processed a total of 726 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6084.781885147095, \"sum\": 6084.781885147095, \"min\": 6084.781885147095}}, \"EndTime\": 1580469047.575058, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469041.489868}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:47 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=119.311717435 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:47 INFO 140345909798720] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:47 INFO 140345909798720] #quality_metric: host=algo-1, epoch=135, train loss <loss>=-3.8054357374\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:48 INFO 140345909798720] Epoch[136] Batch[0] avg_epoch_loss=-4.237685\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=-4.23768533243\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:51 INFO 140345909798720] Epoch[136] Batch[5] avg_epoch_loss=-4.072976\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:51 INFO 140345909798720] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=-4.07297567419\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:51 INFO 140345909798720] Epoch[136] Batch [5]#011Speed: 126.95 samples/sec#011loss=-4.072976\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:54 INFO 140345909798720] Epoch[136] Batch[10] avg_epoch_loss=-4.148293\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:54 INFO 140345909798720] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=-4.23867298848\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:54 INFO 140345909798720] Epoch[136] Batch [10]#011Speed: 127.66 samples/sec#011loss=-4.238673\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:54 INFO 140345909798720] processed a total of 769 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6641.561031341553, \"sum\": 6641.561031341553, \"min\": 6641.561031341553}}, \"EndTime\": 1580469054.217079, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469047.575138}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:54 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.783679763 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:54 INFO 140345909798720] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:54 INFO 140345909798720] #quality_metric: host=algo-1, epoch=136, train loss <loss>=-4.14829263523\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:55 INFO 140345909798720] Epoch[137] Batch[0] avg_epoch_loss=-2.230038\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=-2.23003758611\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:57 INFO 140345909798720] Epoch[137] Batch[5] avg_epoch_loss=-2.707755\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:57 INFO 140345909798720] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=-2.70775497711\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:10:57 INFO 140345909798720] Epoch[137] Batch [5]#011Speed: 126.87 samples/sec#011loss=-2.707755\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:00 INFO 140345909798720] processed a total of 739 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6050.118923187256, \"sum\": 6050.118923187256, \"min\": 6050.118923187256}}, \"EndTime\": 1580469060.268023, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469054.217172}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:00 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=122.142662713 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:00 INFO 140345909798720] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:00 INFO 140345909798720] #quality_metric: host=algo-1, epoch=137, train loss <loss>=-2.86205549498\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:01 INFO 140345909798720] Epoch[138] Batch[0] avg_epoch_loss=-2.836973\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:01 INFO 140345909798720] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=-2.83697303566\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:04 INFO 140345909798720] Epoch[138] Batch[5] avg_epoch_loss=-3.326051\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:04 INFO 140345909798720] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=-3.32605121372\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:04 INFO 140345909798720] Epoch[138] Batch [5]#011Speed: 126.49 samples/sec#011loss=-3.326051\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:06 INFO 140345909798720] Epoch[138] Batch[10] avg_epoch_loss=-3.574633\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:06 INFO 140345909798720] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=-3.87293177424\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:06 INFO 140345909798720] Epoch[138] Batch [10]#011Speed: 126.41 samples/sec#011loss=-3.872932\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:06 INFO 140345909798720] processed a total of 757 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6665.553092956543, \"sum\": 6665.553092956543, \"min\": 6665.553092956543}}, \"EndTime\": 1580469066.93427, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469060.268097}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:06 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.566825301 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:06 INFO 140345909798720] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:06 INFO 140345909798720] #quality_metric: host=algo-1, epoch=138, train loss <loss>=-3.57463328668\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:07 INFO 140345909798720] Epoch[139] Batch[0] avg_epoch_loss=-3.677242\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:07 INFO 140345909798720] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=-3.67724196975\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:10 INFO 140345909798720] Epoch[139] Batch[5] avg_epoch_loss=-3.554184\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:10 INFO 140345909798720] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=-3.55418444109\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:10 INFO 140345909798720] Epoch[139] Batch [5]#011Speed: 126.98 samples/sec#011loss=-3.554184\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:13 INFO 140345909798720] Epoch[139] Batch[10] avg_epoch_loss=-3.608888\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:13 INFO 140345909798720] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=-3.67453279237\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:13 INFO 140345909798720] Epoch[139] Batch [10]#011Speed: 127.41 samples/sec#011loss=-3.674533\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:13 INFO 140345909798720] processed a total of 761 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6627.671957015991, \"sum\": 6627.671957015991, \"min\": 6627.671957015991}}, \"EndTime\": 1580469073.562436, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469066.934355}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:13 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.819343602 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:13 INFO 140345909798720] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:13 INFO 140345909798720] #quality_metric: host=algo-1, epoch=139, train loss <loss>=-3.60888823713\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:14 INFO 140345909798720] Epoch[140] Batch[0] avg_epoch_loss=-2.794545\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=-2.79454473547\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:17 INFO 140345909798720] Epoch[140] Batch[5] avg_epoch_loss=-2.975705\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=-2.97570515538\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:17 INFO 140345909798720] Epoch[140] Batch [5]#011Speed: 127.18 samples/sec#011loss=-2.975705\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:20 INFO 140345909798720] Epoch[140] Batch[10] avg_epoch_loss=-3.525144\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:20 INFO 140345909798720] #quality_metric: host=algo-1, epoch=140, batch=10 train loss <loss>=-4.18446981069\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:20 INFO 140345909798720] Epoch[140] Batch [10]#011Speed: 127.66 samples/sec#011loss=-4.184470\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:20 INFO 140345909798720] processed a total of 742 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6614.267110824585, \"sum\": 6614.267110824585, \"min\": 6614.267110824585}}, \"EndTime\": 1580469080.177191, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469073.562524}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:20 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.179213745 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:20 INFO 140345909798720] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:20 INFO 140345909798720] #quality_metric: host=algo-1, epoch=140, train loss <loss>=-3.52514363507\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:21 INFO 140345909798720] Epoch[141] Batch[0] avg_epoch_loss=-2.911611\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:21 INFO 140345909798720] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=-2.91161057756\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:23 INFO 140345909798720] Epoch[141] Batch[5] avg_epoch_loss=-3.042616\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=-3.04261632009\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:23 INFO 140345909798720] Epoch[141] Batch [5]#011Speed: 127.17 samples/sec#011loss=-3.042616\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:26 INFO 140345909798720] Epoch[141] Batch[10] avg_epoch_loss=-3.325382\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:26 INFO 140345909798720] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=-3.66470006994\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:26 INFO 140345909798720] Epoch[141] Batch [10]#011Speed: 128.33 samples/sec#011loss=-3.664700\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:26 INFO 140345909798720] processed a total of 764 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6653.004169464111, \"sum\": 6653.004169464111, \"min\": 6653.004169464111}}, \"EndTime\": 1580469086.830891, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469080.177282}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:26 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.833221305 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:26 INFO 140345909798720] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:26 INFO 140345909798720] #quality_metric: host=algo-1, epoch=141, train loss <loss>=-3.32538166093\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:27 INFO 140345909798720] Epoch[142] Batch[0] avg_epoch_loss=-3.462989\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:27 INFO 140345909798720] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=-3.46298918853\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:30 INFO 140345909798720] Epoch[142] Batch[5] avg_epoch_loss=-3.503760\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:30 INFO 140345909798720] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=-3.50376032924\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:30 INFO 140345909798720] Epoch[142] Batch [5]#011Speed: 126.92 samples/sec#011loss=-3.503760\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:32 INFO 140345909798720] processed a total of 706 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6109.486103057861, \"sum\": 6109.486103057861, \"min\": 6109.486103057861}}, \"EndTime\": 1580469092.940893, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469086.830975}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:32 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.55544844 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:32 INFO 140345909798720] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=142, train loss <loss>=-3.59450613486\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:33 INFO 140345909798720] Epoch[143] Batch[0] avg_epoch_loss=-3.696811\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:33 INFO 140345909798720] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=-3.69681116053\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:36 INFO 140345909798720] Epoch[143] Batch[5] avg_epoch_loss=-3.688885\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:36 INFO 140345909798720] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=-3.68888525061\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:36 INFO 140345909798720] Epoch[143] Batch [5]#011Speed: 127.41 samples/sec#011loss=-3.688885\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:39 INFO 140345909798720] Epoch[143] Batch[10] avg_epoch_loss=-3.675103\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:39 INFO 140345909798720] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=-3.65856368606\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:39 INFO 140345909798720] Epoch[143] Batch [10]#011Speed: 127.71 samples/sec#011loss=-3.658564\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:39 INFO 140345909798720] processed a total of 755 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6620.763063430786, \"sum\": 6620.763063430786, \"min\": 6620.763063430786}}, \"EndTime\": 1580469099.562178, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469092.940987}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:39 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.033075034 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:39 INFO 140345909798720] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:39 INFO 140345909798720] #quality_metric: host=algo-1, epoch=143, train loss <loss>=-3.67510272127\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:40 INFO 140345909798720] Epoch[144] Batch[0] avg_epoch_loss=-3.800441\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:40 INFO 140345909798720] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=-3.80044102024\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:43 INFO 140345909798720] Epoch[144] Batch[5] avg_epoch_loss=-3.572036\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:43 INFO 140345909798720] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=-3.57203643386\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:43 INFO 140345909798720] Epoch[144] Batch [5]#011Speed: 125.48 samples/sec#011loss=-3.572036\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:46 INFO 140345909798720] Epoch[144] Batch[10] avg_epoch_loss=-3.583728\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:46 INFO 140345909798720] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=-3.59775687553\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:46 INFO 140345909798720] Epoch[144] Batch [10]#011Speed: 121.71 samples/sec#011loss=-3.597757\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:46 INFO 140345909798720] processed a total of 762 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6805.810213088989, \"sum\": 6805.810213088989, \"min\": 6805.810213088989}}, \"EndTime\": 1580469106.368511, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469099.562259}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:46 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=111.960843302 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:46 INFO 140345909798720] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:46 INFO 140345909798720] #quality_metric: host=algo-1, epoch=144, train loss <loss>=-3.58372754371\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:47 INFO 140345909798720] Epoch[145] Batch[0] avg_epoch_loss=-3.658632\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:47 INFO 140345909798720] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=-3.65863202069\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:50 INFO 140345909798720] Epoch[145] Batch[5] avg_epoch_loss=-3.657338\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:50 INFO 140345909798720] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=-3.65733846029\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:50 INFO 140345909798720] Epoch[145] Batch [5]#011Speed: 126.74 samples/sec#011loss=-3.657338\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:52 INFO 140345909798720] processed a total of 706 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6103.090047836304, \"sum\": 6103.090047836304, \"min\": 6103.090047836304}}, \"EndTime\": 1580469112.472154, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469106.368609}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:52 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.676683757 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:52 INFO 140345909798720] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:52 INFO 140345909798720] #quality_metric: host=algo-1, epoch=145, train loss <loss>=-3.50958080807\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:53 INFO 140345909798720] Epoch[146] Batch[0] avg_epoch_loss=-3.938291\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:53 INFO 140345909798720] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=-3.93829098263\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:56 INFO 140345909798720] Epoch[146] Batch[5] avg_epoch_loss=-4.003442\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:56 INFO 140345909798720] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=-4.003441613\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:56 INFO 140345909798720] Epoch[146] Batch [5]#011Speed: 125.06 samples/sec#011loss=-4.003442\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:58 INFO 140345909798720] processed a total of 699 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6095.0257778167725, \"sum\": 6095.0257778167725, \"min\": 6095.0257778167725}}, \"EndTime\": 1580469118.567685, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469112.47224}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:58 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.681416893 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:58 INFO 140345909798720] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:58 INFO 140345909798720] #quality_metric: host=algo-1, epoch=146, train loss <loss>=-4.01751308957\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:59 INFO 140345909798720] Epoch[147] Batch[0] avg_epoch_loss=-2.464865\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:11:59 INFO 140345909798720] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=-2.46486478238\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:02 INFO 140345909798720] Epoch[147] Batch[5] avg_epoch_loss=-3.223838\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:02 INFO 140345909798720] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=-3.22383849685\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:02 INFO 140345909798720] Epoch[147] Batch [5]#011Speed: 123.80 samples/sec#011loss=-3.223838\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:04 INFO 140345909798720] processed a total of 716 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6129.1069984436035, \"sum\": 6129.1069984436035, \"min\": 6129.1069984436035}}, \"EndTime\": 1580469124.697335, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469118.567762}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:04 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.817246957 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:04 INFO 140345909798720] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:04 INFO 140345909798720] #quality_metric: host=algo-1, epoch=147, train loss <loss>=-3.39404488641\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:05 INFO 140345909798720] Epoch[148] Batch[0] avg_epoch_loss=-3.770237\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:05 INFO 140345909798720] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=-3.77023727829\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:08 INFO 140345909798720] Epoch[148] Batch[5] avg_epoch_loss=-3.702706\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=-3.70270583007\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:08 INFO 140345909798720] Epoch[148] Batch [5]#011Speed: 123.99 samples/sec#011loss=-3.702706\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:10 INFO 140345909798720] processed a total of 709 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6135.441064834595, \"sum\": 6135.441064834595, \"min\": 6135.441064834595}}, \"EndTime\": 1580469130.833358, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469124.697418}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:10 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.555249456 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:10 INFO 140345909798720] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:10 INFO 140345909798720] #quality_metric: host=algo-1, epoch=148, train loss <loss>=-3.9278224842\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:11 INFO 140345909798720] Epoch[149] Batch[0] avg_epoch_loss=-4.246944\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:11 INFO 140345909798720] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=-4.24694411819\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:14 INFO 140345909798720] Epoch[149] Batch[5] avg_epoch_loss=-3.832809\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=-3.83280944824\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:14 INFO 140345909798720] Epoch[149] Batch [5]#011Speed: 126.53 samples/sec#011loss=-3.832809\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:16 INFO 140345909798720] processed a total of 723 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6093.3990478515625, \"sum\": 6093.3990478515625, \"min\": 6093.3990478515625}}, \"EndTime\": 1580469136.927382, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469130.833436}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:16 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.650299335 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:16 INFO 140345909798720] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:16 INFO 140345909798720] #quality_metric: host=algo-1, epoch=149, train loss <loss>=-3.78414785024\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:17 INFO 140345909798720] Epoch[150] Batch[0] avg_epoch_loss=-3.924639\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=-3.92463890282\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:20 INFO 140345909798720] Epoch[150] Batch[5] avg_epoch_loss=-3.784143\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:20 INFO 140345909798720] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=-3.78414329323\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:20 INFO 140345909798720] Epoch[150] Batch [5]#011Speed: 127.65 samples/sec#011loss=-3.784143\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:23 INFO 140345909798720] processed a total of 699 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6094.152927398682, \"sum\": 6094.152927398682, \"min\": 6094.152927398682}}, \"EndTime\": 1580469143.022077, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469136.927478}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:23 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.697186979 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:23 INFO 140345909798720] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=150, train loss <loss>=-3.75913873621\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:23 INFO 140345909798720] Epoch[151] Batch[0] avg_epoch_loss=-3.711164\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=-3.71116390744\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:26 INFO 140345909798720] Epoch[151] Batch[5] avg_epoch_loss=-3.356815\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:26 INFO 140345909798720] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=-3.35681499447\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:26 INFO 140345909798720] Epoch[151] Batch [5]#011Speed: 125.22 samples/sec#011loss=-3.356815\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:29 INFO 140345909798720] processed a total of 725 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6167.768955230713, \"sum\": 6167.768955230713, \"min\": 6167.768955230713}}, \"EndTime\": 1580469149.190442, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469143.022169}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:29 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.544325202 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:29 INFO 140345909798720] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=151, train loss <loss>=-3.36896733464\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:29 INFO 140345909798720] Epoch[152] Batch[0] avg_epoch_loss=-3.723999\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=-3.72399943584\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:32 INFO 140345909798720] Epoch[152] Batch[5] avg_epoch_loss=-3.697844\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=-3.69784425615\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:32 INFO 140345909798720] Epoch[152] Batch [5]#011Speed: 125.65 samples/sec#011loss=-3.697844\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:35 INFO 140345909798720] processed a total of 715 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6078.811883926392, \"sum\": 6078.811883926392, \"min\": 6078.811883926392}}, \"EndTime\": 1580469155.269883, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469149.190517}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:35 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.619034994 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:35 INFO 140345909798720] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:35 INFO 140345909798720] #quality_metric: host=algo-1, epoch=152, train loss <loss>=-3.83411009505\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:36 INFO 140345909798720] Epoch[153] Batch[0] avg_epoch_loss=-3.569127\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:36 INFO 140345909798720] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=-3.56912685085\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:39 INFO 140345909798720] Epoch[153] Batch[5] avg_epoch_loss=-3.685786\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:39 INFO 140345909798720] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=-3.68578627303\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:39 INFO 140345909798720] Epoch[153] Batch [5]#011Speed: 126.05 samples/sec#011loss=-3.685786\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:41 INFO 140345909798720] Epoch[153] Batch[10] avg_epoch_loss=-3.557835\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:41 INFO 140345909798720] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=-3.40429361704\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:41 INFO 140345909798720] Epoch[153] Batch [10]#011Speed: 125.66 samples/sec#011loss=-3.404294\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:41 INFO 140345909798720] processed a total of 747 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6712.930917739868, \"sum\": 6712.930917739868, \"min\": 6712.930917739868}}, \"EndTime\": 1580469161.983411, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469155.269977}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:41 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=111.275480363 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:41 INFO 140345909798720] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:41 INFO 140345909798720] #quality_metric: host=algo-1, epoch=153, train loss <loss>=-3.55783506576\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:42 INFO 140345909798720] Epoch[154] Batch[0] avg_epoch_loss=-3.332411\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:42 INFO 140345909798720] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=-3.33241148253\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:45 INFO 140345909798720] Epoch[154] Batch[5] avg_epoch_loss=-3.634016\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=-3.63401629474\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:45 INFO 140345909798720] Epoch[154] Batch [5]#011Speed: 127.38 samples/sec#011loss=-3.634016\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:48 INFO 140345909798720] processed a total of 705 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6062.242031097412, \"sum\": 6062.242031097412, \"min\": 6062.242031097412}}, \"EndTime\": 1580469168.046202, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469161.983507}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:48 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.291156846 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:48 INFO 140345909798720] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=154, train loss <loss>=-3.48188996186\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:48 INFO 140345909798720] Epoch[155] Batch[0] avg_epoch_loss=-3.800473\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=-3.80047277502\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:51 INFO 140345909798720] Epoch[155] Batch[5] avg_epoch_loss=-3.686060\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:51 INFO 140345909798720] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=-3.68606017517\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:51 INFO 140345909798720] Epoch[155] Batch [5]#011Speed: 126.54 samples/sec#011loss=-3.686060\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:54 INFO 140345909798720] Epoch[155] Batch[10] avg_epoch_loss=-3.690288\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:54 INFO 140345909798720] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=-3.69536083325\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:54 INFO 140345909798720] Epoch[155] Batch [10]#011Speed: 127.15 samples/sec#011loss=-3.695361\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:54 INFO 140345909798720] processed a total of 790 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6658.690929412842, \"sum\": 6658.690929412842, \"min\": 6658.690929412842}}, \"EndTime\": 1580469174.705427, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469168.046288}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:54 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.639389765 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:54 INFO 140345909798720] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:54 INFO 140345909798720] #quality_metric: host=algo-1, epoch=155, train loss <loss>=-3.69028774702\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:55 INFO 140345909798720] Epoch[156] Batch[0] avg_epoch_loss=-3.592838\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=-3.59283818425\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:58 INFO 140345909798720] Epoch[156] Batch[5] avg_epoch_loss=-3.767814\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:58 INFO 140345909798720] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=-3.76781439566\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:12:58 INFO 140345909798720] Epoch[156] Batch [5]#011Speed: 125.12 samples/sec#011loss=-3.767814\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:00 INFO 140345909798720] processed a total of 721 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6074.475049972534, \"sum\": 6074.475049972534, \"min\": 6074.475049972534}}, \"EndTime\": 1580469180.780458, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469174.705512}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:00 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.690887078 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:00 INFO 140345909798720] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:00 INFO 140345909798720] #quality_metric: host=algo-1, epoch=156, train loss <loss>=-3.8346814336\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:01 INFO 140345909798720] Epoch[157] Batch[0] avg_epoch_loss=-3.731423\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:01 INFO 140345909798720] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=-3.73142304292\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:04 INFO 140345909798720] Epoch[157] Batch[5] avg_epoch_loss=-3.832193\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:04 INFO 140345909798720] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=-3.83219260138\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:04 INFO 140345909798720] Epoch[157] Batch [5]#011Speed: 126.27 samples/sec#011loss=-3.832193\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:07 INFO 140345909798720] Epoch[157] Batch[10] avg_epoch_loss=-3.442607\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:07 INFO 140345909798720] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=-2.97510495572\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:07 INFO 140345909798720] Epoch[157] Batch [10]#011Speed: 124.67 samples/sec#011loss=-2.975105\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:07 INFO 140345909798720] processed a total of 756 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6753.88503074646, \"sum\": 6753.88503074646, \"min\": 6753.88503074646}}, \"EndTime\": 1580469187.534945, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469180.780546}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:07 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=111.933472226 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:07 INFO 140345909798720] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:07 INFO 140345909798720] #quality_metric: host=algo-1, epoch=157, train loss <loss>=-3.4426073079\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:08 INFO 140345909798720] Epoch[158] Batch[0] avg_epoch_loss=-3.460394\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=-3.46039436959\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:11 INFO 140345909798720] Epoch[158] Batch[5] avg_epoch_loss=-3.146811\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:11 INFO 140345909798720] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=-3.1468105488\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:11 INFO 140345909798720] Epoch[158] Batch [5]#011Speed: 127.69 samples/sec#011loss=-3.146811\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:13 INFO 140345909798720] processed a total of 739 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6127.835035324097, \"sum\": 6127.835035324097, \"min\": 6127.835035324097}}, \"EndTime\": 1580469193.66326, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469187.535034}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:13 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.594604313 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:13 INFO 140345909798720] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:13 INFO 140345909798720] #quality_metric: host=algo-1, epoch=158, train loss <loss>=-3.13538603912\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:14 INFO 140345909798720] Epoch[159] Batch[0] avg_epoch_loss=-3.571040\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=-3.57103997308\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:17 INFO 140345909798720] Epoch[159] Batch[5] avg_epoch_loss=-3.565035\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=-3.56503529592\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:17 INFO 140345909798720] Epoch[159] Batch [5]#011Speed: 126.49 samples/sec#011loss=-3.565035\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:19 INFO 140345909798720] processed a total of 729 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6072.948932647705, \"sum\": 6072.948932647705, \"min\": 6072.948932647705}}, \"EndTime\": 1580469199.736732, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469193.663351}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:19 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.036890512 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:19 INFO 140345909798720] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:19 INFO 140345909798720] #quality_metric: host=algo-1, epoch=159, train loss <loss>=-3.52520984959\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:20 INFO 140345909798720] Epoch[160] Batch[0] avg_epoch_loss=-3.684116\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:20 INFO 140345909798720] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=-3.68411584803\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:23 INFO 140345909798720] Epoch[160] Batch[5] avg_epoch_loss=-3.689092\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=-3.68909200033\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:23 INFO 140345909798720] Epoch[160] Batch [5]#011Speed: 125.95 samples/sec#011loss=-3.689092\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:25 INFO 140345909798720] processed a total of 701 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6070.250988006592, \"sum\": 6070.250988006592, \"min\": 6070.250988006592}}, \"EndTime\": 1580469205.807601, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469199.736873}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:25 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.477797324 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:25 INFO 140345909798720] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:25 INFO 140345909798720] #quality_metric: host=algo-1, epoch=160, train loss <loss>=-3.46348338772\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:26 INFO 140345909798720] Epoch[161] Batch[0] avg_epoch_loss=-3.492620\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:26 INFO 140345909798720] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=-3.49261969489\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:29 INFO 140345909798720] Epoch[161] Batch[5] avg_epoch_loss=-3.544067\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=-3.54406662675\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:29 INFO 140345909798720] Epoch[161] Batch [5]#011Speed: 126.62 samples/sec#011loss=-3.544067\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:31 INFO 140345909798720] processed a total of 729 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6112.607955932617, \"sum\": 6112.607955932617, \"min\": 6112.607955932617}}, \"EndTime\": 1580469211.920785, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469205.807672}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:31 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=119.259357566 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:31 INFO 140345909798720] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:31 INFO 140345909798720] #quality_metric: host=algo-1, epoch=161, train loss <loss>=-3.5342097102\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:32 INFO 140345909798720] Epoch[162] Batch[0] avg_epoch_loss=-3.004763\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=-3.00476301039\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:35 INFO 140345909798720] Epoch[162] Batch[5] avg_epoch_loss=-3.635504\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:35 INFO 140345909798720] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=-3.63550406104\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:35 INFO 140345909798720] Epoch[162] Batch [5]#011Speed: 127.26 samples/sec#011loss=-3.635504\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:38 INFO 140345909798720] Epoch[162] Batch[10] avg_epoch_loss=-3.691804\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:38 INFO 140345909798720] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=-3.75936489621\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:38 INFO 140345909798720] Epoch[162] Batch [10]#011Speed: 126.24 samples/sec#011loss=-3.759365\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:38 INFO 140345909798720] processed a total of 768 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6655.8802127838135, \"sum\": 6655.8802127838135, \"min\": 6655.8802127838135}}, \"EndTime\": 1580469218.577315, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469211.920868}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:38 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.38446008 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:38 INFO 140345909798720] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:38 INFO 140345909798720] #quality_metric: host=algo-1, epoch=162, train loss <loss>=-3.69180444066\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:39 INFO 140345909798720] Epoch[163] Batch[0] avg_epoch_loss=-3.625464\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:39 INFO 140345909798720] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=-3.62546436207\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:42 INFO 140345909798720] Epoch[163] Batch[5] avg_epoch_loss=-3.935345\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:42 INFO 140345909798720] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=-3.93534521154\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:42 INFO 140345909798720] Epoch[163] Batch [5]#011Speed: 125.18 samples/sec#011loss=-3.935345\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:45 INFO 140345909798720] Epoch[163] Batch[10] avg_epoch_loss=-3.599927\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=-3.19742503811\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:45 INFO 140345909798720] Epoch[163] Batch [10]#011Speed: 126.86 samples/sec#011loss=-3.197425\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:45 INFO 140345909798720] processed a total of 755 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6695.454120635986, \"sum\": 6695.454120635986, \"min\": 6695.454120635986}}, \"EndTime\": 1580469225.273276, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469218.577405}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:45 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.76077094 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:45 INFO 140345909798720] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=163, train loss <loss>=-3.59992695089\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:46 INFO 140345909798720] Epoch[164] Batch[0] avg_epoch_loss=-4.094535\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:46 INFO 140345909798720] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=-4.09453520904\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:49 INFO 140345909798720] Epoch[164] Batch[5] avg_epoch_loss=-3.880531\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=-3.8805314485\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:49 INFO 140345909798720] Epoch[164] Batch [5]#011Speed: 126.84 samples/sec#011loss=-3.880531\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:51 INFO 140345909798720] Epoch[164] Batch[10] avg_epoch_loss=-3.939682\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:51 INFO 140345909798720] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=-4.01066226444\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:51 INFO 140345909798720] Epoch[164] Batch [10]#011Speed: 126.28 samples/sec#011loss=-4.010662\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:51 INFO 140345909798720] processed a total of 761 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6659.17706489563, \"sum\": 6659.17706489563, \"min\": 6659.17706489563}}, \"EndTime\": 1580469231.933101, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469225.273369}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:51 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.275795072 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:51 INFO 140345909798720] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:51 INFO 140345909798720] #quality_metric: host=algo-1, epoch=164, train loss <loss>=-3.93968181938\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:52 INFO 140345909798720] Epoch[165] Batch[0] avg_epoch_loss=-4.024789\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:52 INFO 140345909798720] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=-4.02478893383\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:55 INFO 140345909798720] Epoch[165] Batch[5] avg_epoch_loss=-3.880214\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=-3.88021355706\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:55 INFO 140345909798720] Epoch[165] Batch [5]#011Speed: 126.15 samples/sec#011loss=-3.880214\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:58 INFO 140345909798720] processed a total of 738 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6129.956007003784, \"sum\": 6129.956007003784, \"min\": 6129.956007003784}}, \"EndTime\": 1580469238.063833, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469231.933193}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:58 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.39019912 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:58 INFO 140345909798720] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:58 INFO 140345909798720] #quality_metric: host=algo-1, epoch=165, train loss <loss>=-3.96348435685\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:58 INFO 140345909798720] Epoch[166] Batch[0] avg_epoch_loss=-3.792290\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:13:58 INFO 140345909798720] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=-3.79228994009\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:01 INFO 140345909798720] Epoch[166] Batch[5] avg_epoch_loss=-3.966881\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:01 INFO 140345909798720] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=-3.96688100454\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:01 INFO 140345909798720] Epoch[166] Batch [5]#011Speed: 125.80 samples/sec#011loss=-3.966881\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:04 INFO 140345909798720] processed a total of 725 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6096.208095550537, \"sum\": 6096.208095550537, \"min\": 6096.208095550537}}, \"EndTime\": 1580469244.160548, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469238.063907}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:04 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.923912124 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:04 INFO 140345909798720] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:04 INFO 140345909798720] #quality_metric: host=algo-1, epoch=166, train loss <loss>=-3.93712121087\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:04 INFO 140345909798720] Epoch[167] Batch[0] avg_epoch_loss=-4.013758\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:04 INFO 140345909798720] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=-4.01375765414\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:07 INFO 140345909798720] Epoch[167] Batch[5] avg_epoch_loss=-4.017916\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:07 INFO 140345909798720] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=-4.01791591472\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:07 INFO 140345909798720] Epoch[167] Batch [5]#011Speed: 123.29 samples/sec#011loss=-4.017916\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:10 INFO 140345909798720] processed a total of 726 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6162.816047668457, \"sum\": 6162.816047668457, \"min\": 6162.816047668457}}, \"EndTime\": 1580469250.3239, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469244.160634}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:10 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.800308541 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:10 INFO 140345909798720] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:10 INFO 140345909798720] #quality_metric: host=algo-1, epoch=167, train loss <loss>=-3.92565744761\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:11 INFO 140345909798720] Epoch[168] Batch[0] avg_epoch_loss=-3.420146\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:11 INFO 140345909798720] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=-3.42014642664\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:14 INFO 140345909798720] Epoch[168] Batch[5] avg_epoch_loss=-3.786650\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=-3.78665006483\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:14 INFO 140345909798720] Epoch[168] Batch [5]#011Speed: 126.01 samples/sec#011loss=-3.786650\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:16 INFO 140345909798720] processed a total of 713 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6098.2911586761475, \"sum\": 6098.2911586761475, \"min\": 6098.2911586761475}}, \"EndTime\": 1580469256.422788, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469250.324011}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:16 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.914474915 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:16 INFO 140345909798720] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:16 INFO 140345909798720] #quality_metric: host=algo-1, epoch=168, train loss <loss>=-3.61991716333\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:17 INFO 140345909798720] Epoch[169] Batch[0] avg_epoch_loss=-3.695990\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=-3.69598966031\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:20 INFO 140345909798720] Epoch[169] Batch[5] avg_epoch_loss=-3.891190\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:20 INFO 140345909798720] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=-3.8911899876\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:20 INFO 140345909798720] Epoch[169] Batch [5]#011Speed: 126.51 samples/sec#011loss=-3.891190\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:23 INFO 140345909798720] Epoch[169] Batch[10] avg_epoch_loss=-3.754814\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=-3.5911618207\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:23 INFO 140345909798720] Epoch[169] Batch [10]#011Speed: 123.53 samples/sec#011loss=-3.591162\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:23 INFO 140345909798720] processed a total of 749 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6751.71685218811, \"sum\": 6751.71685218811, \"min\": 6751.71685218811}}, \"EndTime\": 1580469263.175129, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469256.422927}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:23 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=110.932623711 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:23 INFO 140345909798720] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=169, train loss <loss>=-3.7548135481\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:23 INFO 140345909798720] Epoch[170] Batch[0] avg_epoch_loss=-3.157199\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=-3.15719913792\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:26 INFO 140345909798720] Epoch[170] Batch[5] avg_epoch_loss=-3.443381\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:26 INFO 140345909798720] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=-3.44338130092\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:26 INFO 140345909798720] Epoch[170] Batch [5]#011Speed: 127.33 samples/sec#011loss=-3.443381\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:29 INFO 140345909798720] Epoch[170] Batch[10] avg_epoch_loss=-3.502073\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=-3.57250250739\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:29 INFO 140345909798720] Epoch[170] Batch [10]#011Speed: 126.51 samples/sec#011loss=-3.572503\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:29 INFO 140345909798720] processed a total of 761 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6644.972085952759, \"sum\": 6644.972085952759, \"min\": 6644.972085952759}}, \"EndTime\": 1580469269.820574, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469263.17522}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:29 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.520541572 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:29 INFO 140345909798720] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=170, train loss <loss>=-3.50207275841\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:30 INFO 140345909798720] Epoch[171] Batch[0] avg_epoch_loss=-3.471080\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:30 INFO 140345909798720] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=-3.47108047073\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:33 INFO 140345909798720] Epoch[171] Batch[5] avg_epoch_loss=-3.616690\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:33 INFO 140345909798720] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=-3.61668997412\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:33 INFO 140345909798720] Epoch[171] Batch [5]#011Speed: 122.88 samples/sec#011loss=-3.616690\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:35 INFO 140345909798720] processed a total of 716 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6155.239105224609, \"sum\": 6155.239105224609, \"min\": 6155.239105224609}}, \"EndTime\": 1580469275.976351, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469269.820654}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:35 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.321497891 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:35 INFO 140345909798720] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:35 INFO 140345909798720] #quality_metric: host=algo-1, epoch=171, train loss <loss>=-3.46523765358\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:36 INFO 140345909798720] Epoch[172] Batch[0] avg_epoch_loss=-3.227102\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:36 INFO 140345909798720] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=-3.22710171261\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:39 INFO 140345909798720] Epoch[172] Batch[5] avg_epoch_loss=-3.388138\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:39 INFO 140345909798720] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=-3.38813847035\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:39 INFO 140345909798720] Epoch[172] Batch [5]#011Speed: 126.35 samples/sec#011loss=-3.388138\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:42 INFO 140345909798720] processed a total of 720 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6062.482118606567, \"sum\": 6062.482118606567, \"min\": 6062.482118606567}}, \"EndTime\": 1580469282.039508, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469275.976426}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:42 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.760556034 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:42 INFO 140345909798720] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:42 INFO 140345909798720] #quality_metric: host=algo-1, epoch=172, train loss <loss>=-3.62513871064\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:42 INFO 140345909798720] Epoch[173] Batch[0] avg_epoch_loss=-3.533955\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:42 INFO 140345909798720] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=-3.53395451726\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:45 INFO 140345909798720] Epoch[173] Batch[5] avg_epoch_loss=-3.718220\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=-3.71821972271\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:45 INFO 140345909798720] Epoch[173] Batch [5]#011Speed: 127.31 samples/sec#011loss=-3.718220\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:48 INFO 140345909798720] Epoch[173] Batch[10] avg_epoch_loss=-4.052472\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=-4.45357410328\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:48 INFO 140345909798720] Epoch[173] Batch [10]#011Speed: 126.48 samples/sec#011loss=-4.453574\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:48 INFO 140345909798720] processed a total of 760 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6673.910140991211, \"sum\": 6673.910140991211, \"min\": 6673.910140991211}}, \"EndTime\": 1580469288.714006, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469282.039602}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:48 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.873561725 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:48 INFO 140345909798720] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=173, train loss <loss>=-4.05247171388\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:49 INFO 140345909798720] Epoch[174] Batch[0] avg_epoch_loss=-2.892006\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=-2.89200612661\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:52 INFO 140345909798720] Epoch[174] Batch[5] avg_epoch_loss=-3.684721\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:52 INFO 140345909798720] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=-3.68472125079\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:52 INFO 140345909798720] Epoch[174] Batch [5]#011Speed: 126.39 samples/sec#011loss=-3.684721\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:55 INFO 140345909798720] Epoch[174] Batch[10] avg_epoch_loss=-3.791931\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=-3.92058212693\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:55 INFO 140345909798720] Epoch[174] Batch [10]#011Speed: 127.48 samples/sec#011loss=-3.920582\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:55 INFO 140345909798720] processed a total of 763 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6644.239902496338, \"sum\": 6644.239902496338, \"min\": 6644.239902496338}}, \"EndTime\": 1580469295.358831, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469288.714124}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:55 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.834077638 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:55 INFO 140345909798720] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=174, train loss <loss>=-3.79193073994\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:56 INFO 140345909798720] Epoch[175] Batch[0] avg_epoch_loss=-3.513248\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:56 INFO 140345909798720] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=-3.5132479281\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:59 INFO 140345909798720] Epoch[175] Batch[5] avg_epoch_loss=-3.691327\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:59 INFO 140345909798720] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=-3.69132741292\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:14:59 INFO 140345909798720] Epoch[175] Batch [5]#011Speed: 125.80 samples/sec#011loss=-3.691327\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:01 INFO 140345909798720] processed a total of 739 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6136.306047439575, \"sum\": 6136.306047439575, \"min\": 6136.306047439575}}, \"EndTime\": 1580469301.495614, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469295.35892}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:01 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.427914976 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:01 INFO 140345909798720] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:01 INFO 140345909798720] #quality_metric: host=algo-1, epoch=175, train loss <loss>=-3.7324777964\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:02 INFO 140345909798720] Epoch[176] Batch[0] avg_epoch_loss=-3.594637\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:02 INFO 140345909798720] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=-3.59463665936\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:05 INFO 140345909798720] Epoch[176] Batch[5] avg_epoch_loss=-3.821198\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:05 INFO 140345909798720] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=-3.8211979909\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:05 INFO 140345909798720] Epoch[176] Batch [5]#011Speed: 125.57 samples/sec#011loss=-3.821198\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:08 INFO 140345909798720] Epoch[176] Batch[10] avg_epoch_loss=-3.699693\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=-3.55388674349\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:08 INFO 140345909798720] Epoch[176] Batch [10]#011Speed: 125.96 samples/sec#011loss=-3.553887\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:08 INFO 140345909798720] processed a total of 780 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6728.616952896118, \"sum\": 6728.616952896118, \"min\": 6728.616952896118}}, \"EndTime\": 1580469308.224739, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469301.49571}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:08 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.920642571 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:08 INFO 140345909798720] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=176, train loss <loss>=-3.69969287844\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:09 INFO 140345909798720] Epoch[177] Batch[0] avg_epoch_loss=-3.969106\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:09 INFO 140345909798720] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=-3.96910590094\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:11 INFO 140345909798720] Epoch[177] Batch[5] avg_epoch_loss=-3.670647\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:11 INFO 140345909798720] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=-3.67064711425\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:11 INFO 140345909798720] Epoch[177] Batch [5]#011Speed: 126.80 samples/sec#011loss=-3.670647\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:14 INFO 140345909798720] Epoch[177] Batch[10] avg_epoch_loss=-4.019268\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=-4.43761258512\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:14 INFO 140345909798720] Epoch[177] Batch [10]#011Speed: 125.28 samples/sec#011loss=-4.437613\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:14 INFO 140345909798720] processed a total of 750 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6707.021951675415, \"sum\": 6707.021951675415, \"min\": 6707.021951675415}}, \"EndTime\": 1580469314.932279, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469308.224825}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:14 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=111.821118515 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:14 INFO 140345909798720] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=177, train loss <loss>=-4.01926778283\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:15 INFO 140345909798720] Epoch[178] Batch[0] avg_epoch_loss=-3.178883\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:15 INFO 140345909798720] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=-3.17888332058\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:18 INFO 140345909798720] Epoch[178] Batch[5] avg_epoch_loss=-3.771368\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:18 INFO 140345909798720] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=-3.77136807828\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:18 INFO 140345909798720] Epoch[178] Batch [5]#011Speed: 124.82 samples/sec#011loss=-3.771368\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:21 INFO 140345909798720] processed a total of 711 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6102.47278213501, \"sum\": 6102.47278213501, \"min\": 6102.47278213501}}, \"EndTime\": 1580469321.03527, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469314.932352}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:21 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.507606915 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:21 INFO 140345909798720] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:21 INFO 140345909798720] #quality_metric: host=algo-1, epoch=178, train loss <loss>=-3.87787467338\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:21 INFO 140345909798720] Epoch[179] Batch[0] avg_epoch_loss=-4.278197\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:21 INFO 140345909798720] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=-4.27819659259\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:24 INFO 140345909798720] Epoch[179] Batch[5] avg_epoch_loss=-4.204789\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:24 INFO 140345909798720] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=-4.20478917027\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:24 INFO 140345909798720] Epoch[179] Batch [5]#011Speed: 125.57 samples/sec#011loss=-4.204789\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:27 INFO 140345909798720] Epoch[179] Batch[10] avg_epoch_loss=-4.197033\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:27 INFO 140345909798720] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=-4.187725129\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:27 INFO 140345909798720] Epoch[179] Batch [10]#011Speed: 126.82 samples/sec#011loss=-4.187725\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:27 INFO 140345909798720] processed a total of 777 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6681.36191368103, \"sum\": 6681.36191368103, \"min\": 6681.36191368103}}, \"EndTime\": 1580469327.717275, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469321.035361}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:27 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.290260933 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:27 INFO 140345909798720] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:27 INFO 140345909798720] #quality_metric: host=algo-1, epoch=179, train loss <loss>=-4.19703278788\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:28 INFO 140345909798720] Epoch[180] Batch[0] avg_epoch_loss=-4.538559\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:28 INFO 140345909798720] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=-4.53855937236\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:31 INFO 140345909798720] Epoch[180] Batch[5] avg_epoch_loss=-4.039688\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:31 INFO 140345909798720] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=-4.03968845402\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:31 INFO 140345909798720] Epoch[180] Batch [5]#011Speed: 127.41 samples/sec#011loss=-4.039688\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:33 INFO 140345909798720] processed a total of 706 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6202.883958816528, \"sum\": 6202.883958816528, \"min\": 6202.883958816528}}, \"EndTime\": 1580469333.920744, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469327.717427}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:33 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.815439315 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:33 INFO 140345909798720] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:33 INFO 140345909798720] #quality_metric: host=algo-1, epoch=180, train loss <loss>=-3.89712625452\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:34 INFO 140345909798720] Epoch[181] Batch[0] avg_epoch_loss=-3.986359\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:34 INFO 140345909798720] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=-3.98635905498\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:37 INFO 140345909798720] Epoch[181] Batch[5] avg_epoch_loss=-4.117286\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:37 INFO 140345909798720] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=-4.11728606353\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:37 INFO 140345909798720] Epoch[181] Batch [5]#011Speed: 126.73 samples/sec#011loss=-4.117286\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:40 INFO 140345909798720] Epoch[181] Batch[10] avg_epoch_loss=-4.163870\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:40 INFO 140345909798720] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=-4.21977122539\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:40 INFO 140345909798720] Epoch[181] Batch [10]#011Speed: 126.69 samples/sec#011loss=-4.219771\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:40 INFO 140345909798720] processed a total of 742 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6674.579858779907, \"sum\": 6674.579858779907, \"min\": 6674.579858779907}}, \"EndTime\": 1580469340.595922, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469333.92084}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:40 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=111.165909546 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:40 INFO 140345909798720] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:40 INFO 140345909798720] #quality_metric: host=algo-1, epoch=181, train loss <loss>=-4.16387022801\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:41 INFO 140345909798720] Epoch[182] Batch[0] avg_epoch_loss=-4.081397\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:41 INFO 140345909798720] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=-4.08139739165\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:44 INFO 140345909798720] Epoch[182] Batch[5] avg_epoch_loss=-4.241355\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:44 INFO 140345909798720] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=-4.24135479626\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:44 INFO 140345909798720] Epoch[182] Batch [5]#011Speed: 126.20 samples/sec#011loss=-4.241355\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:47 INFO 140345909798720] Epoch[182] Batch[10] avg_epoch_loss=-4.168890\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:47 INFO 140345909798720] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=-4.08193276895\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:47 INFO 140345909798720] Epoch[182] Batch [10]#011Speed: 127.66 samples/sec#011loss=-4.081933\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:47 INFO 140345909798720] processed a total of 760 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6701.479911804199, \"sum\": 6701.479911804199, \"min\": 6701.479911804199}}, \"EndTime\": 1580469347.297918, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469340.596011}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:47 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.405566995 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:47 INFO 140345909798720] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:47 INFO 140345909798720] #quality_metric: host=algo-1, epoch=182, train loss <loss>=-4.16889023839\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:48 INFO 140345909798720] Epoch[183] Batch[0] avg_epoch_loss=-3.136374\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=-3.13637398385\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:51 INFO 140345909798720] Epoch[183] Batch[5] avg_epoch_loss=-3.801135\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:51 INFO 140345909798720] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=-3.80113467655\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:51 INFO 140345909798720] Epoch[183] Batch [5]#011Speed: 126.33 samples/sec#011loss=-3.801135\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:53 INFO 140345909798720] processed a total of 723 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6110.635995864868, \"sum\": 6110.635995864868, \"min\": 6110.635995864868}}, \"EndTime\": 1580469353.409051, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469347.298009}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:53 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.315852277 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:53 INFO 140345909798720] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:53 INFO 140345909798720] #quality_metric: host=algo-1, epoch=183, train loss <loss>=-3.93703988565\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:54 INFO 140345909798720] Epoch[184] Batch[0] avg_epoch_loss=-4.105531\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:54 INFO 140345909798720] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=-4.10553102236\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:57 INFO 140345909798720] Epoch[184] Batch[5] avg_epoch_loss=-4.099442\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:57 INFO 140345909798720] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=-4.09944187199\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:57 INFO 140345909798720] Epoch[184] Batch [5]#011Speed: 126.51 samples/sec#011loss=-4.099442\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:59 INFO 140345909798720] processed a total of 710 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6088.052988052368, \"sum\": 6088.052988052368, \"min\": 6088.052988052368}}, \"EndTime\": 1580469359.497788, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469353.409137}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:59 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.618954135 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:59 INFO 140345909798720] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:15:59 INFO 140345909798720] #quality_metric: host=algo-1, epoch=184, train loss <loss>=-3.91667416547\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:00 INFO 140345909798720] Epoch[185] Batch[0] avg_epoch_loss=-3.956800\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:00 INFO 140345909798720] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=-3.95679989377\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:03 INFO 140345909798720] Epoch[185] Batch[5] avg_epoch_loss=-3.382546\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:03 INFO 140345909798720] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=-3.38254591796\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:03 INFO 140345909798720] Epoch[185] Batch [5]#011Speed: 125.19 samples/sec#011loss=-3.382546\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:05 INFO 140345909798720] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6074.729204177856, \"sum\": 6074.729204177856, \"min\": 6074.729204177856}}, \"EndTime\": 1580469365.57315, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469359.497895}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:05 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.582809173 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:05 INFO 140345909798720] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:05 INFO 140345909798720] #quality_metric: host=algo-1, epoch=185, train loss <loss>=-3.16631402196\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:06 INFO 140345909798720] Epoch[186] Batch[0] avg_epoch_loss=-3.501865\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:06 INFO 140345909798720] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=-3.50186528386\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:09 INFO 140345909798720] Epoch[186] Batch[5] avg_epoch_loss=-3.739288\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:09 INFO 140345909798720] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=-3.73928750528\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:09 INFO 140345909798720] Epoch[186] Batch [5]#011Speed: 126.51 samples/sec#011loss=-3.739288\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:12 INFO 140345909798720] Epoch[186] Batch[10] avg_epoch_loss=-3.687963\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:12 INFO 140345909798720] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=-3.62637333226\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:12 INFO 140345909798720] Epoch[186] Batch [10]#011Speed: 127.92 samples/sec#011loss=-3.626373\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:12 INFO 140345909798720] processed a total of 760 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6623.207092285156, \"sum\": 6623.207092285156, \"min\": 6623.207092285156}}, \"EndTime\": 1580469372.197016, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469365.573225}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:12 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.745821136 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:12 INFO 140345909798720] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:12 INFO 140345909798720] #quality_metric: host=algo-1, epoch=186, train loss <loss>=-3.68796288118\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:12 INFO 140345909798720] Epoch[187] Batch[0] avg_epoch_loss=-4.015095\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:12 INFO 140345909798720] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=-4.01509506638\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:15 INFO 140345909798720] Epoch[187] Batch[5] avg_epoch_loss=-3.948077\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:15 INFO 140345909798720] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=-3.94807709015\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:15 INFO 140345909798720] Epoch[187] Batch [5]#011Speed: 127.13 samples/sec#011loss=-3.948077\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:18 INFO 140345909798720] Epoch[187] Batch[10] avg_epoch_loss=-3.924747\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:18 INFO 140345909798720] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=-3.89675115637\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:18 INFO 140345909798720] Epoch[187] Batch [10]#011Speed: 128.32 samples/sec#011loss=-3.896751\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:18 INFO 140345909798720] processed a total of 743 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6593.951940536499, \"sum\": 6593.951940536499, \"min\": 6593.951940536499}}, \"EndTime\": 1580469378.791497, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469372.197103}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:18 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.676805394 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:18 INFO 140345909798720] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:18 INFO 140345909798720] #quality_metric: host=algo-1, epoch=187, train loss <loss>=-3.92474712025\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:19 INFO 140345909798720] Epoch[188] Batch[0] avg_epoch_loss=-3.759583\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:19 INFO 140345909798720] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=-3.75958293193\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:22 INFO 140345909798720] Epoch[188] Batch[5] avg_epoch_loss=-3.798721\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:22 INFO 140345909798720] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=-3.79872124474\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:22 INFO 140345909798720] Epoch[188] Batch [5]#011Speed: 126.09 samples/sec#011loss=-3.798721\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:25 INFO 140345909798720] Epoch[188] Batch[10] avg_epoch_loss=-3.820232\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:25 INFO 140345909798720] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=-3.84604434452\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:25 INFO 140345909798720] Epoch[188] Batch [10]#011Speed: 127.45 samples/sec#011loss=-3.846044\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:25 INFO 140345909798720] processed a total of 768 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6664.232015609741, \"sum\": 6664.232015609741, \"min\": 6664.232015609741}}, \"EndTime\": 1580469385.456196, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469378.791586}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:25 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.239855703 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:25 INFO 140345909798720] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:25 INFO 140345909798720] #quality_metric: host=algo-1, epoch=188, train loss <loss>=-3.82023174464\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:26 INFO 140345909798720] Epoch[189] Batch[0] avg_epoch_loss=-3.461854\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:26 INFO 140345909798720] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=-3.46185385214\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:29 INFO 140345909798720] Epoch[189] Batch[5] avg_epoch_loss=-3.835352\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=-3.83535216735\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:29 INFO 140345909798720] Epoch[189] Batch [5]#011Speed: 126.66 samples/sec#011loss=-3.835352\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:32 INFO 140345909798720] Epoch[189] Batch[10] avg_epoch_loss=-3.947766\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=-4.08266312883\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:32 INFO 140345909798720] Epoch[189] Batch [10]#011Speed: 128.18 samples/sec#011loss=-4.082663\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:32 INFO 140345909798720] processed a total of 768 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6623.049020767212, \"sum\": 6623.049020767212, \"min\": 6623.049020767212}}, \"EndTime\": 1580469392.079762, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469385.456287}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:32 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.956489374 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:32 INFO 140345909798720] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=189, train loss <loss>=-3.94776624075\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:32 INFO 140345909798720] Epoch[190] Batch[0] avg_epoch_loss=-3.432458\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=-3.43245841361\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:35 INFO 140345909798720] Epoch[190] Batch[5] avg_epoch_loss=-3.198147\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:35 INFO 140345909798720] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=-3.19814723247\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:35 INFO 140345909798720] Epoch[190] Batch [5]#011Speed: 127.26 samples/sec#011loss=-3.198147\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:38 INFO 140345909798720] processed a total of 709 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6088.011980056763, \"sum\": 6088.011980056763, \"min\": 6088.011980056763}}, \"EndTime\": 1580469398.168243, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469392.07985}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:38 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.455814848 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:38 INFO 140345909798720] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:38 INFO 140345909798720] #quality_metric: host=algo-1, epoch=190, train loss <loss>=-3.54226191753\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:38 INFO 140345909798720] Epoch[191] Batch[0] avg_epoch_loss=-3.967418\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:38 INFO 140345909798720] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=-3.96741836135\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:41 INFO 140345909798720] Epoch[191] Batch[5] avg_epoch_loss=-3.907152\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:41 INFO 140345909798720] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=-3.90715205562\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:41 INFO 140345909798720] Epoch[191] Batch [5]#011Speed: 128.05 samples/sec#011loss=-3.907152\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:44 INFO 140345909798720] Epoch[191] Batch[10] avg_epoch_loss=-3.894171\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:44 INFO 140345909798720] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=-3.8785945583\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:44 INFO 140345909798720] Epoch[191] Batch [10]#011Speed: 126.88 samples/sec#011loss=-3.878595\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:44 INFO 140345909798720] processed a total of 770 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6629.086971282959, \"sum\": 6629.086971282959, \"min\": 6629.086971282959}}, \"EndTime\": 1580469404.797896, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469398.168334}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:44 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.152027005 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:44 INFO 140345909798720] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:44 INFO 140345909798720] #quality_metric: host=algo-1, epoch=191, train loss <loss>=-3.89417137502\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:45 INFO 140345909798720] Epoch[192] Batch[0] avg_epoch_loss=-4.297306\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=-4.29730595769\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:48 INFO 140345909798720] Epoch[192] Batch[5] avg_epoch_loss=-4.175831\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=-4.1758308067\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:48 INFO 140345909798720] Epoch[192] Batch [5]#011Speed: 126.51 samples/sec#011loss=-4.175831\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:50 INFO 140345909798720] processed a total of 735 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6112.869024276733, \"sum\": 6112.869024276733, \"min\": 6112.869024276733}}, \"EndTime\": 1580469410.91135, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469404.798011}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:50 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.235011855 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:50 INFO 140345909798720] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:50 INFO 140345909798720] #quality_metric: host=algo-1, epoch=192, train loss <loss>=-4.09245234309\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:51 INFO 140345909798720] Epoch[193] Batch[0] avg_epoch_loss=-3.531704\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:51 INFO 140345909798720] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=-3.53170363967\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:54 INFO 140345909798720] Epoch[193] Batch[5] avg_epoch_loss=-3.777018\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:54 INFO 140345909798720] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=-3.77701785113\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:54 INFO 140345909798720] Epoch[193] Batch [5]#011Speed: 125.90 samples/sec#011loss=-3.777018\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:56 INFO 140345909798720] processed a total of 728 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6075.35195350647, \"sum\": 6075.35195350647, \"min\": 6075.35195350647}}, \"EndTime\": 1580469416.987421, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469410.911467}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:56 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=119.825961148 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:56 INFO 140345909798720] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:56 INFO 140345909798720] #quality_metric: host=algo-1, epoch=193, train loss <loss>=-3.84173771626\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:57 INFO 140345909798720] Epoch[194] Batch[0] avg_epoch_loss=-4.276705\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:16:57 INFO 140345909798720] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=-4.27670494286\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:00 INFO 140345909798720] Epoch[194] Batch[5] avg_epoch_loss=-4.034365\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:00 INFO 140345909798720] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=-4.03436464877\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:00 INFO 140345909798720] Epoch[194] Batch [5]#011Speed: 125.62 samples/sec#011loss=-4.034365\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:03 INFO 140345909798720] Epoch[194] Batch[10] avg_epoch_loss=-4.184617\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:03 INFO 140345909798720] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=-4.36491954907\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:03 INFO 140345909798720] Epoch[194] Batch [10]#011Speed: 124.80 samples/sec#011loss=-4.364920\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:03 INFO 140345909798720] processed a total of 774 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6737.438917160034, \"sum\": 6737.438917160034, \"min\": 6737.438917160034}}, \"EndTime\": 1580469423.725418, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469416.987505}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:03 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.878297328 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:03 INFO 140345909798720] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:03 INFO 140345909798720] #quality_metric: host=algo-1, epoch=194, train loss <loss>=-4.18461687618\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:04 INFO 140345909798720] Epoch[195] Batch[0] avg_epoch_loss=-3.021574\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:04 INFO 140345909798720] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=-3.02157365954\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:07 INFO 140345909798720] Epoch[195] Batch[5] avg_epoch_loss=-3.403686\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:07 INFO 140345909798720] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=-3.4036858361\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:07 INFO 140345909798720] Epoch[195] Batch [5]#011Speed: 127.01 samples/sec#011loss=-3.403686\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:10 INFO 140345909798720] Epoch[195] Batch[10] avg_epoch_loss=-3.408329\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:10 INFO 140345909798720] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=-3.41390059188\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:10 INFO 140345909798720] Epoch[195] Batch [10]#011Speed: 125.56 samples/sec#011loss=-3.413901\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:10 INFO 140345909798720] processed a total of 783 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6672.701835632324, \"sum\": 6672.701835632324, \"min\": 6672.701835632324}}, \"EndTime\": 1580469430.398656, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469423.725502}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:10 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.340287509 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:10 INFO 140345909798720] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:10 INFO 140345909798720] #quality_metric: host=algo-1, epoch=195, train loss <loss>=-3.40832890691\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:11 INFO 140345909798720] Epoch[196] Batch[0] avg_epoch_loss=-4.171059\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:11 INFO 140345909798720] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=-4.17105927338\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:14 INFO 140345909798720] Epoch[196] Batch[5] avg_epoch_loss=-3.714335\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=-3.71433546736\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:14 INFO 140345909798720] Epoch[196] Batch [5]#011Speed: 125.90 samples/sec#011loss=-3.714335\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:17 INFO 140345909798720] Epoch[196] Batch[10] avg_epoch_loss=-3.827517\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=-3.96333585172\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:17 INFO 140345909798720] Epoch[196] Batch [10]#011Speed: 127.22 samples/sec#011loss=-3.963336\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:17 INFO 140345909798720] processed a total of 787 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6666.883945465088, \"sum\": 6666.883945465088, \"min\": 6666.883945465088}}, \"EndTime\": 1580469437.066348, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469430.398807}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:17 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.043742221 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:17 INFO 140345909798720] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=196, train loss <loss>=-3.82751746025\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:17 INFO 140345909798720] Epoch[197] Batch[0] avg_epoch_loss=-4.113598\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=-4.11359838537\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:20 INFO 140345909798720] Epoch[197] Batch[5] avg_epoch_loss=-3.993289\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:20 INFO 140345909798720] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=-3.99328908834\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:20 INFO 140345909798720] Epoch[197] Batch [5]#011Speed: 124.63 samples/sec#011loss=-3.993289\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:23 INFO 140345909798720] processed a total of 739 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6141.910076141357, \"sum\": 6141.910076141357, \"min\": 6141.910076141357}}, \"EndTime\": 1580469443.208862, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469437.06644}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:23 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.318563961 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:23 INFO 140345909798720] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=197, train loss <loss>=-3.94488669731\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:24 INFO 140345909798720] Epoch[198] Batch[0] avg_epoch_loss=-3.416944\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:24 INFO 140345909798720] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=-3.41694352433\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:27 INFO 140345909798720] Epoch[198] Batch[5] avg_epoch_loss=-3.721976\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:27 INFO 140345909798720] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=-3.72197637472\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:27 INFO 140345909798720] Epoch[198] Batch [5]#011Speed: 125.40 samples/sec#011loss=-3.721976\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:29 INFO 140345909798720] Epoch[198] Batch[10] avg_epoch_loss=-3.847108\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=-3.99726587244\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:29 INFO 140345909798720] Epoch[198] Batch [10]#011Speed: 126.30 samples/sec#011loss=-3.997266\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:29 INFO 140345909798720] processed a total of 761 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6783.131122589111, \"sum\": 6783.131122589111, \"min\": 6783.131122589111}}, \"EndTime\": 1580469449.992681, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469443.208938}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:29 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.187947202 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:29 INFO 140345909798720] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=198, train loss <loss>=-3.84710796459\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:30 INFO 140345909798720] Epoch[199] Batch[0] avg_epoch_loss=-4.153211\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:30 INFO 140345909798720] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=-4.15321061418\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:33 INFO 140345909798720] Epoch[199] Batch[5] avg_epoch_loss=-3.831830\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:33 INFO 140345909798720] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=-3.83182951781\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:33 INFO 140345909798720] Epoch[199] Batch [5]#011Speed: 126.24 samples/sec#011loss=-3.831830\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:36 INFO 140345909798720] processed a total of 723 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6171.7848777771, \"sum\": 6171.7848777771, \"min\": 6171.7848777771}}, \"EndTime\": 1580469456.164971, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469449.99277}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:36 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.143389701 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:36 INFO 140345909798720] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:36 INFO 140345909798720] #quality_metric: host=algo-1, epoch=199, train loss <loss>=-3.87226226394\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:36 INFO 140345909798720] Epoch[200] Batch[0] avg_epoch_loss=-3.688976\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:36 INFO 140345909798720] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=-3.68897597854\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:39 INFO 140345909798720] Epoch[200] Batch[5] avg_epoch_loss=-3.955888\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:39 INFO 140345909798720] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=-3.95588773435\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:39 INFO 140345909798720] Epoch[200] Batch [5]#011Speed: 125.14 samples/sec#011loss=-3.955888\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:42 INFO 140345909798720] processed a total of 698 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6103.750944137573, \"sum\": 6103.750944137573, \"min\": 6103.750944137573}}, \"EndTime\": 1580469462.269376, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469456.165063}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:42 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.353454326 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:42 INFO 140345909798720] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:42 INFO 140345909798720] #quality_metric: host=algo-1, epoch=200, train loss <loss>=-4.01452867663\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:43 INFO 140345909798720] Epoch[201] Batch[0] avg_epoch_loss=-2.084601\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:43 INFO 140345909798720] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=-2.08460070636\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:46 INFO 140345909798720] Epoch[201] Batch[5] avg_epoch_loss=-3.583826\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:46 INFO 140345909798720] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=-3.58382563548\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:46 INFO 140345909798720] Epoch[201] Batch [5]#011Speed: 125.96 samples/sec#011loss=-3.583826\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:48 INFO 140345909798720] processed a total of 700 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6153.499126434326, \"sum\": 6153.499126434326, \"min\": 6153.499126434326}}, \"EndTime\": 1580469468.423742, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469462.269462}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:48 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.75331214 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:48 INFO 140345909798720] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=201, train loss <loss>=-3.73075085202\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:49 INFO 140345909798720] Epoch[202] Batch[0] avg_epoch_loss=-4.275668\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=-4.27566817\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:52 INFO 140345909798720] Epoch[202] Batch[5] avg_epoch_loss=-4.047920\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:52 INFO 140345909798720] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=-4.04791967718\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:52 INFO 140345909798720] Epoch[202] Batch [5]#011Speed: 127.23 samples/sec#011loss=-4.047920\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:55 INFO 140345909798720] Epoch[202] Batch[10] avg_epoch_loss=-4.073629\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=-4.10448080527\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:55 INFO 140345909798720] Epoch[202] Batch [10]#011Speed: 124.22 samples/sec#011loss=-4.104481\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:55 INFO 140345909798720] processed a total of 749 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6719.628810882568, \"sum\": 6719.628810882568, \"min\": 6719.628810882568}}, \"EndTime\": 1580469475.143937, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469468.423833}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:55 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=111.462366518 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:55 INFO 140345909798720] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=202, train loss <loss>=-4.07362928086\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:56 INFO 140345909798720] Epoch[203] Batch[0] avg_epoch_loss=-4.289243\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:56 INFO 140345909798720] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=-4.28924313107\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:58 INFO 140345909798720] Epoch[203] Batch[5] avg_epoch_loss=-4.113321\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:58 INFO 140345909798720] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=-4.11332097784\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:17:58 INFO 140345909798720] Epoch[203] Batch [5]#011Speed: 127.06 samples/sec#011loss=-4.113321\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:01 INFO 140345909798720] Epoch[203] Batch[10] avg_epoch_loss=-4.145095\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:01 INFO 140345909798720] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=-4.18322432234\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:01 INFO 140345909798720] Epoch[203] Batch [10]#011Speed: 125.64 samples/sec#011loss=-4.183224\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:01 INFO 140345909798720] processed a total of 749 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6721.672058105469, \"sum\": 6721.672058105469, \"min\": 6721.672058105469}}, \"EndTime\": 1580469481.866219, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469475.144026}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:01 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=111.428417755 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:01 INFO 140345909798720] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:01 INFO 140345909798720] #quality_metric: host=algo-1, epoch=203, train loss <loss>=-4.14509522534\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:02 INFO 140345909798720] Epoch[204] Batch[0] avg_epoch_loss=-4.013130\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:02 INFO 140345909798720] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=-4.01313039419\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:05 INFO 140345909798720] Epoch[204] Batch[5] avg_epoch_loss=-3.842243\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:05 INFO 140345909798720] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=-3.84224333205\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:05 INFO 140345909798720] Epoch[204] Batch [5]#011Speed: 124.77 samples/sec#011loss=-3.842243\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:07 INFO 140345909798720] processed a total of 704 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6101.521968841553, \"sum\": 6101.521968841553, \"min\": 6101.521968841553}}, \"EndTime\": 1580469487.968233, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469481.86631}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:07 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.378663167 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:07 INFO 140345909798720] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:07 INFO 140345909798720] #quality_metric: host=algo-1, epoch=204, train loss <loss>=-3.80827463511\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:08 INFO 140345909798720] Epoch[205] Batch[0] avg_epoch_loss=-3.577566\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=-3.577565786\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:11 INFO 140345909798720] Epoch[205] Batch[5] avg_epoch_loss=-3.746184\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:11 INFO 140345909798720] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=-3.7461839968\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:11 INFO 140345909798720] Epoch[205] Batch [5]#011Speed: 125.33 samples/sec#011loss=-3.746184\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:14 INFO 140345909798720] Epoch[205] Batch[10] avg_epoch_loss=-3.918619\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=-4.12554115089\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:14 INFO 140345909798720] Epoch[205] Batch [10]#011Speed: 121.67 samples/sec#011loss=-4.125541\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:14 INFO 140345909798720] processed a total of 778 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6820.621013641357, \"sum\": 6820.621013641357, \"min\": 6820.621013641357}}, \"EndTime\": 1580469494.789349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469487.96832}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:14 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.063722639 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:14 INFO 140345909798720] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=205, train loss <loss>=-3.91861906684\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:15 INFO 140345909798720] Epoch[206] Batch[0] avg_epoch_loss=-3.952600\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:15 INFO 140345909798720] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=-3.95260042758\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:18 INFO 140345909798720] Epoch[206] Batch[5] avg_epoch_loss=-4.082333\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:18 INFO 140345909798720] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=-4.08233264545\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:18 INFO 140345909798720] Epoch[206] Batch [5]#011Speed: 127.45 samples/sec#011loss=-4.082333\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:20 INFO 140345909798720] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6059.6630573272705, \"sum\": 6059.6630573272705, \"min\": 6059.6630573272705}}, \"EndTime\": 1580469500.849563, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469494.789438}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:20 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.359946149 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:20 INFO 140345909798720] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:20 INFO 140345909798720] #quality_metric: host=algo-1, epoch=206, train loss <loss>=-4.3120188945\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:21 INFO 140345909798720] Epoch[207] Batch[0] avg_epoch_loss=-4.605260\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:21 INFO 140345909798720] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=-4.60525966335\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:24 INFO 140345909798720] Epoch[207] Batch[5] avg_epoch_loss=-4.232000\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:24 INFO 140345909798720] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=-4.23199992137\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:24 INFO 140345909798720] Epoch[207] Batch [5]#011Speed: 127.13 samples/sec#011loss=-4.232000\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:26 INFO 140345909798720] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6082.787990570068, \"sum\": 6082.787990570068, \"min\": 6082.787990570068}}, \"EndTime\": 1580469506.933063, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469500.849679}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:26 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.416552227 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:26 INFO 140345909798720] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:26 INFO 140345909798720] #quality_metric: host=algo-1, epoch=207, train loss <loss>=-4.24682542956\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:27 INFO 140345909798720] Epoch[208] Batch[0] avg_epoch_loss=-4.147816\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:27 INFO 140345909798720] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=-4.14781560125\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:30 INFO 140345909798720] Epoch[208] Batch[5] avg_epoch_loss=-4.160946\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:30 INFO 140345909798720] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=-4.1609455143\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:30 INFO 140345909798720] Epoch[208] Batch [5]#011Speed: 126.49 samples/sec#011loss=-4.160946\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:33 INFO 140345909798720] Epoch[208] Batch[10] avg_epoch_loss=-4.343860\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:33 INFO 140345909798720] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=-4.56335713155\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:33 INFO 140345909798720] Epoch[208] Batch [10]#011Speed: 127.32 samples/sec#011loss=-4.563357\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:33 INFO 140345909798720] processed a total of 759 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6645.272016525269, \"sum\": 6645.272016525269, \"min\": 6645.272016525269}}, \"EndTime\": 1580469513.579099, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469506.933141}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:33 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.214461777 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:33 INFO 140345909798720] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:33 INFO 140345909798720] #quality_metric: host=algo-1, epoch=208, train loss <loss>=-4.34385988578\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:34 INFO 140345909798720] Epoch[209] Batch[0] avg_epoch_loss=-4.127555\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:34 INFO 140345909798720] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=-4.12755522857\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:37 INFO 140345909798720] Epoch[209] Batch[5] avg_epoch_loss=-4.096057\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:37 INFO 140345909798720] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=-4.09605662028\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:37 INFO 140345909798720] Epoch[209] Batch [5]#011Speed: 125.53 samples/sec#011loss=-4.096057\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:39 INFO 140345909798720] processed a total of 715 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6084.360837936401, \"sum\": 6084.360837936401, \"min\": 6084.360837936401}}, \"EndTime\": 1580469519.663974, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469513.579181}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:39 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.509760913 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:39 INFO 140345909798720] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:39 INFO 140345909798720] #quality_metric: host=algo-1, epoch=209, train loss <loss>=-4.04920516143\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:40 INFO 140345909798720] Epoch[210] Batch[0] avg_epoch_loss=-2.214048\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:40 INFO 140345909798720] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=-2.21404802477\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:43 INFO 140345909798720] Epoch[210] Batch[5] avg_epoch_loss=-3.258667\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:43 INFO 140345909798720] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=-3.25866657979\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:43 INFO 140345909798720] Epoch[210] Batch [5]#011Speed: 126.84 samples/sec#011loss=-3.258667\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:45 INFO 140345909798720] processed a total of 716 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6123.565912246704, \"sum\": 6123.565912246704, \"min\": 6123.565912246704}}, \"EndTime\": 1580469525.788187, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469519.664056}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:45 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.920159809 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:45 INFO 140345909798720] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=210, train loss <loss>=-3.27570340956\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:46 INFO 140345909798720] Epoch[211] Batch[0] avg_epoch_loss=-3.420433\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:46 INFO 140345909798720] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=-3.42043263203\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:49 INFO 140345909798720] Epoch[211] Batch[5] avg_epoch_loss=-3.653600\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=-3.653600435\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:49 INFO 140345909798720] Epoch[211] Batch [5]#011Speed: 127.00 samples/sec#011loss=-3.653600\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:51 INFO 140345909798720] processed a total of 739 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6120.995998382568, \"sum\": 6120.995998382568, \"min\": 6120.995998382568}}, \"EndTime\": 1580469531.909885, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469525.788416}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:51 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.729601296 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:51 INFO 140345909798720] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:51 INFO 140345909798720] #quality_metric: host=algo-1, epoch=211, train loss <loss>=-3.72662310214\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:52 INFO 140345909798720] Epoch[212] Batch[0] avg_epoch_loss=-3.081871\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:52 INFO 140345909798720] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=-3.08187144511\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:55 INFO 140345909798720] Epoch[212] Batch[5] avg_epoch_loss=-3.523637\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=-3.52363679216\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:55 INFO 140345909798720] Epoch[212] Batch [5]#011Speed: 125.65 samples/sec#011loss=-3.523637\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:58 INFO 140345909798720] Epoch[212] Batch[10] avg_epoch_loss=-3.564732\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:58 INFO 140345909798720] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=-3.61404703501\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:58 INFO 140345909798720] Epoch[212] Batch [10]#011Speed: 126.34 samples/sec#011loss=-3.614047\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:58 INFO 140345909798720] processed a total of 747 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6681.839942932129, \"sum\": 6681.839942932129, \"min\": 6681.839942932129}}, \"EndTime\": 1580469538.592292, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469531.909968}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:58 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=111.793412201 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:58 INFO 140345909798720] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:58 INFO 140345909798720] #quality_metric: host=algo-1, epoch=212, train loss <loss>=-3.56473235709\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:59 INFO 140345909798720] Epoch[213] Batch[0] avg_epoch_loss=-3.646505\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:18:59 INFO 140345909798720] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=-3.64650499499\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:02 INFO 140345909798720] Epoch[213] Batch[5] avg_epoch_loss=-3.791555\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:02 INFO 140345909798720] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=-3.79155497508\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:02 INFO 140345909798720] Epoch[213] Batch [5]#011Speed: 124.64 samples/sec#011loss=-3.791555\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:05 INFO 140345909798720] Epoch[213] Batch[10] avg_epoch_loss=-3.800444\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:05 INFO 140345909798720] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=-3.81111169764\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:05 INFO 140345909798720] Epoch[213] Batch [10]#011Speed: 125.38 samples/sec#011loss=-3.811112\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:05 INFO 140345909798720] processed a total of 770 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6733.827829360962, \"sum\": 6733.827829360962, \"min\": 6733.827829360962}}, \"EndTime\": 1580469545.326672, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469538.592378}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:05 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.345758597 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:05 INFO 140345909798720] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:05 INFO 140345909798720] #quality_metric: host=algo-1, epoch=213, train loss <loss>=-3.80044439442\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:06 INFO 140345909798720] Epoch[214] Batch[0] avg_epoch_loss=-3.777285\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:06 INFO 140345909798720] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=-3.77728477684\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:09 INFO 140345909798720] Epoch[214] Batch[5] avg_epoch_loss=-3.887794\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:09 INFO 140345909798720] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=-3.88779449463\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:09 INFO 140345909798720] Epoch[214] Batch [5]#011Speed: 125.80 samples/sec#011loss=-3.887794\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:12 INFO 140345909798720] Epoch[214] Batch[10] avg_epoch_loss=-3.945022\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:12 INFO 140345909798720] #quality_metric: host=algo-1, epoch=214, batch=10 train loss <loss>=-4.01369455698\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:12 INFO 140345909798720] Epoch[214] Batch [10]#011Speed: 125.92 samples/sec#011loss=-4.013695\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:12 INFO 140345909798720] processed a total of 770 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6696.040868759155, \"sum\": 6696.040868759155, \"min\": 6696.040868759155}}, \"EndTime\": 1580469552.023233, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469545.326765}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:12 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.991105283 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:12 INFO 140345909798720] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:12 INFO 140345909798720] #quality_metric: host=algo-1, epoch=214, train loss <loss>=-3.9450217957\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:12 INFO 140345909798720] Epoch[215] Batch[0] avg_epoch_loss=-3.704011\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:12 INFO 140345909798720] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=-3.70401083457\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:15 INFO 140345909798720] Epoch[215] Batch[5] avg_epoch_loss=-4.069921\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:15 INFO 140345909798720] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=-4.06992116705\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:15 INFO 140345909798720] Epoch[215] Batch [5]#011Speed: 125.31 samples/sec#011loss=-4.069921\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:18 INFO 140345909798720] Epoch[215] Batch[10] avg_epoch_loss=-4.221116\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:18 INFO 140345909798720] #quality_metric: host=algo-1, epoch=215, batch=10 train loss <loss>=-4.40254961993\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:18 INFO 140345909798720] Epoch[215] Batch [10]#011Speed: 127.24 samples/sec#011loss=-4.402550\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:18 INFO 140345909798720] processed a total of 763 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6681.824207305908, \"sum\": 6681.824207305908, \"min\": 6681.824207305908}}, \"EndTime\": 1580469558.705553, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469552.023322}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:18 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.187879676 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:18 INFO 140345909798720] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:18 INFO 140345909798720] #quality_metric: host=algo-1, epoch=215, train loss <loss>=-4.22111591836\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:19 INFO 140345909798720] Epoch[216] Batch[0] avg_epoch_loss=-3.735771\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:19 INFO 140345909798720] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=-3.735770973\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:22 INFO 140345909798720] Epoch[216] Batch[5] avg_epoch_loss=-4.003401\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:22 INFO 140345909798720] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=-4.00340057923\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:22 INFO 140345909798720] Epoch[216] Batch [5]#011Speed: 124.65 samples/sec#011loss=-4.003401\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:24 INFO 140345909798720] processed a total of 718 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6135.130882263184, \"sum\": 6135.130882263184, \"min\": 6135.130882263184}}, \"EndTime\": 1580469564.841319, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469558.705643}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:24 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.028093914 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:24 INFO 140345909798720] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:24 INFO 140345909798720] #quality_metric: host=algo-1, epoch=216, train loss <loss>=-4.0121671522\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:25 INFO 140345909798720] Epoch[217] Batch[0] avg_epoch_loss=-3.659920\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:25 INFO 140345909798720] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=-3.65991994497\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:28 INFO 140345909798720] Epoch[217] Batch[5] avg_epoch_loss=-4.162564\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:28 INFO 140345909798720] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=-4.16256404567\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:28 INFO 140345909798720] Epoch[217] Batch [5]#011Speed: 124.20 samples/sec#011loss=-4.162564\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:31 INFO 140345909798720] Epoch[217] Batch[10] avg_epoch_loss=-4.049003\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:31 INFO 140345909798720] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=-3.91272937672\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:31 INFO 140345909798720] Epoch[217] Batch [10]#011Speed: 125.58 samples/sec#011loss=-3.912729\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:31 INFO 140345909798720] processed a total of 757 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6755.030155181885, \"sum\": 6755.030155181885, \"min\": 6755.030155181885}}, \"EndTime\": 1580469571.597032, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469564.841395}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:31 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.062532475 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:31 INFO 140345909798720] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:31 INFO 140345909798720] #quality_metric: host=algo-1, epoch=217, train loss <loss>=-4.04900283251\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:32 INFO 140345909798720] Epoch[218] Batch[0] avg_epoch_loss=-2.397174\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:32 INFO 140345909798720] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=-2.39717390731\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:35 INFO 140345909798720] Epoch[218] Batch[5] avg_epoch_loss=-2.693831\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:35 INFO 140345909798720] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=-2.69383105716\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:35 INFO 140345909798720] Epoch[218] Batch [5]#011Speed: 125.70 samples/sec#011loss=-2.693831\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:38 INFO 140345909798720] Epoch[218] Batch[10] avg_epoch_loss=-2.933376\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:38 INFO 140345909798720] #quality_metric: host=algo-1, epoch=218, batch=10 train loss <loss>=-3.22083043279\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:38 INFO 140345909798720] Epoch[218] Batch [10]#011Speed: 125.64 samples/sec#011loss=-3.220830\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:38 INFO 140345909798720] processed a total of 745 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6733.1109046936035, \"sum\": 6733.1109046936035, \"min\": 6733.1109046936035}}, \"EndTime\": 1580469578.330658, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469571.59712}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:38 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=110.645064612 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:38 INFO 140345909798720] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:38 INFO 140345909798720] #quality_metric: host=algo-1, epoch=218, train loss <loss>=-2.9333762279\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:39 INFO 140345909798720] Epoch[219] Batch[0] avg_epoch_loss=-2.887542\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:39 INFO 140345909798720] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=-2.88754231221\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:42 INFO 140345909798720] Epoch[219] Batch[5] avg_epoch_loss=-3.088246\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:42 INFO 140345909798720] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=-3.08824576988\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:42 INFO 140345909798720] Epoch[219] Batch [5]#011Speed: 122.56 samples/sec#011loss=-3.088246\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:45 INFO 140345909798720] Epoch[219] Batch[10] avg_epoch_loss=-3.082791\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=219, batch=10 train loss <loss>=-3.07624627191\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:45 INFO 140345909798720] Epoch[219] Batch [10]#011Speed: 127.75 samples/sec#011loss=-3.076246\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:45 INFO 140345909798720] processed a total of 751 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6735.316038131714, \"sum\": 6735.316038131714, \"min\": 6735.316038131714}}, \"EndTime\": 1580469585.066525, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469578.330749}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:45 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=111.499539212 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:45 INFO 140345909798720] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=219, train loss <loss>=-3.08279145262\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:45 INFO 140345909798720] Epoch[220] Batch[0] avg_epoch_loss=-3.530780\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=-3.53077986434\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:48 INFO 140345909798720] Epoch[220] Batch[5] avg_epoch_loss=-3.601930\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=-3.601930498\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:48 INFO 140345909798720] Epoch[220] Batch [5]#011Speed: 126.06 samples/sec#011loss=-3.601930\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:51 INFO 140345909798720] processed a total of 740 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6161.212921142578, \"sum\": 6161.212921142578, \"min\": 6161.212921142578}}, \"EndTime\": 1580469591.228284, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469585.066624}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:51 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.103841298 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:51 INFO 140345909798720] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:51 INFO 140345909798720] #quality_metric: host=algo-1, epoch=220, train loss <loss>=-3.72081183356\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:52 INFO 140345909798720] Epoch[221] Batch[0] avg_epoch_loss=-4.153564\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:52 INFO 140345909798720] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=-4.15356362833\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:54 INFO 140345909798720] Epoch[221] Batch[5] avg_epoch_loss=-4.204188\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:54 INFO 140345909798720] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=-4.20418837264\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:54 INFO 140345909798720] Epoch[221] Batch [5]#011Speed: 127.33 samples/sec#011loss=-4.204188\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:57 INFO 140345909798720] processed a total of 714 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6083.607912063599, \"sum\": 6083.607912063599, \"min\": 6083.607912063599}}, \"EndTime\": 1580469597.312365, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469591.228369}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:57 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.361865743 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:57 INFO 140345909798720] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:57 INFO 140345909798720] #quality_metric: host=algo-1, epoch=221, train loss <loss>=-3.87822754319\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:58 INFO 140345909798720] Epoch[222] Batch[0] avg_epoch_loss=-3.947727\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:19:58 INFO 140345909798720] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=-3.94772668787\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:01 INFO 140345909798720] Epoch[222] Batch[5] avg_epoch_loss=-4.045270\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:01 INFO 140345909798720] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=-4.04526956232\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:01 INFO 140345909798720] Epoch[222] Batch [5]#011Speed: 126.47 samples/sec#011loss=-4.045270\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:03 INFO 140345909798720] processed a total of 735 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6098.757982254028, \"sum\": 6098.757982254028, \"min\": 6098.757982254028}}, \"EndTime\": 1580469603.411738, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469597.312469}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:03 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.513736231 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:03 INFO 140345909798720] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:03 INFO 140345909798720] #quality_metric: host=algo-1, epoch=222, train loss <loss>=-3.79164121473\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:04 INFO 140345909798720] Epoch[223] Batch[0] avg_epoch_loss=-4.588790\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:04 INFO 140345909798720] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=-4.58878965636\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:07 INFO 140345909798720] Epoch[223] Batch[5] avg_epoch_loss=-3.826815\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:07 INFO 140345909798720] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=-3.82681528727\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:07 INFO 140345909798720] Epoch[223] Batch [5]#011Speed: 125.35 samples/sec#011loss=-3.826815\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:09 INFO 140345909798720] processed a total of 727 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6091.963052749634, \"sum\": 6091.963052749634, \"min\": 6091.963052749634}}, \"EndTime\": 1580469609.504276, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469603.411829}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:09 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=119.334859495 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:09 INFO 140345909798720] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:09 INFO 140345909798720] #quality_metric: host=algo-1, epoch=223, train loss <loss>=-3.85900157207\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:10 INFO 140345909798720] Epoch[224] Batch[0] avg_epoch_loss=-3.832916\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:10 INFO 140345909798720] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=-3.83291584737\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:13 INFO 140345909798720] Epoch[224] Batch[5] avg_epoch_loss=-3.826738\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:13 INFO 140345909798720] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=-3.82673844346\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:13 INFO 140345909798720] Epoch[224] Batch [5]#011Speed: 124.89 samples/sec#011loss=-3.826738\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:16 INFO 140345909798720] Epoch[224] Batch[10] avg_epoch_loss=-4.113427\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:16 INFO 140345909798720] #quality_metric: host=algo-1, epoch=224, batch=10 train loss <loss>=-4.45745264002\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:16 INFO 140345909798720] Epoch[224] Batch [10]#011Speed: 126.51 samples/sec#011loss=-4.457453\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:16 INFO 140345909798720] processed a total of 766 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6697.528123855591, \"sum\": 6697.528123855591, \"min\": 6697.528123855591}}, \"EndTime\": 1580469616.202343, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469609.504369}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:16 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.368505849 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:16 INFO 140345909798720] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:16 INFO 140345909798720] #quality_metric: host=algo-1, epoch=224, train loss <loss>=-4.11342671462\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:17 INFO 140345909798720] Epoch[225] Batch[0] avg_epoch_loss=-4.048972\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:17 INFO 140345909798720] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=-4.0489720525\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:19 INFO 140345909798720] Epoch[225] Batch[5] avg_epoch_loss=-3.936611\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:19 INFO 140345909798720] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=-3.9366107975\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:19 INFO 140345909798720] Epoch[225] Batch [5]#011Speed: 126.99 samples/sec#011loss=-3.936611\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:22 INFO 140345909798720] Epoch[225] Batch[10] avg_epoch_loss=-3.836429\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:22 INFO 140345909798720] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=-3.71621060758\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:22 INFO 140345909798720] Epoch[225] Batch [10]#011Speed: 125.21 samples/sec#011loss=-3.716211\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:22 INFO 140345909798720] processed a total of 770 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6711.806058883667, \"sum\": 6711.806058883667, \"min\": 6711.806058883667}}, \"EndTime\": 1580469622.914675, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469616.202422}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:22 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.721255313 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:22 INFO 140345909798720] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:22 INFO 140345909798720] #quality_metric: host=algo-1, epoch=225, train loss <loss>=-3.83642889299\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:23 INFO 140345909798720] Epoch[226] Batch[0] avg_epoch_loss=-3.809714\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:23 INFO 140345909798720] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=-3.80971424\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:26 INFO 140345909798720] Epoch[226] Batch[5] avg_epoch_loss=-3.977116\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:26 INFO 140345909798720] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=-3.97711569984\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:26 INFO 140345909798720] Epoch[226] Batch [5]#011Speed: 125.38 samples/sec#011loss=-3.977116\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:29 INFO 140345909798720] Epoch[226] Batch[10] avg_epoch_loss=-3.904029\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=226, batch=10 train loss <loss>=-3.8163244299\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:29 INFO 140345909798720] Epoch[226] Batch [10]#011Speed: 126.72 samples/sec#011loss=-3.816324\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:29 INFO 140345909798720] processed a total of 797 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6752.4919509887695, \"sum\": 6752.4919509887695, \"min\": 6752.4919509887695}}, \"EndTime\": 1580469629.667633, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469622.914753}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:29 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=118.02840363 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:29 INFO 140345909798720] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:29 INFO 140345909798720] #quality_metric: host=algo-1, epoch=226, train loss <loss>=-3.90402875896\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:30 INFO 140345909798720] Epoch[227] Batch[0] avg_epoch_loss=-3.970073\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:30 INFO 140345909798720] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=-3.97007297825\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:33 INFO 140345909798720] Epoch[227] Batch[5] avg_epoch_loss=-4.079218\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:33 INFO 140345909798720] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=-4.07921785922\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:33 INFO 140345909798720] Epoch[227] Batch [5]#011Speed: 123.73 samples/sec#011loss=-4.079218\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:35 INFO 140345909798720] processed a total of 707 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6121.978998184204, \"sum\": 6121.978998184204, \"min\": 6121.978998184204}}, \"EndTime\": 1580469635.790112, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469629.66771}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:35 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.480854494 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:35 INFO 140345909798720] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:35 INFO 140345909798720] #quality_metric: host=algo-1, epoch=227, train loss <loss>=-3.84257996018\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:36 INFO 140345909798720] Epoch[228] Batch[0] avg_epoch_loss=-3.250606\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:36 INFO 140345909798720] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=-3.25060602137\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:39 INFO 140345909798720] Epoch[228] Batch[5] avg_epoch_loss=-3.421955\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:39 INFO 140345909798720] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=-3.42195497118\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:39 INFO 140345909798720] Epoch[228] Batch [5]#011Speed: 126.08 samples/sec#011loss=-3.421955\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:42 INFO 140345909798720] Epoch[228] Batch[10] avg_epoch_loss=-3.485369\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:42 INFO 140345909798720] #quality_metric: host=algo-1, epoch=228, batch=10 train loss <loss>=-3.56146520666\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:42 INFO 140345909798720] Epoch[228] Batch [10]#011Speed: 125.01 samples/sec#011loss=-3.561465\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:43 INFO 140345909798720] processed a total of 817 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 7291.1670207977295, \"sum\": 7291.1670207977295, \"min\": 7291.1670207977295}}, \"EndTime\": 1580469643.081939, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469635.790184}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:43 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.051641089 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:43 INFO 140345909798720] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:43 INFO 140345909798720] #quality_metric: host=algo-1, epoch=228, train loss <loss>=-3.3437274383\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:43 INFO 140345909798720] Epoch[229] Batch[0] avg_epoch_loss=-3.606268\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:43 INFO 140345909798720] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=-3.60626839303\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:46 INFO 140345909798720] Epoch[229] Batch[5] avg_epoch_loss=-3.661321\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:46 INFO 140345909798720] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=-3.66132100423\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:46 INFO 140345909798720] Epoch[229] Batch [5]#011Speed: 124.44 samples/sec#011loss=-3.661321\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:49 INFO 140345909798720] processed a total of 721 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6118.935108184814, \"sum\": 6118.935108184814, \"min\": 6118.935108184814}}, \"EndTime\": 1580469649.201426, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469643.082014}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:49 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=117.828692335 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:49 INFO 140345909798720] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:49 INFO 140345909798720] #quality_metric: host=algo-1, epoch=229, train loss <loss>=-3.76115062817\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:50 INFO 140345909798720] Epoch[230] Batch[0] avg_epoch_loss=-4.145615\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:50 INFO 140345909798720] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=-4.14561544882\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:52 INFO 140345909798720] Epoch[230] Batch[5] avg_epoch_loss=-3.907670\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:52 INFO 140345909798720] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=-3.90766996092\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:52 INFO 140345909798720] Epoch[230] Batch [5]#011Speed: 126.04 samples/sec#011loss=-3.907670\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:55 INFO 140345909798720] processed a total of 731 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6111.49001121521, \"sum\": 6111.49001121521, \"min\": 6111.49001121521}}, \"EndTime\": 1580469655.313521, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469649.20151}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:55 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=119.608320693 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:55 INFO 140345909798720] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:55 INFO 140345909798720] #quality_metric: host=algo-1, epoch=230, train loss <loss>=-3.962219362\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:56 INFO 140345909798720] Epoch[231] Batch[0] avg_epoch_loss=-3.178516\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:56 INFO 140345909798720] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=-3.17851628484\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:59 INFO 140345909798720] Epoch[231] Batch[5] avg_epoch_loss=-3.867607\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:59 INFO 140345909798720] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=-3.8676067043\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:20:59 INFO 140345909798720] Epoch[231] Batch [5]#011Speed: 126.07 samples/sec#011loss=-3.867607\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:01 INFO 140345909798720] processed a total of 737 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6096.894979476929, \"sum\": 6096.894979476929, \"min\": 6096.894979476929}}, \"EndTime\": 1580469661.410904, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469655.313606}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:01 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=120.877969836 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:01 INFO 140345909798720] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:01 INFO 140345909798720] #quality_metric: host=algo-1, epoch=231, train loss <loss>=-3.9572056126\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:02 INFO 140345909798720] Epoch[232] Batch[0] avg_epoch_loss=-4.248070\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:02 INFO 140345909798720] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=-4.24806996938\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:05 INFO 140345909798720] Epoch[232] Batch[5] avg_epoch_loss=-3.968302\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:05 INFO 140345909798720] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=-3.96830213392\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:05 INFO 140345909798720] Epoch[232] Batch [5]#011Speed: 126.50 samples/sec#011loss=-3.968302\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:08 INFO 140345909798720] Epoch[232] Batch[10] avg_epoch_loss=-3.830723\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=232, batch=10 train loss <loss>=-3.66562796928\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:08 INFO 140345909798720] Epoch[232] Batch [10]#011Speed: 127.16 samples/sec#011loss=-3.665628\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:08 INFO 140345909798720] processed a total of 746 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6702.411890029907, \"sum\": 6702.411890029907, \"min\": 6702.411890029907}}, \"EndTime\": 1580469668.113949, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469661.411025}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:08 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=111.300504207 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:08 INFO 140345909798720] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=232, train loss <loss>=-3.83072296817\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:08 INFO 140345909798720] Epoch[233] Batch[0] avg_epoch_loss=-4.239558\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:08 INFO 140345909798720] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=-4.23955762709\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:11 INFO 140345909798720] Epoch[233] Batch[5] avg_epoch_loss=-3.884864\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:11 INFO 140345909798720] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=-3.88486408543\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:11 INFO 140345909798720] Epoch[233] Batch [5]#011Speed: 126.42 samples/sec#011loss=-3.884864\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:14 INFO 140345909798720] Epoch[233] Batch[10] avg_epoch_loss=-3.948917\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=233, batch=10 train loss <loss>=-4.02578079636\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:14 INFO 140345909798720] Epoch[233] Batch [10]#011Speed: 126.78 samples/sec#011loss=-4.025781\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:14 INFO 140345909798720] processed a total of 748 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6674.862861633301, \"sum\": 6674.862861633301, \"min\": 6674.862861633301}}, \"EndTime\": 1580469674.789373, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469668.114069}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:14 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=112.06007399 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:14 INFO 140345909798720] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:14 INFO 140345909798720] #quality_metric: host=algo-1, epoch=233, train loss <loss>=-3.94891713585\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:15 INFO 140345909798720] Epoch[234] Batch[0] avg_epoch_loss=-3.469061\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:15 INFO 140345909798720] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=-3.46906094938\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:18 INFO 140345909798720] Epoch[234] Batch[5] avg_epoch_loss=-3.864553\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:18 INFO 140345909798720] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=-3.86455302196\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:18 INFO 140345909798720] Epoch[234] Batch [5]#011Speed: 127.39 samples/sec#011loss=-3.864553\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:21 INFO 140345909798720] Epoch[234] Batch[10] avg_epoch_loss=-3.885044\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:21 INFO 140345909798720] #quality_metric: host=algo-1, epoch=234, batch=10 train loss <loss>=-3.90963411073\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:21 INFO 140345909798720] Epoch[234] Batch [10]#011Speed: 127.75 samples/sec#011loss=-3.909634\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:21 INFO 140345909798720] processed a total of 748 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6617.928981781006, \"sum\": 6617.928981781006, \"min\": 6617.928981781006}}, \"EndTime\": 1580469681.407764, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469674.789461}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:21 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.024056497 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:21 INFO 140345909798720] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:21 INFO 140345909798720] #quality_metric: host=algo-1, epoch=234, train loss <loss>=-3.88504442595\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:22 INFO 140345909798720] Epoch[235] Batch[0] avg_epoch_loss=-4.337077\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:22 INFO 140345909798720] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=-4.33707696038\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:25 INFO 140345909798720] Epoch[235] Batch[5] avg_epoch_loss=-3.597138\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:25 INFO 140345909798720] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=-3.59713810414\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:25 INFO 140345909798720] Epoch[235] Batch [5]#011Speed: 126.32 samples/sec#011loss=-3.597138\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:28 INFO 140345909798720] Epoch[235] Batch[10] avg_epoch_loss=-3.671750\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:28 INFO 140345909798720] #quality_metric: host=algo-1, epoch=235, batch=10 train loss <loss>=-3.76128478179\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:28 INFO 140345909798720] Epoch[235] Batch [10]#011Speed: 126.96 samples/sec#011loss=-3.761285\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:28 INFO 140345909798720] processed a total of 766 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6716.562032699585, \"sum\": 6716.562032699585, \"min\": 6716.562032699585}}, \"EndTime\": 1580469688.124872, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469681.407854}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:28 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=114.044437774 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:28 INFO 140345909798720] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:28 INFO 140345909798720] #quality_metric: host=algo-1, epoch=235, train loss <loss>=-3.67175023034\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:28 INFO 140345909798720] Epoch[236] Batch[0] avg_epoch_loss=-4.226007\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:28 INFO 140345909798720] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=-4.22600741\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:31 INFO 140345909798720] Epoch[236] Batch[5] avg_epoch_loss=-3.868229\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:31 INFO 140345909798720] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=-3.86822853432\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:31 INFO 140345909798720] Epoch[236] Batch [5]#011Speed: 127.47 samples/sec#011loss=-3.868229\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:34 INFO 140345909798720] Epoch[236] Batch[10] avg_epoch_loss=-3.938332\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:34 INFO 140345909798720] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=-4.02245524638\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:34 INFO 140345909798720] Epoch[236] Batch [10]#011Speed: 127.14 samples/sec#011loss=-4.022455\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:34 INFO 140345909798720] processed a total of 752 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6631.577014923096, \"sum\": 6631.577014923096, \"min\": 6631.577014923096}}, \"EndTime\": 1580469694.756968, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469688.12495}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:34 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=113.394428693 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:34 INFO 140345909798720] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:34 INFO 140345909798720] #quality_metric: host=algo-1, epoch=236, train loss <loss>=-3.93833158526\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:35 INFO 140345909798720] Epoch[237] Batch[0] avg_epoch_loss=-4.096392\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:35 INFO 140345909798720] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=-4.09639183251\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:38 INFO 140345909798720] Epoch[237] Batch[5] avg_epoch_loss=-4.148854\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:38 INFO 140345909798720] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=-4.1488536113\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:38 INFO 140345909798720] Epoch[237] Batch [5]#011Speed: 127.44 samples/sec#011loss=-4.148854\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:41 INFO 140345909798720] Epoch[237] Batch[10] avg_epoch_loss=-4.046228\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:41 INFO 140345909798720] #quality_metric: host=algo-1, epoch=237, batch=10 train loss <loss>=-3.9230783411\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:41 INFO 140345909798720] Epoch[237] Batch [10]#011Speed: 126.78 samples/sec#011loss=-3.923078\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:41 INFO 140345909798720] processed a total of 767 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6635.483026504517, \"sum\": 6635.483026504517, \"min\": 6635.483026504517}}, \"EndTime\": 1580469701.392989, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469694.757064}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:41 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=115.588450465 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:41 INFO 140345909798720] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:41 INFO 140345909798720] #quality_metric: host=algo-1, epoch=237, train loss <loss>=-4.04622848848\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:42 INFO 140345909798720] Epoch[238] Batch[0] avg_epoch_loss=-2.827801\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:42 INFO 140345909798720] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=-2.82780147243\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:45 INFO 140345909798720] Epoch[238] Batch[5] avg_epoch_loss=-3.297497\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:45 INFO 140345909798720] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=-3.29749703622\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:45 INFO 140345909798720] Epoch[238] Batch [5]#011Speed: 126.29 samples/sec#011loss=-3.297497\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:47 INFO 140345909798720] processed a total of 709 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 6075.054883956909, \"sum\": 6075.054883956909, \"min\": 6075.054883956909}}, \"EndTime\": 1580469707.468521, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1580469701.393076}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:47 INFO 140345909798720] #throughput_metric: host=algo-1, train throughput=116.70405313 records/second\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:47 INFO 140345909798720] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:47 INFO 140345909798720] #quality_metric: host=algo-1, epoch=238, train loss <loss>=-3.28157620817\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:48 INFO 140345909798720] Epoch[239] Batch[0] avg_epoch_loss=-3.144697\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:48 INFO 140345909798720] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=-3.14469662228\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:51 INFO 140345909798720] Epoch[239] Batch[5] avg_epoch_loss=-3.529069\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:51 INFO 140345909798720] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=-3.52906905853\u001b[0m\n",
      "\u001b[34m[01/31/2020 11:21:51 INFO 140345909798720] Epoch[239] Batch [5]#011Speed: 127.81 samples/sec#011loss=-3.529069\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train and test channels\n",
    "data_channels = {\n",
    "    \"train\": train_s3_path,\n",
    "    \"test\": test_s3_path\n",
    "}\n",
    "\n",
    "# fit the estimator\n",
    "estimator.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy and Create a Predictor\n",
    "\n",
    "Now that we have trained a model, we can use it to perform predictions by deploying it to a predictor endpoint.\n",
    "\n",
    "Remember to **delete the endpoint** at the end of this notebook. A cell at the very bottom of this notebook will be provided, but it is always good to keep, front-of-mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# # create a predictor\n",
    "# predictor = estimator.deploy(\n",
    "#     initial_instance_count=1,\n",
    "#     instance_type='ml.t2.medium',\n",
    "#     content_type=\"application/json\" # specify that it will accept/produce JSON\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forecasting-deepar-2020-01-28-11-50-19-637'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator._current_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create endpoint from job name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "job_name = \"forecasting-deepar-200127-0636-011-a47b0ff3\"\n",
    "\n",
    "# job_name = estimator._current_job_name\n",
    "\n",
    "endpoint_name = sagemaker_session.endpoint_from_job(\n",
    "    job_name=job_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    deployment_image=image_name,\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint_name = \"forecasting-deepar-2019-11-21-07-41-20-349\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "class DeepARPredictor(sagemaker.predictor.RealTimePredictor):\n",
    "\n",
    "    def set_prediction_parameters(self, freq, prediction_length, target_col):\n",
    "        \"\"\"Set the time frequency and prediction length parameters. This method **must** be called\n",
    "        before being able to use `predict`.\n",
    "        \n",
    "        Parameters:\n",
    "        freq -- string indicating the time frequency\n",
    "        prediction_length -- integer, number of predicted time points\n",
    "        \n",
    "        Return value: none.\n",
    "        \"\"\"\n",
    "        self.freq = freq\n",
    "        self.prediction_length = prediction_length\n",
    "        self.target_col = target_col\n",
    "        \n",
    "    def predict(self, ts, cat=None, encoding=\"utf-8\", num_samples=100, quantiles=[\"0.1\", \"0.5\", \"0.9\"]):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "        \n",
    "        Parameters:\n",
    "        ts -- list of `pandas.Series` objects, the time series to predict\n",
    "        cat -- list of integers (default: None)\n",
    "        encoding -- string, encoding to use for the request (default: \"utf-8\")\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "        \n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_times = [x.index[-self.prediction_length]+1 for x in ts]\n",
    "        req = self.__encode_request(ts, cat, encoding, num_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, prediction_times, encoding)\n",
    "    \n",
    "    def __encode_request(self, ts, cat, encoding, num_samples, quantiles):\n",
    "#         instances = self.series_to_jsons(ts, self.target_col)\n",
    "        json_objs = []\n",
    "        for ts_i in ts:\n",
    "            json_objs.append(series_to_json(ts_i, self.target_col, self.prediction_length))\n",
    "        configuration = {\"num_samples\": num_samples, \"output_types\": [\"quantiles\"], \"quantiles\": quantiles}\n",
    "        http_request_data = {\"instances\": json_objs, \"configuration\": configuration}\n",
    "        return json.dumps(http_request_data).encode(encoding)\n",
    "    \n",
    "    def __decode_response(self, response, prediction_times, encoding):\n",
    "        response_data = json.loads(response.decode(encoding))\n",
    "        list_of_df = []\n",
    "        for k in range(len(prediction_times)):\n",
    "            prediction_index = pd.DatetimeIndex(start=prediction_times[k], freq=self.freq, periods=self.prediction_length)\n",
    "            list_of_df.append(pd.DataFrame(data=response_data['predictions'][k]['quantiles'], index=prediction_index))\n",
    "        return list_of_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = DeepARPredictor(\n",
    "    endpoint=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    content_type=\"application/json\"\n",
    ")\n",
    "\n",
    "\n",
    "predictor.set_prediction_parameters(freq, prediction_length, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1adb87a668>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CabFlowMean\n",
    "# CabRainTotal\n",
    "ts_s[1].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1adbcae7f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_ts_data['CabRainTotal'][4400:12000].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0f1b9c8518>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction_series[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/ipykernel/__main__.py:32: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/ipykernel/__main__.py:50: FutureWarning: Creating a DatetimeIndex by passing range endpoints is deprecated.  Use `pandas.date_range` instead.\n"
     ]
    }
   ],
   "source": [
    "original_series = train_all_ts_data[4400:4505]\n",
    "prediction_series = predictor.predict([original_series])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the prediction median against the actual data\n",
    "def display_quantiles(prediction_list, target_ts=None):\n",
    "    # show predictions for all input ts\n",
    "    for k in range(len(prediction_list)):\n",
    "        plt.figure(figsize=(12,6))\n",
    "        # get the target month of data\n",
    "        if target_ts is not None:\n",
    "#             target = target_ts[k][-prediction_length:]\n",
    "            target_ts[k].plot(label='target')\n",
    "        # get the quantile values at 10 and 90%\n",
    "        p10 = prediction_list[k]['0.1']\n",
    "        p90 = prediction_list[k]['0.9']\n",
    "        # fill the 80% confidence interval\n",
    "        plt.fill_between(p10.index, p10, p90, color='y', alpha=0.5, label='80% confidence interval')\n",
    "        # plot the median prediction line\n",
    "        prediction_list[k]['0.5'].plot(label='prediction median')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_quantiles(prediction_series, target_ts=[original_series['CabFlowMean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
